<?xml version="1.0" ?>
<net batch="1" name="vehicle-license-plate-detection-barrier-0106" version="6">
	<layers>
		<layer id="0" name="Placeholder" precision="FP32" type="Input">
			<output>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>300</dim>
					<dim>300</dim>
				</port>
			</output>
		</layer>
		<layer id="1" name="Mul_/Fused_Mul_/FusedScaleShift_" precision="FP32" type="ScaleShift">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>300</dim>
					<dim>300</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>3</dim>
					<dim>300</dim>
					<dim>300</dim>
				</port>
			</output>
			<blobs>
				<weights offset="0" size="12"/>
				<biases offset="12" size="12"/>
			</blobs>
		</layer>
		<layer id="2" name="MobilenetV2/Conv/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="16" pads_begin="0,0" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>300</dim>
					<dim>300</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</output>
			<blobs>
				<weights offset="24" size="1728"/>
				<biases offset="1752" size="64"/>
			</blobs>
		</layer>
		<layer id="3" name="MobilenetV2/Conv/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</output>
		</layer>
		<layer id="4" name="MobilenetV2/expanded_conv/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="16" kernel="3,3" output="16" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</output>
			<blobs>
				<weights offset="1816" size="576"/>
				<biases offset="2392" size="64"/>
			</blobs>
		</layer>
		<layer id="5" name="MobilenetV2/expanded_conv/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</output>
		</layer>
		<layer id="6" name="MobilenetV2/expanded_conv/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="16" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2456" size="1024"/>
				<biases offset="3480" size="64"/>
			</blobs>
		</layer>
		<layer id="7" name="MobilenetV2/expanded_conv/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</output>
		</layer>
		<layer id="8" name="MobilenetV2/expanded_conv_1/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="96" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</output>
			<blobs>
				<weights offset="3544" size="6144"/>
				<biases offset="9688" size="384"/>
			</blobs>
		</layer>
		<layer id="9" name="MobilenetV2/expanded_conv_1/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</output>
		</layer>
		<layer id="10" name="MobilenetV2/expanded_conv_1/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="96" kernel="3,3" output="96" pads_begin="0,0" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>150</dim>
					<dim>150</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
			<blobs>
				<weights offset="10072" size="3456"/>
				<biases offset="13528" size="384"/>
			</blobs>
		</layer>
		<layer id="11" name="MobilenetV2/expanded_conv_1/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
		</layer>
		<layer id="12" name="MobilenetV2/expanded_conv_1/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="16" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>16</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
			<blobs>
				<weights offset="13912" size="6144"/>
				<biases offset="20056" size="64"/>
			</blobs>
		</layer>
		<layer id="13" name="MobilenetV2/expanded_conv_2/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="96" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
			<blobs>
				<weights offset="20120" size="6144"/>
				<biases offset="26264" size="384"/>
			</blobs>
		</layer>
		<layer id="14" name="MobilenetV2/expanded_conv_2/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
		</layer>
		<layer id="15" name="MobilenetV2/expanded_conv_2/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="96" kernel="3,3" output="96" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
			<blobs>
				<weights offset="26648" size="3456"/>
				<biases offset="30104" size="384"/>
			</blobs>
		</layer>
		<layer id="16" name="MobilenetV2/expanded_conv_2/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
		</layer>
		<layer id="17" name="MobilenetV2/expanded_conv_2/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="16" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>16</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
			<blobs>
				<weights offset="30488" size="6144"/>
				<biases offset="36632" size="64"/>
			</blobs>
		</layer>
		<layer id="18" name="MobilenetV2/expanded_conv_2/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>16</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
		</layer>
		<layer id="19" name="MobilenetV2/expanded_conv_3/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="96" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
			<blobs>
				<weights offset="36696" size="6144"/>
				<biases offset="42840" size="384"/>
			</blobs>
		</layer>
		<layer id="20" name="MobilenetV2/expanded_conv_3/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</output>
		</layer>
		<layer id="21" name="MobilenetV2/expanded_conv_3/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="96" kernel="3,3" output="96" pads_begin="1,1" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>75</dim>
					<dim>75</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="43224" size="3456"/>
				<biases offset="46680" size="384"/>
			</blobs>
		</layer>
		<layer id="22" name="MobilenetV2/expanded_conv_3/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
		</layer>
		<layer id="23" name="MobilenetV2/expanded_conv_3/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="16" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="47064" size="6144"/>
				<biases offset="53208" size="64"/>
			</blobs>
		</layer>
		<layer id="24" name="MobilenetV2/expanded_conv_4/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="96" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="53272" size="6144"/>
				<biases offset="59416" size="384"/>
			</blobs>
		</layer>
		<layer id="25" name="MobilenetV2/expanded_conv_4/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
		</layer>
		<layer id="26" name="MobilenetV2/expanded_conv_4/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="96" kernel="3,3" output="96" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="59800" size="3456"/>
				<biases offset="63256" size="384"/>
			</blobs>
		</layer>
		<layer id="27" name="MobilenetV2/expanded_conv_4/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
		</layer>
		<layer id="28" name="MobilenetV2/expanded_conv_4/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="16" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="63640" size="6144"/>
				<biases offset="69784" size="64"/>
			</blobs>
		</layer>
		<layer id="29" name="MobilenetV2/expanded_conv_4/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
		</layer>
		<layer id="30" name="MobilenetV2/expanded_conv_5/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="96" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="69848" size="6144"/>
				<biases offset="75992" size="384"/>
			</blobs>
		</layer>
		<layer id="31" name="MobilenetV2/expanded_conv_5/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
		</layer>
		<layer id="32" name="MobilenetV2/expanded_conv_5/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="96" kernel="3,3" output="96" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="76376" size="3456"/>
				<biases offset="79832" size="384"/>
			</blobs>
		</layer>
		<layer id="33" name="MobilenetV2/expanded_conv_5/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
		</layer>
		<layer id="34" name="MobilenetV2/expanded_conv_5/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="16" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="80216" size="6144"/>
				<biases offset="86360" size="64"/>
			</blobs>
		</layer>
		<layer id="35" name="MobilenetV2/expanded_conv_5/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
		</layer>
		<layer id="36" name="MobilenetV2/expanded_conv_6/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="96" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
			<blobs>
				<weights offset="86424" size="6144"/>
				<biases offset="92568" size="384"/>
			</blobs>
		</layer>
		<layer id="37" name="MobilenetV2/expanded_conv_6/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</output>
		</layer>
		<layer id="38" name="MobilenetV2/expanded_conv_6/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="96" kernel="3,3" output="96" pads_begin="0,0" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>38</dim>
					<dim>38</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="92952" size="3456"/>
				<biases offset="96408" size="384"/>
			</blobs>
		</layer>
		<layer id="39" name="MobilenetV2/expanded_conv_6/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="40" name="MobilenetV2/expanded_conv_6/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="24" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="96792" size="9216"/>
				<biases offset="106008" size="96"/>
			</blobs>
		</layer>
		<layer id="41" name="MobilenetV2/expanded_conv_7/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="144" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="106104" size="13824"/>
				<biases offset="119928" size="576"/>
			</blobs>
		</layer>
		<layer id="42" name="MobilenetV2/expanded_conv_7/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="43" name="MobilenetV2/expanded_conv_7/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="144" kernel="3,3" output="144" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="120504" size="5184"/>
				<biases offset="125688" size="576"/>
			</blobs>
		</layer>
		<layer id="44" name="MobilenetV2/expanded_conv_7/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="45" name="MobilenetV2/expanded_conv_7/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="24" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="126264" size="13824"/>
				<biases offset="140088" size="96"/>
			</blobs>
		</layer>
		<layer id="46" name="MobilenetV2/expanded_conv_7/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="47" name="MobilenetV2/expanded_conv_8/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="144" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="140184" size="13824"/>
				<biases offset="154008" size="576"/>
			</blobs>
		</layer>
		<layer id="48" name="MobilenetV2/expanded_conv_8/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="49" name="MobilenetV2/expanded_conv_8/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="144" kernel="3,3" output="144" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="154584" size="5184"/>
				<biases offset="159768" size="576"/>
			</blobs>
		</layer>
		<layer id="50" name="MobilenetV2/expanded_conv_8/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="51" name="MobilenetV2/expanded_conv_8/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="24" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="160344" size="13824"/>
				<biases offset="174168" size="96"/>
			</blobs>
		</layer>
		<layer id="52" name="MobilenetV2/expanded_conv_8/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="53" name="MobilenetV2/expanded_conv_9/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="144" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="174264" size="13824"/>
				<biases offset="188088" size="576"/>
			</blobs>
		</layer>
		<layer id="54" name="MobilenetV2/expanded_conv_9/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="55" name="MobilenetV2/expanded_conv_9/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="144" kernel="3,3" output="144" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="188664" size="5184"/>
				<biases offset="193848" size="576"/>
			</blobs>
		</layer>
		<layer id="56" name="MobilenetV2/expanded_conv_9/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="57" name="MobilenetV2/expanded_conv_9/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="24" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="194424" size="13824"/>
				<biases offset="208248" size="96"/>
			</blobs>
		</layer>
		<layer id="58" name="MobilenetV2/expanded_conv_9/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="59" name="MobilenetV2/expanded_conv_10/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="144" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="208344" size="13824"/>
				<biases offset="222168" size="576"/>
			</blobs>
		</layer>
		<layer id="60" name="MobilenetV2/expanded_conv_10/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="61" name="MobilenetV2/expanded_conv_10/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="144" kernel="3,3" output="144" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="222744" size="5184"/>
				<biases offset="227928" size="576"/>
			</blobs>
		</layer>
		<layer id="62" name="MobilenetV2/expanded_conv_10/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="63" name="MobilenetV2/expanded_conv_10/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="32" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>144</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="228504" size="18432"/>
				<biases offset="246936" size="128"/>
			</blobs>
		</layer>
		<layer id="64" name="MobilenetV2/expanded_conv_11/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="192" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="247064" size="24576"/>
				<biases offset="271640" size="768"/>
			</blobs>
		</layer>
		<layer id="65" name="MobilenetV2/expanded_conv_11/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="66" name="MobilenetV2/expanded_conv_11/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="192" kernel="3,3" output="192" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="272408" size="6912"/>
				<biases offset="279320" size="768"/>
			</blobs>
		</layer>
		<layer id="67" name="MobilenetV2/expanded_conv_11/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="68" name="MobilenetV2/expanded_conv_11/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="32" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="280088" size="24576"/>
				<biases offset="304664" size="128"/>
			</blobs>
		</layer>
		<layer id="69" name="MobilenetV2/expanded_conv_11/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="70" name="MobilenetV2/expanded_conv_12/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="192" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="304792" size="24576"/>
				<biases offset="329368" size="768"/>
			</blobs>
		</layer>
		<layer id="71" name="MobilenetV2/expanded_conv_12/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="72" name="MobilenetV2/expanded_conv_12/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="192" kernel="3,3" output="192" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="330136" size="6912"/>
				<biases offset="337048" size="768"/>
			</blobs>
		</layer>
		<layer id="73" name="MobilenetV2/expanded_conv_12/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="74" name="MobilenetV2/expanded_conv_12/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="32" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="337816" size="24576"/>
				<biases offset="362392" size="128"/>
			</blobs>
		</layer>
		<layer id="75" name="MobilenetV2/expanded_conv_12/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="76" name="SSD/ssd_head/layer_14/output_mbox_loc/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="8" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>8</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="362520" size="9216"/>
				<biases offset="371736" size="32"/>
			</blobs>
		</layer>
		<layer id="77" name="SSD/ssd_head/layer_14/output_mbox_loc/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>19</dim>
					<dim>19</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="78" name="1236/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="79" name="SSD/ssd_head/Flatten/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>19</dim>
					<dim>19</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>2888</dim>
				</port>
			</output>
		</layer>
		<layer id="80" name="MobilenetV2/expanded_conv_13/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="192" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="371776" size="24576"/>
				<biases offset="396352" size="768"/>
			</blobs>
		</layer>
		<layer id="81" name="MobilenetV2/expanded_conv_13/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
		</layer>
		<layer id="82" name="MobilenetV2/expanded_conv_13/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="192" kernel="3,3" output="192" pads_begin="1,1" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>192</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="397120" size="6912"/>
				<biases offset="404032" size="768"/>
			</blobs>
		</layer>
		<layer id="83" name="MobilenetV2/expanded_conv_13/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>192</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="84" name="MobilenetV2/expanded_conv_13/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="56" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="404800" size="43008"/>
				<biases offset="447808" size="224"/>
			</blobs>
		</layer>
		<layer id="85" name="MobilenetV2/expanded_conv_14/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="336" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="448032" size="75264"/>
				<biases offset="523296" size="1344"/>
			</blobs>
		</layer>
		<layer id="86" name="MobilenetV2/expanded_conv_14/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="87" name="MobilenetV2/expanded_conv_14/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="336" kernel="3,3" output="336" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="524640" size="12096"/>
				<biases offset="536736" size="1344"/>
			</blobs>
		</layer>
		<layer id="88" name="MobilenetV2/expanded_conv_14/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="89" name="MobilenetV2/expanded_conv_14/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="56" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="538080" size="75264"/>
				<biases offset="613344" size="224"/>
			</blobs>
		</layer>
		<layer id="90" name="MobilenetV2/expanded_conv_14/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="91" name="MobilenetV2/expanded_conv_15/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="336" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="613568" size="75264"/>
				<biases offset="688832" size="1344"/>
			</blobs>
		</layer>
		<layer id="92" name="MobilenetV2/expanded_conv_15/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="93" name="MobilenetV2/expanded_conv_15/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="336" kernel="3,3" output="336" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="690176" size="12096"/>
				<biases offset="702272" size="1344"/>
			</blobs>
		</layer>
		<layer id="94" name="MobilenetV2/expanded_conv_15/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="95" name="MobilenetV2/expanded_conv_15/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="56" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="703616" size="75264"/>
				<biases offset="778880" size="224"/>
			</blobs>
		</layer>
		<layer id="96" name="MobilenetV2/expanded_conv_15/add" precision="FP32" type="Eltwise">
			<data operation="sum"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="97" name="MobilenetV2/expanded_conv_16/expand/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="336" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>56</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="779104" size="75264"/>
				<biases offset="854368" size="1344"/>
			</blobs>
		</layer>
		<layer id="98" name="MobilenetV2/expanded_conv_16/expand/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="99" name="MobilenetV2/expanded_conv_16/depthwise/depthwise" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="336" kernel="3,3" output="336" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="855712" size="12096"/>
				<biases offset="867808" size="1344"/>
			</blobs>
		</layer>
		<layer id="100" name="MobilenetV2/expanded_conv_16/depthwise/Relu6" precision="FP32" type="Clamp">
			<data max="6" min="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="101" name="MobilenetV2/expanded_conv_16/project/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="112" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>336</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>112</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="869152" size="150528"/>
				<biases offset="1019680" size="448"/>
			</blobs>
		</layer>
		<layer id="102" name="SSD/ssd_head_1/layer_18/output_mbox_loc/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="12" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>112</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>12</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="1020128" size="48384"/>
				<biases offset="1068512" size="48"/>
			</blobs>
		</layer>
		<layer id="103" name="SSD/ssd_head_1/layer_18/output_mbox_loc/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>12</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>10</dim>
					<dim>10</dim>
					<dim>12</dim>
				</port>
			</output>
		</layer>
		<layer id="104" name="1232/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="105" name="SSD/ssd_head_1/Flatten/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>10</dim>
					<dim>10</dim>
					<dim>12</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>1200</dim>
				</port>
			</output>
		</layer>
		<layer id="106" name="features/intermediate_1/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="96" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>112</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="1068560" size="43008"/>
				<biases offset="1111568" size="384"/>
			</blobs>
		</layer>
		<layer id="107" name="features/intermediate_1/Relu" precision="FP32" type="ReLU">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
		</layer>
		<layer id="108" name="features/feature_map_1/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="192" pads_begin="0,0" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>192</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
			<blobs>
				<weights offset="1111952" size="663552"/>
				<biases offset="1775504" size="768"/>
			</blobs>
		</layer>
		<layer id="109" name="features/feature_map_1/Relu" precision="FP32" type="ReLU">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>192</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="110" name="SSD/ssd_head_2/feature_map_1_mbox_loc/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="12" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>12</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
			<blobs>
				<weights offset="1776272" size="82944"/>
				<biases offset="1859216" size="48"/>
			</blobs>
		</layer>
		<layer id="111" name="SSD/ssd_head_2/feature_map_1_mbox_loc/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>12</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
					<dim>12</dim>
				</port>
			</output>
		</layer>
		<layer id="112" name="1242/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="113" name="SSD/ssd_head_2/Flatten/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
					<dim>12</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>300</dim>
				</port>
			</output>
		</layer>
		<layer id="114" name="features/intermediate_2/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="48" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>48</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
			<blobs>
				<weights offset="1859264" size="36864"/>
				<biases offset="1896128" size="192"/>
			</blobs>
		</layer>
		<layer id="115" name="features/intermediate_2/Relu" precision="FP32" type="ReLU">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>48</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>48</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="116" name="features/feature_map_2/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="96" pads_begin="1,1" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>48</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
			<blobs>
				<weights offset="1896320" size="165888"/>
				<biases offset="2062208" size="384"/>
			</blobs>
		</layer>
		<layer id="117" name="features/feature_map_2/Relu" precision="FP32" type="ReLU">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="118" name="SSD/ssd_head_3/feature_map_2_mbox_loc/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="8" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>8</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2062592" size="27648"/>
				<biases offset="2090240" size="32"/>
			</blobs>
		</layer>
		<layer id="119" name="SSD/ssd_head_3/feature_map_2_mbox_loc/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="120" name="1235/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="121" name="SSD/ssd_head_3/Flatten/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>72</dim>
				</port>
			</output>
		</layer>
		<layer id="122" name="features/intermediate_3/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="48" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>48</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2090272" size="18432"/>
				<biases offset="2108704" size="192"/>
			</blobs>
		</layer>
		<layer id="123" name="features/intermediate_3/Relu" precision="FP32" type="ReLU">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>48</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>48</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="124" name="features/feature_map_3/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="96" pads_begin="1,1" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>48</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2108896" size="165888"/>
				<biases offset="2274784" size="384"/>
			</blobs>
		</layer>
		<layer id="125" name="features/feature_map_3/Relu" precision="FP32" type="ReLU">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="126" name="SSD/ssd_head_4/feature_map_3_mbox_loc/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="8" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>8</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2275168" size="27648"/>
				<biases offset="2302816" size="32"/>
			</blobs>
		</layer>
		<layer id="127" name="SSD/ssd_head_4/feature_map_3_mbox_loc/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>2</dim>
					<dim>2</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="128" name="1240/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="129" name="SSD/ssd_head_4/Flatten/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>2</dim>
					<dim>2</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="130" name="features/intermediate_4/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="1,1" output="24" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>24</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2302848" size="9216"/>
				<biases offset="2312064" size="96"/>
			</blobs>
		</layer>
		<layer id="131" name="features/intermediate_4/Relu" precision="FP32" type="ReLU">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>24</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="132" name="features/feature_map_4/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="48" pads_begin="0,0" pads_end="1,1" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>24</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2312160" size="41472"/>
				<biases offset="2353632" size="192"/>
			</blobs>
		</layer>
		<layer id="133" name="features/feature_map_4/Relu" precision="FP32" type="ReLU">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="134" name="SSD/ssd_head_5/feature_map_4_mbox_loc/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="12" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>12</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2353824" size="20736"/>
				<biases offset="2374560" size="48"/>
			</blobs>
		</layer>
		<layer id="135" name="SSD/ssd_head_5/feature_map_4_mbox_loc/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>12</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>12</dim>
				</port>
			</output>
		</layer>
		<layer id="136" name="1237/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="137" name="SSD/ssd_head_5/Flatten/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>12</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>12</dim>
				</port>
			</output>
		</layer>
		<layer id="138" name="SSD/concat_reshape_softmax/mbox_loc" precision="FP32" type="Concat">
			<data axis="1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>2888</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>1200</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>300</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>72</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>32</dim>
				</port>
				<port id="5">
					<dim>1</dim>
					<dim>12</dim>
				</port>
			</input>
			<output>
				<port id="6">
					<dim>1</dim>
					<dim>4504</dim>
				</port>
			</output>
		</layer>
		<layer id="139" name="SSD/concat_reshape_softmax/mbox_loc_final/shape/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>3</dim>
				</port>
			</output>
			<blobs>
				<custom offset="2374608" size="12"/>
			</blobs>
		</layer>
		<layer id="140" name="SSD/concat_reshape_softmax/mbox_loc_final" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4504</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>1126</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="141" name="Copy_1225/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="142" name="DetectionOutput_Reshape_loc_" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>1126</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>4504</dim>
				</port>
			</output>
		</layer>
		<layer id="143" name="SSD/ssd_head/layer_14/output_mbox_conf/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="6" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>32</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>6</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2374620" size="6912"/>
				<biases offset="2381532" size="24"/>
			</blobs>
		</layer>
		<layer id="144" name="SSD/ssd_head/layer_14/output_mbox_conf/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>19</dim>
					<dim>19</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>19</dim>
					<dim>19</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="145" name="1238/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="146" name="SSD/ssd_head/Flatten_1/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>19</dim>
					<dim>19</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>2166</dim>
				</port>
			</output>
		</layer>
		<layer id="147" name="SSD/ssd_head_1/layer_18/output_mbox_conf/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="9" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>112</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>9</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2381556" size="36288"/>
				<biases offset="2417844" size="36"/>
			</blobs>
		</layer>
		<layer id="148" name="SSD/ssd_head_1/layer_18/output_mbox_conf/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>9</dim>
					<dim>10</dim>
					<dim>10</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>10</dim>
					<dim>10</dim>
					<dim>9</dim>
				</port>
			</output>
		</layer>
		<layer id="149" name="1233/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="150" name="SSD/ssd_head_1/Flatten_1/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>10</dim>
					<dim>10</dim>
					<dim>9</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>900</dim>
				</port>
			</output>
		</layer>
		<layer id="151" name="SSD/ssd_head_2/feature_map_1_mbox_conf/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="9" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>192</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>9</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2417880" size="62208"/>
				<biases offset="2480088" size="36"/>
			</blobs>
		</layer>
		<layer id="152" name="SSD/ssd_head_2/feature_map_1_mbox_conf/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>9</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
					<dim>9</dim>
				</port>
			</output>
		</layer>
		<layer id="153" name="1239/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="154" name="SSD/ssd_head_2/Flatten_1/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
					<dim>9</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>225</dim>
				</port>
			</output>
		</layer>
		<layer id="155" name="SSD/ssd_head_3/feature_map_2_mbox_conf/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="6" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>6</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2480124" size="20736"/>
				<biases offset="2500860" size="24"/>
			</blobs>
		</layer>
		<layer id="156" name="SSD/ssd_head_3/feature_map_2_mbox_conf/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="157" name="1241/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="158" name="SSD/ssd_head_3/Flatten_1/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>54</dim>
				</port>
			</output>
		</layer>
		<layer id="159" name="SSD/ssd_head_4/feature_map_3_mbox_conf/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="6" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>6</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2500884" size="20736"/>
				<biases offset="2521620" size="24"/>
			</blobs>
		</layer>
		<layer id="160" name="SSD/ssd_head_4/feature_map_3_mbox_conf/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>2</dim>
					<dim>2</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="161" name="1234/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="162" name="SSD/ssd_head_4/Flatten_1/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>2</dim>
					<dim>2</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>24</dim>
				</port>
			</output>
		</layer>
		<layer id="163" name="SSD/ssd_head_5/feature_map_4_mbox_conf/Conv2D" precision="FP32" type="Convolution">
			<data auto_pad="same_upper" dilations="1,1" group="1" kernel="3,3" output="9" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>9</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
			<blobs>
				<weights offset="2521644" size="15552"/>
				<biases offset="2537196" size="36"/>
			</blobs>
		</layer>
		<layer id="164" name="SSD/ssd_head_5/feature_map_4_mbox_conf/Conv2D/Transpose" precision="FP32" type="Permute">
			<data order="0,2,3,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>9</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>9</dim>
				</port>
			</output>
		</layer>
		<layer id="165" name="1243/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="166" name="SSD/ssd_head_5/Flatten_1/flatten/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>9</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>9</dim>
				</port>
			</output>
		</layer>
		<layer id="167" name="SSD/concat_reshape_softmax/mbox_conf" precision="FP32" type="Concat">
			<data axis="1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>2166</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>900</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>225</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>54</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>24</dim>
				</port>
				<port id="5">
					<dim>1</dim>
					<dim>9</dim>
				</port>
			</input>
			<output>
				<port id="6">
					<dim>1</dim>
					<dim>3378</dim>
				</port>
			</output>
		</layer>
		<layer id="168" name="SSD/concat_reshape_softmax/mbox_conf_logits/shape/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>3</dim>
				</port>
			</output>
			<blobs>
				<custom offset="2537232" size="12"/>
			</blobs>
		</layer>
		<layer id="169" name="SSD/concat_reshape_softmax/mbox_conf_logits" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3378</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>1126</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="170" name="SSD/concat_reshape_softmax/concat/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="2537244" size="8"/>
			</blobs>
		</layer>
		<layer id="171" name="SSD/concat_reshape_softmax/Reshape" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>1126</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1126</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="172" name="SSD/concat_reshape_softmax/Softmax" precision="FP32" type="SoftMax">
			<data axis="1"/>
			<input>
				<port id="0">
					<dim>1126</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1">
					<dim>1126</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="173" name="SSD/concat_reshape_softmax/Shape/Output_0/Data__const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>3</dim>
				</port>
			</output>
			<blobs>
				<custom offset="2537252" size="12"/>
			</blobs>
		</layer>
		<layer id="174" name="SSD/concat_reshape_softmax/mbox_conf_final" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1126</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>1126</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="175" name="Copy_1225/Output_0/Data_3017_const" precision="I32" type="Const">
			<output>
				<port id="1">
					<dim>2</dim>
				</port>
			</output>
			<blobs>
				<custom offset="371768" size="8"/>
			</blobs>
		</layer>
		<layer id="176" name="DetectionOutput_Reshape_conf_" precision="FP32" type="Reshape">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>1126</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2">
					<dim>1</dim>
					<dim>3378</dim>
				</port>
			</output>
		</layer>
		<layer id="177" name="DetectionOutput_Reshape_priors_/Output_0/Data__const" precision="FP32" type="Const">
			<output>
				<port id="1">
					<dim>1</dim>
					<dim>2</dim>
					<dim>4504</dim>
				</port>
			</output>
			<blobs>
				<custom offset="2537264" size="36032"/>
			</blobs>
		</layer>
		<layer id="178" name="DetectionOutput_" precision="FP32" type="DetectionOutput">
			<data code_type="caffe.PriorBoxParameter.CENTER_SIZE" confidence_threshold="0.01" input_height="1" input_width="1" keep_top_k="200" nms_threshold="0.45" normalized="1" num_classes="3" pad_mode="caffe.ResizeParameter.CONSTANT" resize_mode="caffe.ResizeParameter.WARP" share_location="1" top_k="400" variance_encoded_in_target="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4504</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>3378</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>2</dim>
					<dim>4504</dim>
				</port>
			</input>
			<output>
				<port id="3">
					<dim>1</dim>
					<dim>1</dim>
					<dim>200</dim>
					<dim>7</dim>
				</port>
			</output>
		</layer>
	</layers>
	<edges>
		<edge from-layer="0" from-port="0" to-layer="1" to-port="0"/>
		<edge from-layer="1" from-port="3" to-layer="2" to-port="0"/>
		<edge from-layer="2" from-port="3" to-layer="3" to-port="0"/>
		<edge from-layer="3" from-port="1" to-layer="4" to-port="0"/>
		<edge from-layer="4" from-port="3" to-layer="5" to-port="0"/>
		<edge from-layer="5" from-port="1" to-layer="6" to-port="0"/>
		<edge from-layer="6" from-port="3" to-layer="7" to-port="0"/>
		<edge from-layer="3" from-port="1" to-layer="7" to-port="1"/>
		<edge from-layer="7" from-port="2" to-layer="8" to-port="0"/>
		<edge from-layer="8" from-port="3" to-layer="9" to-port="0"/>
		<edge from-layer="9" from-port="1" to-layer="10" to-port="0"/>
		<edge from-layer="10" from-port="3" to-layer="11" to-port="0"/>
		<edge from-layer="11" from-port="1" to-layer="12" to-port="0"/>
		<edge from-layer="12" from-port="3" to-layer="13" to-port="0"/>
		<edge from-layer="13" from-port="3" to-layer="14" to-port="0"/>
		<edge from-layer="14" from-port="1" to-layer="15" to-port="0"/>
		<edge from-layer="15" from-port="3" to-layer="16" to-port="0"/>
		<edge from-layer="16" from-port="1" to-layer="17" to-port="0"/>
		<edge from-layer="17" from-port="3" to-layer="18" to-port="0"/>
		<edge from-layer="12" from-port="3" to-layer="18" to-port="1"/>
		<edge from-layer="18" from-port="2" to-layer="19" to-port="0"/>
		<edge from-layer="19" from-port="3" to-layer="20" to-port="0"/>
		<edge from-layer="20" from-port="1" to-layer="21" to-port="0"/>
		<edge from-layer="21" from-port="3" to-layer="22" to-port="0"/>
		<edge from-layer="22" from-port="1" to-layer="23" to-port="0"/>
		<edge from-layer="23" from-port="3" to-layer="24" to-port="0"/>
		<edge from-layer="24" from-port="3" to-layer="25" to-port="0"/>
		<edge from-layer="25" from-port="1" to-layer="26" to-port="0"/>
		<edge from-layer="26" from-port="3" to-layer="27" to-port="0"/>
		<edge from-layer="27" from-port="1" to-layer="28" to-port="0"/>
		<edge from-layer="28" from-port="3" to-layer="29" to-port="0"/>
		<edge from-layer="23" from-port="3" to-layer="29" to-port="1"/>
		<edge from-layer="29" from-port="2" to-layer="30" to-port="0"/>
		<edge from-layer="30" from-port="3" to-layer="31" to-port="0"/>
		<edge from-layer="31" from-port="1" to-layer="32" to-port="0"/>
		<edge from-layer="32" from-port="3" to-layer="33" to-port="0"/>
		<edge from-layer="33" from-port="1" to-layer="34" to-port="0"/>
		<edge from-layer="34" from-port="3" to-layer="35" to-port="0"/>
		<edge from-layer="29" from-port="2" to-layer="35" to-port="1"/>
		<edge from-layer="35" from-port="2" to-layer="36" to-port="0"/>
		<edge from-layer="36" from-port="3" to-layer="37" to-port="0"/>
		<edge from-layer="37" from-port="1" to-layer="38" to-port="0"/>
		<edge from-layer="38" from-port="3" to-layer="39" to-port="0"/>
		<edge from-layer="39" from-port="1" to-layer="40" to-port="0"/>
		<edge from-layer="40" from-port="3" to-layer="41" to-port="0"/>
		<edge from-layer="41" from-port="3" to-layer="42" to-port="0"/>
		<edge from-layer="42" from-port="1" to-layer="43" to-port="0"/>
		<edge from-layer="43" from-port="3" to-layer="44" to-port="0"/>
		<edge from-layer="44" from-port="1" to-layer="45" to-port="0"/>
		<edge from-layer="45" from-port="3" to-layer="46" to-port="0"/>
		<edge from-layer="40" from-port="3" to-layer="46" to-port="1"/>
		<edge from-layer="46" from-port="2" to-layer="47" to-port="0"/>
		<edge from-layer="47" from-port="3" to-layer="48" to-port="0"/>
		<edge from-layer="48" from-port="1" to-layer="49" to-port="0"/>
		<edge from-layer="49" from-port="3" to-layer="50" to-port="0"/>
		<edge from-layer="50" from-port="1" to-layer="51" to-port="0"/>
		<edge from-layer="51" from-port="3" to-layer="52" to-port="0"/>
		<edge from-layer="46" from-port="2" to-layer="52" to-port="1"/>
		<edge from-layer="52" from-port="2" to-layer="53" to-port="0"/>
		<edge from-layer="53" from-port="3" to-layer="54" to-port="0"/>
		<edge from-layer="54" from-port="1" to-layer="55" to-port="0"/>
		<edge from-layer="55" from-port="3" to-layer="56" to-port="0"/>
		<edge from-layer="56" from-port="1" to-layer="57" to-port="0"/>
		<edge from-layer="57" from-port="3" to-layer="58" to-port="0"/>
		<edge from-layer="52" from-port="2" to-layer="58" to-port="1"/>
		<edge from-layer="58" from-port="2" to-layer="59" to-port="0"/>
		<edge from-layer="59" from-port="3" to-layer="60" to-port="0"/>
		<edge from-layer="60" from-port="1" to-layer="61" to-port="0"/>
		<edge from-layer="61" from-port="3" to-layer="62" to-port="0"/>
		<edge from-layer="62" from-port="1" to-layer="63" to-port="0"/>
		<edge from-layer="63" from-port="3" to-layer="64" to-port="0"/>
		<edge from-layer="64" from-port="3" to-layer="65" to-port="0"/>
		<edge from-layer="65" from-port="1" to-layer="66" to-port="0"/>
		<edge from-layer="66" from-port="3" to-layer="67" to-port="0"/>
		<edge from-layer="67" from-port="1" to-layer="68" to-port="0"/>
		<edge from-layer="68" from-port="3" to-layer="69" to-port="0"/>
		<edge from-layer="63" from-port="3" to-layer="69" to-port="1"/>
		<edge from-layer="69" from-port="2" to-layer="70" to-port="0"/>
		<edge from-layer="70" from-port="3" to-layer="71" to-port="0"/>
		<edge from-layer="71" from-port="1" to-layer="72" to-port="0"/>
		<edge from-layer="72" from-port="3" to-layer="73" to-port="0"/>
		<edge from-layer="73" from-port="1" to-layer="74" to-port="0"/>
		<edge from-layer="74" from-port="3" to-layer="75" to-port="0"/>
		<edge from-layer="69" from-port="2" to-layer="75" to-port="1"/>
		<edge from-layer="75" from-port="2" to-layer="76" to-port="0"/>
		<edge from-layer="76" from-port="3" to-layer="77" to-port="0"/>
		<edge from-layer="77" from-port="1" to-layer="79" to-port="0"/>
		<edge from-layer="78" from-port="1" to-layer="79" to-port="1"/>
		<edge from-layer="75" from-port="2" to-layer="80" to-port="0"/>
		<edge from-layer="80" from-port="3" to-layer="81" to-port="0"/>
		<edge from-layer="81" from-port="1" to-layer="82" to-port="0"/>
		<edge from-layer="82" from-port="3" to-layer="83" to-port="0"/>
		<edge from-layer="83" from-port="1" to-layer="84" to-port="0"/>
		<edge from-layer="84" from-port="3" to-layer="85" to-port="0"/>
		<edge from-layer="85" from-port="3" to-layer="86" to-port="0"/>
		<edge from-layer="86" from-port="1" to-layer="87" to-port="0"/>
		<edge from-layer="87" from-port="3" to-layer="88" to-port="0"/>
		<edge from-layer="88" from-port="1" to-layer="89" to-port="0"/>
		<edge from-layer="89" from-port="3" to-layer="90" to-port="0"/>
		<edge from-layer="84" from-port="3" to-layer="90" to-port="1"/>
		<edge from-layer="90" from-port="2" to-layer="91" to-port="0"/>
		<edge from-layer="91" from-port="3" to-layer="92" to-port="0"/>
		<edge from-layer="92" from-port="1" to-layer="93" to-port="0"/>
		<edge from-layer="93" from-port="3" to-layer="94" to-port="0"/>
		<edge from-layer="94" from-port="1" to-layer="95" to-port="0"/>
		<edge from-layer="95" from-port="3" to-layer="96" to-port="0"/>
		<edge from-layer="90" from-port="2" to-layer="96" to-port="1"/>
		<edge from-layer="96" from-port="2" to-layer="97" to-port="0"/>
		<edge from-layer="97" from-port="3" to-layer="98" to-port="0"/>
		<edge from-layer="98" from-port="1" to-layer="99" to-port="0"/>
		<edge from-layer="99" from-port="3" to-layer="100" to-port="0"/>
		<edge from-layer="100" from-port="1" to-layer="101" to-port="0"/>
		<edge from-layer="101" from-port="3" to-layer="102" to-port="0"/>
		<edge from-layer="102" from-port="3" to-layer="103" to-port="0"/>
		<edge from-layer="103" from-port="1" to-layer="105" to-port="0"/>
		<edge from-layer="104" from-port="1" to-layer="105" to-port="1"/>
		<edge from-layer="101" from-port="3" to-layer="106" to-port="0"/>
		<edge from-layer="106" from-port="3" to-layer="107" to-port="0"/>
		<edge from-layer="107" from-port="1" to-layer="108" to-port="0"/>
		<edge from-layer="108" from-port="3" to-layer="109" to-port="0"/>
		<edge from-layer="109" from-port="1" to-layer="110" to-port="0"/>
		<edge from-layer="110" from-port="3" to-layer="111" to-port="0"/>
		<edge from-layer="111" from-port="1" to-layer="113" to-port="0"/>
		<edge from-layer="112" from-port="1" to-layer="113" to-port="1"/>
		<edge from-layer="109" from-port="1" to-layer="114" to-port="0"/>
		<edge from-layer="114" from-port="3" to-layer="115" to-port="0"/>
		<edge from-layer="115" from-port="1" to-layer="116" to-port="0"/>
		<edge from-layer="116" from-port="3" to-layer="117" to-port="0"/>
		<edge from-layer="117" from-port="1" to-layer="118" to-port="0"/>
		<edge from-layer="118" from-port="3" to-layer="119" to-port="0"/>
		<edge from-layer="119" from-port="1" to-layer="121" to-port="0"/>
		<edge from-layer="120" from-port="1" to-layer="121" to-port="1"/>
		<edge from-layer="117" from-port="1" to-layer="122" to-port="0"/>
		<edge from-layer="122" from-port="3" to-layer="123" to-port="0"/>
		<edge from-layer="123" from-port="1" to-layer="124" to-port="0"/>
		<edge from-layer="124" from-port="3" to-layer="125" to-port="0"/>
		<edge from-layer="125" from-port="1" to-layer="126" to-port="0"/>
		<edge from-layer="126" from-port="3" to-layer="127" to-port="0"/>
		<edge from-layer="127" from-port="1" to-layer="129" to-port="0"/>
		<edge from-layer="128" from-port="1" to-layer="129" to-port="1"/>
		<edge from-layer="125" from-port="1" to-layer="130" to-port="0"/>
		<edge from-layer="130" from-port="3" to-layer="131" to-port="0"/>
		<edge from-layer="131" from-port="1" to-layer="132" to-port="0"/>
		<edge from-layer="132" from-port="3" to-layer="133" to-port="0"/>
		<edge from-layer="133" from-port="1" to-layer="134" to-port="0"/>
		<edge from-layer="134" from-port="3" to-layer="135" to-port="0"/>
		<edge from-layer="135" from-port="1" to-layer="137" to-port="0"/>
		<edge from-layer="136" from-port="1" to-layer="137" to-port="1"/>
		<edge from-layer="79" from-port="2" to-layer="138" to-port="0"/>
		<edge from-layer="105" from-port="2" to-layer="138" to-port="1"/>
		<edge from-layer="113" from-port="2" to-layer="138" to-port="2"/>
		<edge from-layer="121" from-port="2" to-layer="138" to-port="3"/>
		<edge from-layer="129" from-port="2" to-layer="138" to-port="4"/>
		<edge from-layer="137" from-port="2" to-layer="138" to-port="5"/>
		<edge from-layer="138" from-port="6" to-layer="140" to-port="0"/>
		<edge from-layer="139" from-port="1" to-layer="140" to-port="1"/>
		<edge from-layer="140" from-port="2" to-layer="142" to-port="0"/>
		<edge from-layer="141" from-port="1" to-layer="142" to-port="1"/>
		<edge from-layer="75" from-port="2" to-layer="143" to-port="0"/>
		<edge from-layer="143" from-port="3" to-layer="144" to-port="0"/>
		<edge from-layer="144" from-port="1" to-layer="146" to-port="0"/>
		<edge from-layer="145" from-port="1" to-layer="146" to-port="1"/>
		<edge from-layer="101" from-port="3" to-layer="147" to-port="0"/>
		<edge from-layer="147" from-port="3" to-layer="148" to-port="0"/>
		<edge from-layer="148" from-port="1" to-layer="150" to-port="0"/>
		<edge from-layer="149" from-port="1" to-layer="150" to-port="1"/>
		<edge from-layer="109" from-port="1" to-layer="151" to-port="0"/>
		<edge from-layer="151" from-port="3" to-layer="152" to-port="0"/>
		<edge from-layer="152" from-port="1" to-layer="154" to-port="0"/>
		<edge from-layer="153" from-port="1" to-layer="154" to-port="1"/>
		<edge from-layer="117" from-port="1" to-layer="155" to-port="0"/>
		<edge from-layer="155" from-port="3" to-layer="156" to-port="0"/>
		<edge from-layer="156" from-port="1" to-layer="158" to-port="0"/>
		<edge from-layer="157" from-port="1" to-layer="158" to-port="1"/>
		<edge from-layer="125" from-port="1" to-layer="159" to-port="0"/>
		<edge from-layer="159" from-port="3" to-layer="160" to-port="0"/>
		<edge from-layer="160" from-port="1" to-layer="162" to-port="0"/>
		<edge from-layer="161" from-port="1" to-layer="162" to-port="1"/>
		<edge from-layer="133" from-port="1" to-layer="163" to-port="0"/>
		<edge from-layer="163" from-port="3" to-layer="164" to-port="0"/>
		<edge from-layer="164" from-port="1" to-layer="166" to-port="0"/>
		<edge from-layer="165" from-port="1" to-layer="166" to-port="1"/>
		<edge from-layer="146" from-port="2" to-layer="167" to-port="0"/>
		<edge from-layer="150" from-port="2" to-layer="167" to-port="1"/>
		<edge from-layer="154" from-port="2" to-layer="167" to-port="2"/>
		<edge from-layer="158" from-port="2" to-layer="167" to-port="3"/>
		<edge from-layer="162" from-port="2" to-layer="167" to-port="4"/>
		<edge from-layer="166" from-port="2" to-layer="167" to-port="5"/>
		<edge from-layer="167" from-port="6" to-layer="169" to-port="0"/>
		<edge from-layer="168" from-port="1" to-layer="169" to-port="1"/>
		<edge from-layer="169" from-port="2" to-layer="171" to-port="0"/>
		<edge from-layer="170" from-port="1" to-layer="171" to-port="1"/>
		<edge from-layer="171" from-port="2" to-layer="172" to-port="0"/>
		<edge from-layer="172" from-port="1" to-layer="174" to-port="0"/>
		<edge from-layer="173" from-port="1" to-layer="174" to-port="1"/>
		<edge from-layer="174" from-port="2" to-layer="176" to-port="0"/>
		<edge from-layer="175" from-port="1" to-layer="176" to-port="1"/>
		<edge from-layer="142" from-port="2" to-layer="178" to-port="0"/>
		<edge from-layer="176" from-port="2" to-layer="178" to-port="1"/>
		<edge from-layer="177" from-port="1" to-layer="178" to-port="2"/>
	</edges>
	<meta_data>
		<MO_version value="2019.3.0-227-g3a4f9de20"/>
		<cli_parameters>
			<blobs_as_inputs value="False"/>
			<caffe_parser_path value="DIR"/>
			<data_type value="FP32"/>
			<disable_nhwc_to_nchw value="False"/>
			<disable_omitting_optional value="False"/>
			<disable_resnet_optimization value="False"/>
			<enable_concat_optimization value="False"/>
			<enable_flattening_nested_params value="False"/>
			<enable_ssd_gluoncv value="False"/>
			<extensions value="DIR"/>
			<framework value="tf"/>
			<freeze_placeholder_with_value value="{}"/>
			<generate_experimental_IR_V10 value="False"/>
			<input value="Placeholder"/>
			<input_model value="DIR/MobileNetSSD.pb.frozen"/>
			<input_model_is_text value="False"/>
			<input_shape value="[1,300,300,3]"/>
			<k value="DIR/CustomLayersMapping.xml"/>
			<keep_quantize_ops_in_IR value="False"/>
			<keep_shape_ops value="False"/>
			<legacy_mxnet_model value="False"/>
			<log_level value="ERROR"/>
			<mean_scale_values value="{'Placeholder': {'mean': array([127.5, 127.5, 127.5]), 'scale': array([127.5])}}"/>
			<mean_values value="Placeholder[127.5,127.5,127.5]"/>
			<model_name value="vehicle-license-plate-detection-barrier-0106"/>
			<move_to_preprocess value="False"/>
			<output value="['SSD/concat_reshape_softmax/mbox_loc_final', 'SSD/concat_reshape_softmax/mbox_conf_final', 'SSD/concat_reshape_softmax/mbox_priorbox']"/>
			<output_dir value="DIR"/>
			<placeholder_shapes value="{'Placeholder': array([  1, 300, 300,   3])}"/>
			<remove_memory value="False"/>
			<remove_output_softmax value="False"/>
			<reverse_input_channels value="True"/>
			<save_params_from_nd value="False"/>
			<scale_values value="Placeholder[127.5]"/>
			<silent value="False"/>
			<steps value="False"/>
			<tensorflow_use_custom_operations_config value="DIR/MobileNetSSD.tfmo.json"/>
			<version value="False"/>
			<unset unset_cli_parameters="batch, counts, disable_fusing, disable_gfusing, finegrain_fusing, generate_deprecated_IR_V2, input_checkpoint, input_meta_graph, input_proto, input_symbol, mean_file, mean_file_offsets, nd_prefix_name, pretrained_model_name, saved_model_dir, saved_model_tags, scale, tensorboard_logdir, tensorflow_custom_layer_libraries, tensorflow_custom_operations_config_update, tensorflow_object_detection_api_pipeline_config, tensorflow_operation_patterns, tensorflow_subgraph_patterns"/>
		</cli_parameters>
	</meta_data>
</net>
7.283
6.3931
2.9921
3.5123
3.2531
2.9283
2.9696
3.5729
3.4549
3.1471
3.0753
3.0574
3.0223
3.8219
2.9404
2.9366
3.0776
2.9568
3.326
3.4294
3.0192
2.9625
3.0872
3.6383
3.0416
3.5441
2.9511
2.9481
3.731
2.9924
2.9663
3.7326
3.3241
3.0996
3.239
2.9542
3.1938
3.5967
2.9863
3.1518
2.9735
2.8682
3.6234
3.085
2.9034
2.9907
3.0144
3.3271
3.4868
3.0369
3.0045
3.0943
3.5063
3.1224
3.4196
3.0009
2.9039
3.5337
3.005
2.9229
3.6072
3.0222
3.4444
3.1583
2.9917
3.0116
3.5678
3.5104
2.9895
3.1382
2.9756
3.0249
3.1681
2.8836
2.9707
3.1958
3.219
3.4351
2.9833
2.9681
2.9659
3.4281
3.1457
3.2993
3.084
2.9772
3.6382
2.9025
2.9757
3.4327
3.0373
3.4763
3.1109
2.9212
2.9475
3.5179
3.5441
3.0499
3.0943
2.9334
2.9661
3.9583
3.0253
2.885
3.1014
3.0222
3.3619
3.5333
2.9002
2.9793
3.1731
3.3
3.0171
3.6655
2.9372
3.328
3.421
2.9568
3.2154
3.043
3.4123
3.2659
2.9484
2.9537
3.4685
3.5137
3.0697
3.0663
2.9725
2.9587
3.7713
3.0148
2.9294
3.159
2.935
3.402
3.7895
3.9186
3.9971
3.7675
3.1211
3.6154
3.0075
2.9389
3.668
2.9801
2.9522
3.3511
2.9843
3.6068
3.1575
3.0235
2.9714
3.4985
3.475
2.9853
3.1956
2.919
2.9215
3.8326
3.0215
2.961
3.0977
3.0229
3.0457
3.0843
2.8843
2.9591
3.6532
3.1569
3.3201
3.0295
2.9402
3.5983
3.1143
2.9485
3.5337
2.9954
3.5651
3.2397
2.9913
2.9027
3.5317
3.6861
2.9651
3.1529
3.045
2.951
4.1051
2.9413
2.963
3.0902
3.0525
3.0942
3.0478
2.9584
3.004
3.4314
3.2059
3.3555
3.0522
2.9281
3.5776
3.0975
3.0124
3.413
2.994
3.4322
3.1028
2.9725
2.8814
3.5153
3.5649
3.1207
3.1651
2.9435
2.9985
3.7229
2.9695
2.9321
3.1967
2.9959
3.2092
3.3742
3.0083
2.9782
3.214
3.6814
2.9741
3.591
2.9761
2.9392
3.5587
2.9844
3.1414
3.0705
3.2218
3.3262
2.9334
2.9281
3.3363
3.5458
3.048
3.0393
3.0079
2.9454
4.0079
2.991
2.9658
3.0416
2.9427
3.2105
3.454
3.0895
2.9631
3.0694
3.468
3.1455
3.4605
2.9829
2.9865
3.7042
2.9906
2.9403
3.513
2.9797
3.636
3.2091
2.9949
2.9627
3.5402
3.0915
3.1447
2.9098
2.9968
3.8186
2.9829
2.9101
3.1813
2.9786
3.3725
3.4966
2.9778
2.9401
3.0632
3.4011
3.0295
3.5301
2.9307
3.1208
3.8317
3.0377
2.9049
3.5742
2.9908
3.5355
3.1651
2.9872
3.2932
3.6158
3.0238
3.0196
3.0214
2.9574
3.7938
3.1067
2.93
3.1376
2.9604
3.195
3.6517
3.4061
2.9924
3.0675
3.4927
2.9547
3.8515
2.9632
2.9705
3.7905
2.947
2.9409
3.6595
3.0811
3.0844
3.0991
2.9996
2.8651
3.5258
3.1018
3.1567
2.9407
2.8968
3.8257
3.0453
2.9843
3.0092
2.9827
3.0669
3.2261
2.9632
2.986
3.0481
3.4921
3.0789
3.3594
2.9986
2.9655
3.5387
3.0807
2.9955
3.4514
3.054
3.3586
3.1746
2.9708
3.1223
3.4234
3.8524
2.9912
3.1126
3.0449
2.9473
3.9727
2.9611
3.0655
3.1525
3.0815
2.9389
3.0184
2.9137
2.9946
3.6721
3.1335
3.4136
2.9781
2.9101
3.5751
3.1413
2.9392
3.4788
2.9474
3.4433
3.3294
2.9253
2.9782
3.5827
3.6911
2.9585
3.1188
2.9654
2.9751
3.8722
2.9508
2.9375
3.1269
2.8991
3.2259
3.5059
2.9835
2.9508
3.3901
3.3887
3.3021
3.0781
3.0418
3.3889
3.2298
2.9121
3.4129
3.0585
3.4987
3.3281
2.9361
2.9119
3.3961
3.5758
3.0217
3.1814
2.9179
2.9495
3.9646
2.972
2.9821
3.1523
3.1149
3.3264
3.5178
2.9265
2.9536
3.0961
3.8385
2.9404
3.9433
3.755
4.0315
2.9128
2.9758
3.4789
2.9447
3.4354
3.1571
2.956
3.0089
3.6185
3.1151
3.1043
2.9895
2.9974
3.7765
3.0385
2.9524
3.0848
2.9418
3.4683
3.4394
3.0233
2.9531
3.0174
3.5204
3.0628
3.346
2.9662
2.9582
3.7139
3.0143
2.98
3.4539
2.9167
3.5125
3.1833
2.9916
2.9982
3.4537
3.4655
2.9358
3.0943
2.9689
2.9077
3.8534
2.9334
2.9291
3.1648
2.9822
3.0706
3.1595
2.9638
2.9346
3.5719
3.2103
3.4563
3.0051
2.9074
3.6039
3.0553
2.926
3.3744
3.0329
3.4065
3.1559
2.8969
2.9113
3.4074
3.5628
3.1666
3.0263
2.9814
2.9519
3.6729
2.9286
2.9382
3.1868
2.933
3.3814
3.5455
2.9962
2.945
3.1337
3.3603
2.93
3.3515
2.9311
2.9872
3.5618
2.9173
2.9784
3.4395
2.9579
3.6208
3.0947
2.9756
2.9647
3.5681
3.5238
3.0123
3.0865
2.9922
3.0993
3.1728
2.975
2.9451
3.0752
3.1885
3.4266
3.0648
2.9571
2.9507
3.6842
3.0358
3.4927
3.0487
2.9828
3.6758
3.0616
2.9577
3.3756
3.0057
3.5153
3.1621
2.9171
2.9457
3.5803
3.716
2.9391
3.153
2.9971
2.849
4.0127
2.9924
3.047
3.1468
3.0019
2.9869
3.1461
3.0299
3.0019
3.6014
3.1939
3.5956
3.0133
3.1016
3.5424
3.0827
2.9133
3.326
3.0899
3.4234
3.3122
2.9777
2.9873
3.4097
3.5757
2.9115
3.1974
2.9986
2.8937
4.0634
3.017
2.9594
3.1545
3.1812
2.9604
3.0802
2.9297
3.0849
3.4389
3.1905
3.3343
3.0051
2.9504
3.4923
3.1654
3.015
3.5462
2.9408
3.4646
3.3035
2.9802
2.9521
3.5285
3.5508
2.9808
3.0756
2.9028
2.9934
3.7851
2.9617
2.9
3.172
2.8981
3.2674
3.4823
2.9401
2.9339
3.1399
3.5311
2.9907
3.4946
2.9841
3.1939
3.5
3.0245
3.1794
3.0869
3.2685
3.1982
2.9993
3.1176
3.3271
3.417
3.0043
3.1586
3.0253
2.9915
3.8791
2.9794
2.9547
3.1366
2.9409
3.2288
3.3967
3.0125
2.9748
3.1953
3.6069
2.9522
3.592
3.0226
3.0005
4.3816
3.0149
3.1032
3.106
3.3131
3.3634
2.9806
2.9425
3.2931
3.5968
3.0657
3.0511
2.9058
2.9913
4.0955
3.0041
2.9355
3.1357
3.0188
3.2706
3.5014
2.9637
2.9113
3.1467
3.4722
2.9256
3.4768
2.9707
2.9239
3.5649
2.963
2.9517
3.5329
2.9504
3.4627
3.1493
2.9557
3.0253
3.7744
3.1758
3.0301
3.0489
2.8954
3.2655
3.2586
2.9424
3.0281
3.2263
3.5449
3.6035
3.0149
2.9821
3.0185
3.467
3.2131
3.5663
3.0175
3.0044
3.6124
2.906
2.9795
3.7451
4.339
4.1818
3.0134
2.9085
3.3764
3.5856
3.0185
3.2287
2.9148
2.852
3.8137
2.9402
2.9605
3.1849
2.9008
3.2765
3.5771
3.0015
2.9726
3.1165
3.434
3.0104
3.4639
3.0503
2.9784
3.9487
2.9258
3.1044
3.0729
3.3607
3.1777
3.014
2.9728
3.4446
4.3652
4.0045
3.8036
4.0712
4.5176
2.9835
3.0011
3.1034
3.1897
4.3429
4.2986
3.0109
3.197
3.5925
3.0314
3.6434
2.9555
2.9413
3.3297
2.9804
2.9747
3.6342
3.1532
3.3181
3.1138
2.968
3.1514
3.5864
3.1052
3.0286
2.9941
2.8989
3.7823
3.034
2.9974
3.055
2.9933
3.3883
3.6073
2.966
2.9418
3.0233
3.4905
3.1277
3.4383
3.0362
2.9688
3.8184
2.9185
2.9785
3.4129
2.9357
3.85
3.1371
2.9931
2.9978
4.0185
3.2296
2.9052
3.2645
3.045
3.7235
3.1817
2.8961
2.9425
3.062
3.2239
3.3183
3.0059
2.9671
2.93
3.6272
3.1417
3.3565
2.8835
3.0605
3.5893
3.0652
2.9943
3.4157
3.0297
3.5442
3.143
3.0031
3.0343
3.4799
3.6664
2.968
3.1475
2.9073
2.9578
3.8921
2.9727
2.9925
3.1568
3.2956
3.0404
3.5931
2.9715
2.9724
3.6004
3.2733
3.3587
3.0016
3.0547
3.7093
3.1608
2.9241
3.3529
2.9664
3.3625
3.33
3
2.9909
3.4526
3.64
2.953
3.1705
2.9139
2.9715
3.8982
2.9452
2.9376
3.1007
2.9038
3.2973
3.4663
2.9787
2.9914
3.0823
3.4611
3.0018
3.7377
3.02
2.8792
3.7344
3.0371
3.2993
3.0197
3.4153
3.052
3.0911
2.9637
3.4806
4.3759
2.9429
3.433
3.0656
2.9547
3.4831
2.9949
3.0064
3.6527
2.9909
3.5173
3.0528
2.954
2.916
3.7251
3.2584
2.9136
3.0841
2.9054
3.2348
3.2226
3.0143
2.977
2.9477
3.4672
3.5852
2.9842
3.1526
3.031
3.5082
3.1148
3.4001
2.9567
2.9669
3.4208
3.1325
2.9876
3.5147
2.9702
3.5125
3.0209
2.988
2.9522
3.4563
3.4986
2.9747
2.9482
2.9682
2.9054
3.9915
2.9689
3.03
3.686
3.0052
3.1039
3.749
3.0331
3.0051
3.1892
3.4945
3.6835
3.0255
2.934
3.5459
3.1079
2.9288
3.5806
3.0121
3.4527
3.0844
2.9275
2.9042
3.494
3.6328
3.013
3.2357
2.9861
3.0113
3.5561
3.0163
3.2533
3.0868
3.4774
3.2927
2.9848
2.9707
3.3937
3.5114
3.0965
3.119
3.0508
2.9808
3.8972
2.9449
2.9322
3.2293
3.0463
3.251
3.3528
2.9563
3.0052
3.1608
3.5449
3.006
3.4395
2.9254
2.9147
3.768
2.9419
2.9716
3.7098
2.9734
3.4083
3.1582
2.9211
2.9672
4.6457
4.0045
3.829
2.9427
2.9288
3.8949
2.9328
2.9592
3.1248
3.0096
3.0663
3.1047
2.9296
2.9487
3.4395
3.2213
3.3497
3.0379
3.0044
3.5343
3.125
2.9785
3.4564
3.1691
3.5752
3.2002
2.935
2.9121
3.5044
3.7879
2.9986
3.1854
2.9364
2.9635
4.2743
2.968
2.9528
3.1125
2.9737
3.0575
3.1146
3.0829
2.9715
3.4049
3.2661
3.3718
3.0095
2.9156
3.5513
3.1095
2.96
3.3463
3.027
3.5238
3.2176
2.9127
3.0035
3.3519
3.5667
3.1655
3.1563
2.9552
2.9655
4.0624
2.8745
3.0127
3.1298
2.9806
3.3034
3.402
3.0245
3.0117
3.1578
3.7298
2.909
3.1512
2.9656
3.3928
3.2159
2.9798
3.3084
3.0101
3.5051
3.312
2.9889
2.9335
3.3803
3.4928
3.1542
3.104
2.9624
2.9446
3.8258
3.0138
2.9671
3.0094
2.943
3.3069
3.5646
3.0634
2.9592
3.1059
3.5525
2.9856
3.5386
3.015
2.9149
3.8035
2.9865
2.9673
3.1505
3.2921
3.3123
3.0082
2.9308
3.2156
3.6598
3.0905
3.055
2.9623
2.9131
3.7509
2.9882
3.0149
3.1078
2.9371
3.3148
3.3414
3.0067
2.9988
3.0969
3.5183
2.9795
3.4849
2.9847
3.0181
3.6202
2.9474
2.9207
3.5738
3.0458
3.6104
3.1986
2.9768
2.942
3.8919
3.1069
2.9367
3.1292
2.9159
3.1338
3.2161
2.9694
2.966
3.1869
3.3691
3.5219
2.9965
2.9684
3.0521
3.5544
3.1116
3.413
2.9937
2.9989
3.5657
3.0788
3.0427
3.4726
2.9901
3.8143
3.1294
3.0149
2.9819
3.5721
3.2035
3.0202
3.0019
2.9313
3.6634
3.1419
2.9893
3.1103
2.9421
3.3358
3.3742
2.9663
2.9436
3.1114
3.3661
3.0712
3.4069
3.0177
2.9531
3.5858
3.0852
2.9734
3.481
2.9661
3.4386
3.1118
2.9911
3.0805
3.4367
3.831
2.9655
3.2358
2.9367
2.9725
3.9687
2.977
2.9772
3.0976
2.9409
3.0586
3.5207
2.9474
2.9906
3.3926
3.1682
3.2015
3.1204
2.9761
3.1872
3.1316
2.9736
3.2457
3.2665
3.5179
3.2965
2.9979
2.9356
3.455
3.5074
2.9927
3.1996
2.9809
3.0118
3.9649
2.9188
2.9109
3.1257
2.9506
3.2457
3.4526
2.9669
2.9913
3.02
3.588
2.9409
3.7053
2.9689
3.0643
3.4704
2.9651
2.8904
3.5438
3.2279
3.2595
3.2239
2.9279
3.2343
3.6423
3.1049
3.1197
2.9135
2.942
3.9112
3.0235
2.9689
3.0526
2.9836
3.5256
3.4242
2.888
2.9905
3.1541
3.4112
3.0283
3.6387
2.9645
2.9375
3.5105
2.9463
2.9301
3.4684
2.9998
3.5659
3.1431
2.9329
2.9625
3.6151
3.3136
2.9925
3.1596
3.0567
3.091
4.0162
3.8798
3.6674
3.3277
3.2289
2.963
2.957
3.0047
3.4155
3.231
3.2683
2.9593
2.9294
3.5098
3.1288
2.943
3.2443
2.9814
3.5033
3.1295
2.9628
2.961
3.4833
3.4291
3.1471
3.114
2.9749
2.9773
3.7837
2.9703
2.9972
3.1185
2.9928
3.162
3.4143
2.9489
2.9553
3.1729
3.4542
2.9851
3.3482
2.9249
2.9702
3.8048
3.2186
2.991
3.664
2.9651
3.5742
3.1345
3.0005
2.9635
3.833
3.1217
3.0026
3.2052
2.9368
3.6373
3.1057
2.9445
2.9354
3.1476
3.1847
3.3719
3.0015
2.8896
2.9784
3.5549
3.1524
3.43
3.0346
2.8921
3.4657
3.0723
2.9547
3.3031
2.9428
3.4186
3.2284
3.0205
2.9087
3.4874
3.3618
3.1482
3.0664
3.035
3.0082
3.705
2.9229
3.0144
3.1211
2.9485
3.3716
3.4824
2.9726
2.9363
3.1146
3.4733
2.9912
3.4552
2.9898
2.9659
3.9882
2.9725
3.0761
3.0202
3.5143
3.1859
3.0258
2.9539
3.3406
3.6597
3.0744
3.1281
3.0395
2.9615
3.5951
2.9832
2.9244
3.0994
2.9416
3.2899
3.2692
3.0524
2.9665
2.9335
3.4282
3.013
3.6121
3.0053
3.1036
3.6243
2.9716
2.9678
3.4959
3.0148
3.638
3.1182
2.9519
2.9444
3.6418
3.3647
2.939
3.1537
2.9612
2.9488
3.6922
2.9691
2.9272
3.2239
2.9618
3.0254
3.1488
2.9572
3.0192
3.6479
3.1391
3.2789
3.0396
2.9638
3.6056
3.0714
2.9507
3.3234
3.0591
3.5011
3.2782
3.0101
2.8795
3.4351
3.6084
2.9562
3.1221
2.9348
2.944
4.0176
2.9794
2.986
3.057
2.9115
3.289
3.4883
2.9792
2.9237
3.2189
3.8052
2.9759
3.538
2.9598
3.0534
3.5164
2.9418
3.0923
3.0441
3.4188
3.2535
2.9307
3.1024
3.3757
3.5326
3.1111
3.2048
2.9671
2.9668
3.8366
2.9816
2.9479
3.1636
2.9861
3.2796
3.537
2.9688
3.0119
3.1563
3.5036
2.9838
3.529
2.9855
2.9479
3.9939
2.975
3.1638
3.3849
3.4377
3.2558
2.9705
2.9047
3.3839
3.3778
3.2089
3.1293
2.9687
3.0329
3.826
3.1021
2.9546
3.2099
3.0179
3.339
3.5665
2.9224
2.912
3.1848
3.6834
2.9525
3.6583
2.8999
2.9683
3.738
2.9695
2.9057
3.0641
3.2271
3.3285
3.0487
2.9609
3.2399
3.5272
3.1111
2.9954
3.0259
2.8976
4.0586
2.9706
3.0237
3.0327
3.0046
3.364
3.388
2.9846
2.9783
3.1039
3.3784
3.1393
3.6826
3.0386
2.9585
3.8514
2.9375
2.9363
3.8161
3.2595
3.1735
3.2326
3.0365
3.1577
3.5427
3.1174
3.1089
3.0005
2.927
3.6787
3.0783
2.9652
3.1496
2.9637
3.2102
3.5525
3.8709
3.807
4.0395
3.0798
3.3087
3.0169
2.9437
3.3108
3.16
2.9863
3.3772
3.02
3.4311
3.2936
2.8665
2.9062
3.3938
3.5704
2.9889
3.2108
2.9229
2.8969
3.5918
2.9511
3.0111
3.1099
2.9579
3.3803
3.3504
2.9273
2.9657
3.1062
3.5779
3.0055
3.332
2.9732
2.9331
3.553
2.943
3.0723
3.708
2.9737
3.6835
3.1352
2.9537
2.933
3.5462
3.3192
2.9286
3.1399
2.9588
2.9627
3.1256
2.9434
2.9786
3.1723
3.2244
3.3964
3.0214
3.0014
2.9631
3.523
3.1392
3.4035
2.9426
2.9909
3.6117
3.0937
2.9216
3.3624
3.0009
3.5549
3.2818
2.8761
2.9341
3.4693
3.4383
2.9782
3.1265
2.9456
2.9133
3.7846
3.0449
2.9355
3.0823
2.9512
3.3405
3.4477
3.0131
2.9198
3.1699
3.5291
2.967
3.562
3.0045
2.9481
3.8372
2.9513
2.9905
3.0261
3.3826
3.205
2.9536
2.9526
3.4444
3.5811
3.0853
3.0781
2.9186
2.9697
3.7665
3.0403
2.9493
3.0822
2.9622
3.2776
3.348
2.9961
2.9394
3.1089
3.57
3.02
3.5545
2.9824
3.0742
3.5724
2.9402
2.9622
3.5154
2.9805
3.7337
3.1444
3.0114
3.2492
3.4956
3.1891
3.0296
2.9734
2.9438
3.9861
3.0146
2.9508
2.9069
2.9773
3.4025
3.466
2.9278
2.903
3.1845
3.4882
3.1231
3.3038
3.0278
2.907
3.6778
3.0439
2.9428
3.4096
2.9541
3.5959
3.0084
3.0051
2.9094
3.7106
3.3563
2.9666
3.1227
2.9429
2.9398
3.8805
3.0139
2.971
3.2982
2.9903
3.042
3.0891
2.9842
2.9464
3.3665
3.2232
3.3061
3.0608
2.9923
3.4477
3.1358
2.9911
3.4406
3.0319
3.5219
3.1757
2.9562
3.1484
3.3956
3.3749
2.8569
3.1193
3.0046
2.9178
3.6608
2.9879
2.9124
3.2048
2.9488
3.2661
3.3818
2.9789
3.08
3.1569
3.4679
2.997
3.5939
3.0396
2.9805
3.74
2.968
3.0224
3.3014
3.5066
3.2589
3.0271
2.9184
3.4225
3.4749
3.0768
3.0968
2.9914
2.9381
4.1175
2.9546
2.9685
3.0994
2.9686
3.3078
3.4964
2.9705
3.0429
3.1627
3.4855
2.9487
3.6444
2.9276
3.1848
3.3877
2.8976
3.0505
3.0674
3.4507
3.181
3.0049
2.9519
3.3102
3.5389
3.1195
3.0699
2.981
2.9355
4.0206
2.935
2.9836
3.1527
2.9451
3.3354
3.5509
2.9553
3.009
3.1637
3.5636
3.0023
3.4964
3.0069
2.9227
3.7508
2.9553
2.9429
3.5861
2.9764
3.5531
3.1952
2.9259
2.9214
3.9286
3.272
2.9607
3.1984
2.9803
3.7766
3.2101
2.9061
3.0953
2.9867
3.5064
3.6829
2.971
2.9854
3.1604
3.6453
3.0073
3.884
3.9761
4.3481
3.0912
2.9518
3.5339
2.9278
3.462
3.2156
2.9203
2.9048
3.5549
3.6828
2.9848
3.3229
2.9887
2.9655
3.8365
2.9505
2.943
3.1486
2.9302
3.0055
3.6438
2.9689
2.9421
3.1663
3.3254
3.003
3.0638
2.94
3.3637
3.2399
2.9226
3.4296
2.9908
3.4298
3.2839
2.9421
2.972
3.371
3.5615
3.1755
3.1657
2.985
2.9388
4.0226
2.953
2.9893
3.1229
3.0105
3.2535
3.7205
2.9798
2.966
3.0986
3.8983
3.2853
3.0273
2.9374
3.401
3.2653
2.9412
3.2938
2.9846
3.2851
3.2412
2.9785
2.9351
3.4548
3.5311
3.086
3.0998
2.987
2.9914
3.9347
3.0353
2.948
3.1249
2.9709
3.3114
3.3445
3.0168
2.9278
3.067
3.4464
3.1688
3.4381
2.9835
2.9831
3.5758
2.9278
2.9797
3.4325
2.9274
3.5468
3.198
2.97
2.944
3.5537
3.4452
2.9554
3.1508
2.9311
2.9056
3.9357
2.9694
2.9657
3.173
2.9802
3.0459
3.0764
2.9756
2.9736
3.7676
3.1144
3.5491
3.0212
3.067
3.5823
3.126
3.005
3.3842
3.0243
3.7007
3.1262
2.986
2.9648
3.5494
3.6001
2.9371
3.1277
2.9706
2.9229
3.886
2.8983
3.0103
3.1202
3.1824
3.0271
2.9683
2.95
2.9898
3.6267
3.0538
3.2855
2.9999
2.9853
3.4789
3.1307
2.9881
3.4468
3.0131
3.4745
3.2906
2.9484
2.9771
3.445
3.5587
2.899
2.9909
2.9562
3.0238
3.799
2.9725
2.9845
3.1319
2.9259
3.2325
3.4033
2.989
2.9908
3.179
3.5502
2.9323
3.4609
2.976
2.9504
3.7662
2.9739
2.9751
3.7054
2.9831
3.3094
3.1436
3.0063
2.9715
3.5541
3.1324
3.0319
2.9213
2.9345
3.9256
2.9932
2.9949
3.0798
2.9855
3.2183
3.3637
2.9855
3.0081
3.0259
3.558
3.1149
3.3622
3.0382
3.0037
3.6272
2.938
2.9386
3.6022
2.9428
3.3881
3.0887
2.9699
2.9663
3.4839
3.7119
3.0077
3.1233
2.9646
3.0302
3.8452
2.9772
2.967
3.1781
3.3108
3.2463
3.054
2.9296
2.9456
3.6134
3.0694
3.4576
3.0463
2.9005
3.6217
3.028
2.9773
3.3737
3.0232
3.6321
3.2487
3.1578
3.0285
3.5135
3.4229
2.949
3.224
2.9268
2.9445
4.0901
2.9349
2.943
3.133
2.8584
3.1933
3.594
2.9306
2.8933
3.4979
3.2239
2.9563
3.1083
2.8437
3.5058
3.2217
2.9665
3.3049
3.0138
3.2628
3.16
2.9453
2.9353
3.3192
3.5374
3.1456
3.1186
2.9658
2.9731
3.9754
2.9721
2.9584
3.1033
2.9888
3.1742
3.4413
3.0083
3.0348
3.115
3.5122
2.9714
3.3936
2.9988
2.9578
3.6151
2.9494
3.0309
3.7691
4.2581
4.003
3.0206
2.9182
3.717
3.6151
2.9837
3.1565
2.9519
2.944
4.0003
2.9819
2.9669
3.0973
2.9615
3.1753
3.6187
2.9633
2.9681
3.1754
3.4446
2.8566
3.0481
2.9679
3.4025
3.1844
2.9799
3.3282
2.9737
3.439
3.1864
2.9852
2.9267
3.2267
3.3393
3.0769
3.0948
2.8769
2.9208
3.8088
3.0327
2.9309
3.0027
2.8949
3.3288
3.4413
3.0281
2.8199
3.0561
3.3668
3.1042
3.3829
3.034
2.977
3.579
3.1168
2.9277
3.4203
3.0653
3.3824
3.1626
2.9365
2.9675
3.4156
3.638
2.9204
3.1383
2.9462
2.996
3.984
3.0113
2.9417
3.0544
2.948
3.4441
3.5615
2.9381
3.014
3.1728
3.539
3.1151
3.1293
3.0184
3.3622
3.3364
2.9255
3.403
3.0233
3.4177
3.1802
2.938
3.0179
3.3334
3.4085
3.1157
3.1364
2.9488
2.9625
3.7729
2.8843
2.9372
3.0275
2.9507
3.1405
3.3342
2.9897
2.9488
3.1418
3.2941
3.0914
3.5195
2.9922
2.9643
3.5423
3.0068
3.032
3.3685
3.0437
3.4625
3.159
2.9786
2.9627
3.5052
3.7366
3.0093
3.1446
3.007
2.9293
3.8881
2.967
3.0105
3.1409
3.0272
3.1207
3.096
2.9276
3.0122
3.5394
3.0346
3.3241
3.0568
2.9809
3.4515
3.0298
2.9229
3.3898
2.9721
3.4966
3.3514
2.9301
2.9341
3.6918
3.6599
2.9594
3.3945
3.0917
2.968
3.8941
2.997
2.9545
3.6355
3.0827
3.2049
3.0614
3.0093
3.1747
3.571
3.0938
2.947
2.8863
2.9355
3.609
3.1984
2.9392
3.0188
2.9832
3.3582
3.4586
3.0648
2.9592
3.0988
3.5392
3.3361
3.1055
2.9758
3.0078
3.4376
3.1335
2.9254
3.5439
2.9794
3.5015
3.014
2.9366
2.9476
3.5093
3.8247
2.9392
3.0447
2.9639
2.914
4.0735
2.9752
3.046
3.425
3.1518
3.2538
3.0657
2.9589
2.9975
3.4003
3.7004
3.0982
3.0993
2.916
3.532
3.0722
2.9901
3.4021
2.9759
3.555
3.0912
2.9706
2.9414
3.5552
3.5768
2.9589
3.0234
2.9126
2.9147
4.0794
2.9493
2.9845
3.0084
2.9094
3.2653
3.4899
2.9504
3.0581
2.9995
4.0513
3.0696
3.3004
3.0089
3.5053
3.0977
2.9634
3.6413
3.033
3.4002
3.2017
2.8595
2.9957
3.5209
3.5354
2.9732
2.9819
3.0007
2.9372
3.8444
2.9752
2.9634
3.0169
2.9647
3.382
3.549
2.9326
2.9655
3.1408
3.8945
3.0143
3.0634
2.9701
2.9796
3.9053
2.943
2.9363
3.6625
3.2559
2.9469
3.0847
2.9317
2.9734
3.7917
3.2191
3.0121
3.0928
2.9882
3.4459
3.1832
2.9775
2.952
3.0222
3.4675
3.4871
3.0217
2.9562
3.0618
3.437
4.2549
3.9655
3.7597
3.33
3.2122
2.9242
3.4294
3.0379
3.5349
3.2201
2.9189
2.981
3.6879
3.6711
2.9667
3.0014
2.9364
2.9116
3.8917
2.9959
2.9204
3.0402
2.9749
3.3737
3.5484
2.9563
2.9582
2.9728
3.5734
3.0516
3.1474
2.987
3.2143
3.2846
2.9925
2.9935
3.0569
3.4593
3.0737
2.9813
2.9379
3.4435
3.4554
3.0489
3.0247
2.9914
2.9917
3.8151
3.0097
2.9614
3.0179
2.9552
3.2964
3.6039
2.9415
2.964
2.9571
3.3576
3.6542
3.0502
3.0039
2.8725
3.6835
3.0001
2.9778
3.6661
3.0086
3.4728
3.0244
3.0041
2.8998
4.2788
3.1089
2.9603
2.9523
3.0803
3.4115
3.1329
2.9935
3.01
2.9586
3.2937
3.3644
3.0035
2.9955
3.0203
3.4789
3.3696
3.2045
2.9476
2.9226
3.4739
3.1335
3.047
3.5622
2.962
3.5109
3.0592
2.9845
2.9415
3.7037
3.6184
2.9128
3.0818
2.922
3.0888
4.0683
2.9649
2.9165
3.102
2.9132
3.1634
3.2262
2.9334
2.9669
3.2665
3.6202
2.9893
3.0026
2.9405
3.6184
3.1953
2.9771
3.022
2.9496
3.5583
3.604
2.9784
2.9683
3.0759
3.4407
3.0961
3.5572
2.9445
2.9516
3.7603
2.9853
2.968
3.5067
2.9731
3.5025
3.1193
2.9424
3.0499
3.8095
3.2547
2.9851
3.184
2.9513
3.3305
3.1419
2.9338
2.9997
3.0839
3.0967
3.1873
3.0081
2.9768
2.9541
3.5574
3.113
3.4158
3.051
2.9933
3.5611
3.0958
2.9849
3.7525
2.9784
3.599
3.109
2.9677
3.1236
3.453
3.5766
2.9329
3.0763
2.9897
2.9755
4.1087
2.9779
2.9955
3.1872
2.9274
3.0668
3.5773
2.9735
2.9428
3.5135
3.2462
3.0425
3.0464
2.9668
3.6629
3.1001
2.9534
3.4295
3.3127
3.3319
3.141
2.9929
2.9835
3.3922
3.4609
2.9908
3.1212
2.9524
3.056
3.9721
3.0079
2.9487
3.1424
2.9489
3.3729
3.4676
2.9092
2.9464
3.1103
3.6949
2.9564
3.1848
2.9564
3.3554
3.1322
2.9028
3.3484
3.0284
3.3953
3.1799
2.978
2.8824
3.2708
3.4802
3.1298
3.1848
2.9385
2.8977
3.6731
2.9637
2.9556
3.1325
2.8875
3.2986
3.4073
2.9856
2.895
3.1198
3.564
3.0658
3.6135
2.8901
2.9512
3.5337
2.9682
2.967
3.4874
2.9924
3.8239
3.1029
2.9656
2.9688
3.6098
3.2404
3.0131
3.1179
2.9604
2.8928
3.3261
2.9881
2.9157
3.1901
3.2649
3.2284
3.0691
2.9373
2.9885
3.5177
3.0885
3.4659
2.9972
3.0087
3.4997
3.1307
2.9676
3.339
3.0007
3.5147
3.1615
2.9494
2.9872
3.5797
3.5661
2.9787
3.0876
2.9684
2.9477
4.142
3.959
4.0204
3.0254
3.2137
3.4355
2.9631
2.9231
3.122
3.3538
3.0815
3.3329
2.9746
2.993
3.6592
2.9049
2.9482
3.8674
3.6871
3.3621
3.1722
2.9697
3.2277
3.5577
3.1356
2.9875
3.0056
2.9169
3.8779
3.1983
2.9713
3.0978
2.948
3.1784
3.4439
3.0001
2.9012
2.9405
3.5726
3.0562
3.4277
2.9152
2.933
3.5015
3.1972
3.0088
3.5198
2.9049
3.3434
3.0998
2.9294
2.9375
3.3955
3.6199
2.9528
3.0513
2.965
2.9583
4.058
2.9861
2.957
3.2186
2.9253
3.3572
3.6496
2.9114
2.9091
3.2643
3.3258
3.0236
3.028
2.9866
3.4235
3.2714
2.9517
3.3746
3.0142
3.3943
3.2263
2.9908
2.9659
3.3984
3.5312
3.0791
3.0501
3.0162
2.9549
3.6368
2.9861
2.9815
3.0324
2.9575
3.3511
3.3757
3.0013
3.0039
3.1371
3.5779
3.1256
4.0449
3.889
4.1826
3.8687
3.8442
4.1004
4.3024
4.0969
3.9497
4.2224
4.159
3.9714
4.0174
3.7483
4.1582
3.6858
3.8633
4.0006
4.0081
4.1583
3.8869
3.8951
4.2997
4.1786
3.9137
3.8729
3.7955
2.9915
2.9901
3.5447
3.0324
3.4673
3.1186
2.9632
2.9782
4.0464
3.2552
2.9617
3.0677
3.0145
3.4551
3.199
2.976
3.0453
3.027
3.1387
3.3954
2.9882
2.8177
3.0043
3.5916
3.0416
3.2824
3.0706
2.9305
3.5031
3.0995
2.9713
3.5704
3.0082
3.4536
3.2152
2.9853
3.1849
3.4524
3.7254
2.9823
3.218
2.9949
2.9944
3.9635
3.0009
2.9515
3.1183
3.0105
2.9909
3.6444
2.9393
2.994
3.2969
3.2235
2.9461
3.0301
2.9475
3.5936
3.1272
2.9563
3.4851
3.2326
3.5555
3.3219
2.988
2.9472
3.5176
3.8349
2.9987
3.289
2.9436
2.9469
3.9972
2.9814
2.9696
3.1387
3.0538
3.2118
3.1572
2.9519
2.9986
3.6687
3.0886
3.4807
2.9863
2.9446
3.4995
3.1285
3.0029
3.432
2.9945
3.5286
3.2902
2.9479
3.0575
3.4559
3.4667
2.9771
3.1856
2.9965
2.9367
3.9269
3.0453
2.967
3.1166
3.0248
3.2533
3.6167
2.9797
2.9838
3.1533
3.4932
2.9579
3.0723
3.0004
3.2951
3.4105
2.9382
3.3743
3.0418
3.4701
3.1623
2.9891
2.9444
3.2856
3.3065
3.0331
3.0777
2.9276
2.9149
3.8358
3.0762
2.9696
3.0363
2.9328
3.335
3.4888
2.9427
3.1071
3.0969
3.5886
2.9697
3.3815
2.9751
3.0148
3.5006
2.9872
2.9578
3.3905
3.0112
3.4837
3.1751
2.9523
3.0073
3.4753
3.4188
3.0279
3.1897
3.0534
2.9949
3.8067
3.001
2.9536
3.1063
3.1413
3.6402
4.0647
4.0871
3.7627
3.1895
3.0214
3.0425
2.9772
3.5693
3.0494
2.9248
3.8073
2.9766
3.5955
3.3549
2.9748
2.9343
3.387
3.6123
3.0026
3.1588
2.9194
2.9666
3.9465
2.9304
3.0152
3.0486
3.0024
3.1488
3.7718
2.9971
3.0031
3.6058
3.2039
3.2567
3.0424
2.8669
3.4065
3.166
2.9744
3.389
3.0043
3.4905
3.3014
2.9874
2.999
3.4158
3.5901
3.0433
3.0928
2.9294
2.9823
3.8689
2.996
2.994
3.1735
2.9115
3.2964
3.7062
3.0301
2.9512
3.1153
3.6149
2.9859
3.0506
3.0121
3.2414
3.2825
2.9463
3.3156
2.9503
3.3214
3.2464
3.0315
2.9904
3.4584
3.404
3.0798
3.0756
2.9924
2.9206
3.7801
2.9529
2.9235
3.1106
2.8695
3.4165
3.3094
2.9813
2.9924
3.143
3.5602
3.0793
3.5446
2.8796
3.115
3.8549
2.9992
2.9944
3.1715
3.4348
3.1815
3.0649
2.9796
3.267
3.644
3.136
3.038
2.9429
2.9787
3.902
3.8951
2.9484
3.116
2.9038
3.261
3.8588
3.6024
2.9968
3.4856
3.1742
3.2254
3.0736
2.9627
3.5448
3.1734
2.9423
3.4362
3.0339
3.5447
3.2944
2.9711
2.9886
3.485
3.6021
2.9919
3.1514
3.0222
2.9856
3.8269
2.9672
2.9737
3.1599
2.9808
3.273
3.5291
2.9784
2.9871
3.1891
3.4807
3.0061
3.0607
2.939
3.4928
3.0293
2.9887
3.4094
3.1059
3.4406
3.2809
2.9608
3.1523
3.4127
3.5881
2.952
3.0902
2.9067
2.9142
3.7993
3.0229
2.9671
3.1524
2.8989
3.3567
3.4207
2.9218
2.9525
3.1891
3.6281
2.9331
3.5873
3.0339
2.9699
3.6483
2.9053
2.9455
3.9795
3.4383
3.2169
2.9937
3.1058
3.327
3.303
3.1227
2.9937
2.9169
2.8304
3.8128
3.1504
2.8126
3.032
3.0037
3.303
3.3798
3.0148
2.9717
3.0517
3.3577
3.0641
3.3671
2.9867
3.0176
3.5478
3.1993
2.8902
3.4355
3.0296
3.455
3.195
2.9248
2.9726
3.6733
3.8471
2.9822
3.0754
2.9115
2.9289
3.2009
2.9684
2.9901
3.2199
3.0959
3.2759
3.0614
3.0039
3.0005
3.6234
3.0794
3.5873
3.073
3.3704
3.0034
3.5065
3.2478
2.952
2.9353
3.3672
3.6011
3.1826
3.144
2.9481
2.9744
3.912
3.0438
2.9452
3.1911
2.8709
3.2918
3.6056
3
2.9541
3.2618
3.5118
3.0029
3.0776
2.9676
3.5137
3.1934
2.9543
3.3612
2.945
3.4613
3.1506
2.9702
2.9655
3.787
4.7556
4.4565
4.1895
3.8359
3.157
3.0308
3.0073
3.2179
3.2973
3.4693
3.0028
3.014
3.0299
3.5213
3.0052
3.6801
4.0695
4.312
3.6104
2.9468
3.3174
3.0512
3.4824
3.271
3.0182
2.9317
3.3388
3.5697
2.9876
3.1159
2.9783
2.9826
3.7173
2.9532
2.965
3.1791
3.0791
3.2868
3.5497
3.0038
2.9681
3.1302
3.848
3.18
3.1748
2.9747
3.3646
3.2406
3.0031
3.2622
3.0318
3.4715
3.2585
3.0012
2.9891
3.4169
3.5674
3.0395
3.1837
2.9819
3.003
3.9967
2.9359
2.9875
3.152
2.9173
3.2873
3.4693
2.9963
3.0473
3.1947
3.576
2.9529
3.0852
3.0047
3.302
3.3588
2.9961
3.4351
3.1183
3.3397
3.1318
2.9465
2.9088
3.2289
3.6089
3.0972
3.0031
2.9161
2.9188
3.7931
2.9945
2.9742
3.099
2.9762
3.3548
3.4555
3.0201
2.9578
3.0984
3.808
2.9875
3.5463
2.9581
3.1219
3.6453
3.0044
2.9449
3.0433
3.2512
3.2453
2.9683
2.9887
3.3202
3.4525
3.1701
3.0548
3.009
2.9546
3.5906
3.0684
2.9504
3.1441
2.9098
3.4552
3.4835
2.9801
2.976
3.1547
3.5002
2.9211
3.4349
2.941
2.9752
3.5683
2.9542
2.966
3.5455
2.9819
3.8361
3.1519
2.9676
2.9922
3.9526
3.2585
3.0089
3.2171
2.9772
3.6506
3.2186
2.9579
3.0112
3.0173
3.3652
3.3681
2.9616
2.9748
3.0959
3.4529
3.0224
3.4252
2.9751
2.9089
3.6352
3.178
2.9811
3.5882
2.9949
3.5289
3.167
2.9731
3.2421
3.8747
3.3834
2.9985
3.183
2.9667
3.029
3.1827
2.9197
3.0361
3.0974
3.3723
3.5139
2.9688
2.9222
3.0487
3.4593
3.1515
3.4068
2.9859
2.9776
3.6428
3.0941
2.985
3.6304
3.0132
3.4844
3.1412
2.9859
2.926
3.5365
3.2946
2.9772
3.2153
2.9791
3.2632
3.1403
3.0033
2.9576
3.2293
3.373
3.4087
3.0306
2.9163
2.9594
3.5345
3.0131
3.4614
2.9979
2.9427
3.4685
3.1223
2.9217
3.4274
3.0517
3.5128
3.1472
2.9391
3.0066
3.4054
3.6828
3.0107
3.2868
2.9129
3.0085
3.9832
2.9631
2.981
3.2607
3.0311
3.0243
3.0387
2.9659
3.0274
3.665
3.1245
3.6281
2.9683
2.9881
3.5344
3.0814
2.9417
3.3909
2.9842
3.4558
3.2071
2.9685
2.98
3.5437
3.5968
2.981
3.1478
2.9862
2.9757
4.2353
2.9448
2.9711
3.1411
3.0617
2.9799
3.4882
2.9542
2.9203
3.2726
3.3411
3.1144
3.058
2.9793
3.3988
3.1594
3.0218
3.3642
2.9983
3.488
3.2559
3.0281
3.0064
3.5345
3.5114
2.9994
3.1199
2.9557
2.9617
3.8333
2.9695
2.9142
3.0689
2.9999
3.2818
3.4893
3.0129
2.9753
3.1974
3.5768
3.0167
3.1665
3.0612
3.4471
3.1374
3.016
3.488
4.0122
4.2964
3.6641
3.0167
3.2171
3.6304
3.1843
3.0072
2.9146
2.9544
3.8417
3.1037
2.9718
3.1576
2.9251
3.4385
3.3354
3.0122
2.9463
3.0591
3.5307
3.0727
3.5049
3.0014
2.958
3.7056
2.9443
2.9791
3.4846
3.0181
3.6348
3.1389
2.9477
2.9879
3.3804
3.1623
3.0903
2.9913
3.0274
3.826
2.988
3.113
2.9997
2.9062
3.1409
3.6244
2.9341
3.4396
2.9949
2.9491
3.8867
2.9421
3.0757
3.1235
3.462
3.253
2.9682
2.9933
3.3293
3.5994
3.0952
3.1053
2.9363
2.9452
3.989
2.8435
2.9855
3.1611
2.989
3.3893
3.3648
2.9416
2.9816
3.0951
3.5037
2.9979
3.3524
2.9269
3.102
3.7097
3.037
2.9301
3.526
2.9669
3.5715
3.1932
2.9002
2.934
3.917
3.2173
2.8755
3.2055
2.9266
3.7126
3.1645
2.9641
3.0543
3.0067
3.4603
3.5003
2.9512
2.8976
3.1669
3.4606
3.093
3.4424
2.97
2.9752
3.6515
2.9597
2.8733
3.3702
3.0336
3.2739
3.1721
2.9002
2.9332
3.665
3.8579
3.0999
3.5788
2.9953
3.0062
3.0893
2.9699
2.9857
3.6823
3.1344
3.0878
2.9808
2.9675
2.9948
3.5327
3.1698
3.0456
2.9698
2.9899
3.8774
3.0263
2.9548
3.0365
2.9605
3.3055
3.5276
2.9639
3.1598
2.9973
3.4327
3.0905
3.6684
3.0075
2.9172
3.5583
2.9932
3.0352
3.6421
3.0175
3.6044
3.0291
2.9766
2.9316
3.9771
3.2559
2.9769
3.1076
2.9895
3.6453
3.1622
2.968
3.256
3.1974
3.3553
3.4309
2.995
3.0196
3.0453
3.2724
3.1084
3.7726
2.9294
2.9359
3.6434
2.9163
2.9839
3.6361
2.9044
3.8648
3.0772
3.0141
2.9445
4.1556
3.25
3.0046
2.9865
2.975
3.6078
3.119
2.9619
3.0082
3.0145
3.2755
3.3247
2.9719
2.9927
2.9587
3.1843
3.0488
3.4644
3.0217
2.9776
3.3464
3.1243
2.9223
3.5609
2.9489
3.4608
3.1544
2.9768
2.9196
3.3248
3.4793
3.1538
3.0285
2.9635
2.9229
3.8073
2.9531
3.0246
3.0276
2.9623
3.3096
3.4503
2.9818
2.9738
3.093
3.4889
3.3517
3.1177
2.9393
3.0014
3.9225
2.9325
2.9528
3.6963
3.4308
3.119
2.9982
2.9886
3.2634
3.5318
3.0903
2.9997
2.9586
2.9979
3.6703
3.1796
2.9509
3.0337
2.9281
3.3226
3.3689
3.0382
2.9868
2.8565
3.4004
3.1281
3.6631
2.9978
2.9447
3.6424
2.9698
2.956
3.5324
2.9845
3.5811
2.9776
2.9362
2.9679
3.5528
3.5757
2.9776
3.0687
2.9843
3.0267
4.2617
2.9314
2.93
3.0455
2.9657
2.9707
4.4853
3.9272
3.8213
3.9095
3.4331
3.2171
3.0065
3.4034
3.2799
2.9511
3.2689
3.0167
3.4454
3.188
2.9739
2.9793
3.4621
3.4538
3.1568
3.0089
2.9553
2.9041
3.8611
2.9821
2.9271
3.0575
2.9763
3.2655
3.5603
3.0015
2.8894
2.9893
3.4479
3.1127
3.6957
2.9688
2.9623
3.5721
3.0327
2.9454
3.5823
3.0142
3.8338
3.1721
2.9618
3.4025
3.8286
3.529
2.9738
2.9726
2.9188
3.5649
3.0122
2.9458
3.3562
2.9064
3.4181
3.2521
2.9509
2.9841
3.3211
3.3855
3.1394
3.0867
2.9145
2.9987
3.9849
3.0479
2.9662
3.1443
2.9139
3.4868
3.5554
2.9694
2.9551
3.1614
3.6016
2.9644
3.543
2.9916
3.2107
3.1865
3.0086
3.1559
3.063
3.1372
3.2116
3.1171
2.9875
3.1991
3.5948
3.1114
3.146
2.9306
2.973
3.6604
3.0051
2.9528
3.1089
2.943
3.2369
3.4642
3.019
2.9526
3.1019
3.4708
3.026
3.4688
2.9749
2.9897
3.5194
2.9088
2.932
3.502
2.9684
3.4068
3.1254
2.8891
2.9443
3.4879
3.6541
3.0238
3.159
2.9478
2.9283
4.2287
2.9694
2.984
3.2178
3.065
3.1651
3.0737
2.9679
2.9706
3.1874
3.2153
3.1064
3.0466
2.9793
3.5765
3.1622
2.8922
3.4835
2.9876
3.3278
3.2284
2.953
2.9078
3.3529
2.9916
3.4944
3.2285
2.9646
2.9926
3.0417
3.3993
3.5279
3.0401
2.9581
3.1498
3.4497
3.1307
3.4726
3.0212
3.0098
3.7035
2.988
2.9838
3.8226
2.9863
3.5497
3.109
2.9937
3.2301
3.6832
3.1379
3.1049
2.9923
2.9703
3.875
3.2151
2.9325
3.0241
2.9409
3.2685
3.339
3.0659
2.9539
3.151
3.72
2.954
3.4892
3.0466
3.016
3.5533
2.9727
2.9634
3.3896
2.9493
3.5437
3.1761
3.0579
2.986
3.5317
3.5471
3.0942
3.1476
2.9455
2.8278
3.794
2.9478
2.9388
3.1175
2.9774
3.0218
3.5875
2.9741
2.8992
3.5378
3.0962
3.119
3.0234
2.9864
3.5678
3.0319
2.9674
3.4658
2.9922
3.5725
3.1814
2.939
2.9449
3.3627
3.6926
2.9654
3.162
2.8863
2.9875
3.9688
2.9996
2.9204
3.1105
2.9739
3.2457
3.4948
2.9842
2.9805
3.1784
3.7589
2.923
3.1296
2.9669
3.0887
3.3612
2.9551
3.2024
3.031
3.3333
3.2327
2.9447
2.9821
3.4001
3.6116
3.0708
3.124
2.9592
2.9729
3.7908
2.9796
2.9679
3.0919
2.9441
3.1285
3.4562
3.036
2.9277
3.1046
3.4627
3.1926
3.4545
2.9725
2.9758
3.6489
2.9098
2.9716
3.5805
2.9344
3.5597
3.1551
2.9616
2.7903
3.8282
3.2459
2.9029
3.0994
2.9837
3.2833
4.0246
3.9239
3.742
3.0162
3.085
3.738
3.0568
2.998
3.2437
3.2483
3.2492
3.1111
2.9849
3.3162
3.0966
2.9712
3.3942
3.0295
3.4903
3.2563
2.9653
2.9974
3.393
3.535
3.0741
3.1338
2.9339
3.0459
4.0107
2.9954
2.9424
3.1146
3.0048
3.2679
3.5747
2.9849
3.0074
3.1922
3.3439
2.9817
3.1784
2.9846
3.3561
3.2484
2.9524
3.3562
3.0601
3.4714
3.29
2.9514
2.9618
3.3374
3.4173
3.0569
3.137
2.9523
3.0299
3.658
3.0114
2.9444
3.0526
2.9615
3.3373
3.2107
3.0457
2.954
3.0881
3.416
3.0749
3.5289
3.0135
3.1228
3.5724
2.9274
2.9879
3.4532
2.9759
3.4962
3.1803
2.9805
2.9798
3.8285
3.3148
3.0119
3.174
3.0494
3.0385
3.1013
2.9475
2.9687
3.0995
3.153
3.3815
3.0168
2.9783
2.9671
3.5738
3.1082
3.3335
3.0159
2.9915
3.6037
3.1342
2.9295
3.4177
3.03
3.4687
3.3171
2.9606
3.0153
3.4898
3.6588
2.9666
3.1715
3.0428
2.9059
4.1548
2.9394
2.9325
3.1895
3.0101
3.2111
3.0755
2.9898
3.0002
3.561
3.2772
3.311
3.0219
2.929
3.5774
3.1604
2.9574
3.4647
3.0706
3.3196
3.2648
2.915
3.1609
3.3902
3.5643
2.9852
3.0839
3.0035
2.9904
3.8976
2.9349
2.9601
3.1773
2.971
3.2814
3.5886
3
2.918
3.1138
3.807
3.038
3.0674
2.9665
3.4097
3.0746
2.916
3.4403
3.2503
3.4969
3.2542
2.9325
2.9705
3.3987
3.4673
3.1336
3.1022
3.0058
2.967
3.9658
3.0118
2.9316
3.1538
2.9172
3.3074
3.4391
3.0096
2.9276
3.1358
3.6702
2.9344
3.615
2.986
3.0997
3.5504
2.9749
2.9084
3.0413
3.2551
3.0881
3.0041
2.9692
3.4342
3.5485
3.1508
3.2135
2.9485
2.9629
3.6819
2.9363
2.9044
3.0756
2.9284
3.3004
3.4105
2.9375
2.9712
3.0712
3.4077
3.1037
3.5284
3.0326
3.0098
3.4067
2.8769
2.9318
3.5479
3.0056
3.4484
3.1182
2.8797
2.9773
3.4727
3.8189
3.0036
3.2227
2.9545
3.0109
4.0159
2.9747
2.9213
3.1089
3.3107
3.3351
3.0295
2.9735
2.9508
3.7447
3.0917
3.4146
3.0128
2.9635
3.5757
3.5383
3.2587
2.9424
2.9355
3.3844
3.5041
3.1493
3.0495
2.9775
2.9732
3.5076
3.0159
3.03
3.0257
2.9956
3.1688
3.414
3.0438
2.9725
2.9943
3.443
3.0499
3.2867
3.0007
3.0363
3.4835
3.0735
2.9559
3.4019
2.9927
3.5292
3.0905
2.8892
2.8709
3.3864
3.7204
2.9588
3.2052
2.9487
2.9623
3.9619
2.9849
3.0408
3.115
2.9915
3.1897
3.9836
4.0317
3.911
3.4131
2.9683
3.5258
2.9911
2.9562
3.7171
2.9682
2.9343
3.5398
3.1306
3.3852
3.1358
2.968
2.9891
4.2845
3.1319
3.1165
2.9918
2.9261
3.833
3.1157
2.9516
3.0993
3.0166
3.2837
3.4976
2.9754
2.9756
3.0162
3.5463
3.1378
3.4149
3.0026
2.9526
3.7048
2.9228
2.9523
3.4388
2.9727
3.7752
3.1125
3.0136
2.9294
3.6183
3.3514
2.9474
3.0605
2.9539
3.3369
3.2045
2.9871
2.9318
3.0709
3.3134
3.3143
2.9964
2.9699
2.9796
3.7295
3.0281
3.6247
2.9974
3.1107
3.6176
3.1645
2.9591
3.4701
3.0311
3.5313
3.1264
2.9271
2.9561
3.4753
3.5094
2.9488
3.1244
2.9333
2.9664
3.9675
2.9951
3.0162
3.2213
3.0607
3.4567
3.0643
2.9539
2.9723
3.7909
3.134
3.4127
3.0027
2.9694
3.6536
3.0022
3.0319
3.4888
2.9828
3.2951
3.3007
2.9836
2.9467
3.429
3.5317
2.9744
3.1798
2.9254
2.9393
3.8833
3.0454
2.9657
3.1714
3.0016
3.1785
3.5828
3.004
2.9775
3.1518
3.3278
3.0384
3.0353
2.9355
3.2352
3.2649
2.8971
3.3237
3.0578
3.3956
3.2999
2.9488
2.9135
3.2121
3.4976
3.103
3.0123
2.948
2.9639
3.7462
2.9368
2.9673
3.1029
2.915
3.2893
3.471
3.0077
2.9328
3.0272
3.3851
3.1284
3.5764
3.0276
2.9652
3.5604
2.9608
3.0316
3.8977
3.006
3.6506
3.153
3.0013
2.9775
3.5246
3.0724
2.9875
2.903
2.9916
3.6396
3.1257
2.9421
3.0748
2.9977
3.1876
3.5646
2.9956
3.0028
3.0116
3.4785
3.1007
3.4658
3.0068
2.9519
3.6672
3.0264
2.9439
3.433
2.9815
3.5484
3.0977
2.9627
2.9604
3.5294
3.6557
2.915
3.2317
2.946
2.9569
4.0407
3.0049
2.963
3.1078
3.3233
3.3844
3.1113
2.9522
2.9958
3.5598
3.0875
3.4648
3.014
2.9763
3.6401
3.1276
2.9628
3.5097
2.9767
3.8035
3.1719
3.1284
2.9873
3.4474
3.6496
3.0108
3.1929
3.026
3.0323
3.7789
2.9305
3.0039
3.1942
2.9892
3.2099
3.0559
2.9754
2.9861
3.5426
3.1845
3.2998
2.9768
2.9885
3.3569
3.1448
2.913
3.3611
3.04
3.5038
3.272
2.925
3.0008
3.5994
3.3003
3.0357
3.1488
2.9955
2.9704
3.8003
2.9702
2.9344
3.0763
2.9298
3.3629
3.4331
3.005
2.9467
3.1745
3.6081
2.9631
3.5461
2.9552
2.9918
3.7776
2.9669
2.9764
3.1308
3.4709
3.3152
2.9494
2.8769
3.4248
3.5276
3.1192
3.0561
2.9231
2.863
3.6727
3.0422
2.9624
3.0982
2.9741
3.2455
3.4216
2.99
2.9934
3.1516
3.5293
3.1251
3.72
3.8953
4.4398
3.2879
2.9773
3.3059
3.0273
3.5216
3.2371
2.9497
2.9754
3.4059
3.5758
2.9707
3.1197
2.9815
2.9826
4.0067
2.9015
2.9959
3.0588
2.9262
3.2812
3.6248
2.9491
3.0056
3.0961
3.5362
2.9779
3.6416
2.9984
3.0121
3.3661
2.9177
3.013
3.0221
3.4748
3.2627
2.9399
3.041
3.3323
3.4148
3.1412
3.0923
2.8869
2.9243
3.6941
3.3354
3.6881
2.9464
2.9835
3.1063
3.4181
3.0617
3.3189
3.0236
2.9571
3.5826
3.1415
2.9718
3.686
4.3453
3.2883
3.1983
2.9019
3.5497
3.5349
3.1075
3.124
3.0864
2.8242
3.7305
3.0487
2.9605
3.4487
3.6103
3.3146
3.4107
2.9985
2.9966
3.1338
3.8458
3.0185
3.0775
2.9608
3.2684
3.3383
3.0367
3.2588
3.0373
3.3686
3.1611
2.9749
2.904
3.5059
3.3392
3.1686
3.0632
2.873
2.9433
3.7761
2.9611
2.9916
3.0774
2.9717
3.2881
3.4254
2.9826
2.9299
3.1278
3.5713
3.109
3.464
2.9859
2.9532
3.758
2.953
2.9087
3.544
2.9983
3.6359
3.2221
2.9922
3.1069
3.6092
3.102
3.0692
2.8802
3.0207
3.8783
3.166
2.9025
3.2036
2.9758
3.355
3.3851
3.003
3.0415
3.0959
3.498
3.1025
3.4187
2.9401
2.9318
3.8587
2.9616
2.921
3.8162
2.9999
3.5618
3.1964
2.9272
3.1407
3.5148
3.1256
3.0874
2.9316
2.9426
4.0436
3.2562
2.9829
3.1725
2.9743
3.3272
3.4328
2.929
2.9216
3.1794
3.4078
3.0894
3.5708
3.0552
2.9989
3.917
3.0096
3.0106
3.1454
3.3785
3.2409
3.0514
2.9817
3.3978
3.5677
3.1826
3.1576
2.9932
2.9777
3.7314
2.9945
2.9273
3.016
2.9916
3.3437
3.4688
2.9744
2.9806
3.1689
3.7073
2.9555
3.5012
2.9885
3.0009
3.9957
2.9266
2.9894
3.1226
3.6242
3.1878
2.9509
3.0053
3.4209
3.4796
3.0819
3.1652
2.9859
3.0058
3.9405
2.9676
2.9678
3.2011
2.9769
3.234
3.5215
3.0481
2.983
3.1254
3.8071
3.0528
3.5659
2.9667
3.0181
3.5767
3.0201
2.9493
3.0437
3.3181
3.2034
3.0119
2.9806
3.5353
3.5267
3.1749
3.181
3.1189
2.9527
4.0232
3.047
2.8923
3.1101
2.978
3.349
3.3909
2.974
2.9664
3.2138
3.8422
3.0195
3.4881
3.0476
2.9955
3.445
2.9935
2.9941
3.0988
3.2562
3.258
2.9753
3.1015
3.3362
3.5062
3.0312
3.1726
3.0027
2.9822
3.7652
3.0131
2.9869
3.1407
3.0146
3.3089
3.7542
2.9562
3.0093
3.2112
3.8634
3.0437
3.5244
2.9806
3.0308
3.413
2.9923
2.9882
3.9997
4.4045
3.6712
3.0046
3.1751
3.6134
3.1827
3.0781
2.9992
3.0758
3.7995
3.0108
3.0699
3.0947
2.9507
3.1906
3.396
3.0102
3.0104
3.1194
3.4615
3.1294
3.3687
3.0101
2.9426
3.6526
2.9876
2.998
3.5295
2.9715
3.5034
3.1779
2.9699
2.9854
4.166
3.2418
2.9975
3.1541
3.0022
3.4186
3.1887
2.9311
3.0227
3.1803
3.128
3.4259
2.9828
3.0361
2.9507
3.3082
3.1665
3.3113
3.0576
2.9697
3.5596
3.1357
2.9774
3.3951
3.0038
3.4027
3.381
2.9828
2.9456
3.5456
3.7393
2.9712
3.149
2.9722
2.9475
4.2576
3.0408
2.9277
3.142
3.0049
3.1278
3.0629
2.9748
2.9932
3.5513
3.187
3.421
3.0441
2.9918
3.5857
3.182
2.9962
3.347
3.0432
3.5499
3.1213
2.9665
2.959
3.4902
3.7025
3.0143
3.6665
3.1045
3.0608
3.4028
3.0163
3.2951
3.1447
3.3782
3.2455
2.9964
2.9144
3.4766
3.7121
3.1463
3.0428
2.9991
2.9987
3.8457
2.9607
2.9762
3.0193
2.9549
3.2353
3.555
2.9849
3.1478
3.0753
3.6113
3.0287
3.6734
3.0091
3.3074
3.4448
2.9566
2.9368
3.0881
3.4542
3.1595
3.0057
3.0022
3.4873
3.4395
3.1208
3.0296
2.9984
2.982
3.9116
3.0227
2.9746
3.5916
2.9056
3.3301
3.5255
3.1566
3.4513
2.9682
3.0076
3.5946
3.1351
2.9133
3.5463
3.037
3.7304
3.0683
3.0195
2.9939
3.7917
3.223
3.065
3.2134
3.032
3.0372
3.3976
2.9826
3.0255
3.0042
3.2761
3.1855
2.9934
2.9447
3.4004
3.5897
3.1369
3.1425
3.0209
2.9647
3.933
3.0119
2.9726
3.2496
2.9893
3.3184
3.3685
3.0292
3.033
3.177
3.67
2.9873
3.6779
2.9991
2.9435
3.5701
2.9603
3.0025
3.063
3.4028
3.3019
2.9716
2.958
3.437
3.5607
3.0571
3.1268
2.9939
2.9358
3.6532
3.0707
2.935
3.0542
3.0205
3.4876
3.4944
3.043
2.959
3.1901
3.4375
3.0009
3.4021
2.9407
2.9575
3.6823
3.0279
2.9795
3.684
3.0647
3.5776
3.1502
3.0058
3.191
3.2868
3.2065
3.0903
2.9768
3.0163
3.8566
2.9892
2.9927
3.106
3.0402
3.414
3.3872
2.9805
2.9572
3.0512
3.4132
3.0519
3.395
3.0207
2.9727
3.6187
2.9544
2.9838
3.5338
2.997
3.7475
3.086
2.9767
3.0093
3.6308
3.2581
3.0446
3.1736
2.9749
3.4106
3.2179
3.018
3.0322
3.017
3.1396
3.5042
3.0363
2.9608
3.0702
3.555
3.1258
3.6013
3.0222
2.9783
3.6397
3.0274
2.9464
3.4619
3.0135
3.4762
3.201
3.0234
3.0143
3.952
4.2204
4.0089
3.0306
3.0267
3.791
3.0017
2.9563
3.1489
2.9413
3.3195
3.428
2.9831
2.9842
3.119
3.4722
2.9874
3.6099
3.0243
3.2691
3.6822
3.0139
3.1961
3.0842
3.4741
3.2868
2.9889
3.0189
3.5137
3.4847
3.1345
3.1276
2.9734
2.912
3.7261
3.0361
2.9453
3.1304
2.9995
3.2402
3.4659
3.0513
2.9523
3.1608
3.7455
2.9826
3.5995
2.9258
3.1886
3.5237
2.9564
3.1764
3.062
3.5486
3.2676
2.9665
3.0085
3.4717
3.4958
3.1442
3.2326
2.9961
3.0323
3.8708
2.9502
2.982
3.1508
2.9648
3.2882
3.4707
3.0689
2.9414
3.1868
3.737
2.9669
3.0247
3.0361
3.2432
3.281
2.9649
3.2131
3.0819
3.5834
3.3101
3.0258
2.9813
3.4969
3.5134
3.1197
3.1437
2.997
3.0008
3.8174
3.0412
3.0124
3.2011
2.9743
3.4284
3.5497
2.9789
3.1682
3.2441
3.3106
3.028
3.2128
3.0366
3.4523
3.2158
2.9903
3.6459
3.0651
3.3921
3.3447
2.977
3.1714
3.425
3.5792
2.9421
3.2155
3.0075
3.0061
4.078
3.0433
2.9757
3.1867
2.9608
3.0517
3.508
3.0146
2.9966
3.3334
3.2192
3.1967
3.1137
2.9989
3.5713
3.1225
3.0494
3.5565
3.0339
3.5417
3.1595
3.0085
2.9983
3.3681
3.5705
2.957
3.2194
2.9881
2.9394
3.8631
3.0059
3.0452
3.1451
3.0023
3.0487
3.6557
2.9234
2.9422
3.5253
3.0864
3.282
3.0527
2.957
3.6142
3.1631
3.0135
3.4278
3.013
3.5114
3.2884
2.959
2.9572
3.6592
3.5968
2.988
3.0687
2.9131
2.9955
3.8869
2.9608
2.963
3.1848
2.9565
3.4682
3.5052
3.0214
2.981
3.3575
3.327
3.2697
3.0756
2.9748
3.5845
3.1535
2.9427
3.493
3.0493
3.5142
3.2973
3.0107
2.9916
3.4148
3.513
2.9864
3.2312
2.9859
2.9924
3.9756
3.0552
3.0036
3.1924
3.0153
3.0487
3.593
3.0225
3.0116
3.7232
3.2498
3.4306
3.0432
2.9821
3.3387
3.1732
2.9928
3.3051
2.9944
3.4946
3.285
2.9466
2.9849
3.5878
3.5908
3.0261
3.1669
2.9949
2.9892
3.9385
2.994
2.9978
3.1684
3.0126
3.1335
3.585
3.2574
3.395
3.1579
3.0033
3.7908
3.1718
3.0217
3.5088
3.0466
3.5183
3.1961
3.0083
3.0194
3.4486
3.7916
2.9795
3.1851
3.0547
3.3388
3.2626
2.93
2.9844
3.185
3.2765
3.4642
3.0231
2.9701
3.0741
3.4025
3.1364
3.444
3.0827
2.9548
3.5621
3.1448
2.9472
3.6182
3.0661
3.6809
3.1707
2.9338
3.0344
3.7098
3.3483
2.9909
3.2337
2.9789
3.417
4.0126
3.8912
3.7107
3.0187
3.2081
3.0925
3.0127
2.9837
3.6035
3.2313
3.3929
3.0187
3.0789
3.5695
3.1641
2.9764
3.3409
3.0535
3.5187
3.3211
2.9859
2.9909
3.53
3.5163
2.9736
3.1473
3.1047
2.9323
3.8144
2.9766
2.9765
3.2348
2.958
3.212
3.1613
2.9736
2.9712
3.5641
3.2526
3.4316
3.0348
3.0074
3.4447
3.1215
2.9031
3.3914
3.0303
3.5865
3.2583
3.008
3.0231
3.4235
3.6247
2.9826
3.1851
2.9972
3.0945
4.1329
2.9643
2.9968
3.1784
3.3373
3.2311
3.1731
3.0097
3.0163
3.4884
3.1241
3.6822
4.0669
3.9905
3.4775
2.9461
3.1644
3.0338
3.5274
3.2788
2.9464
2.9618
3.4665
3.6191
3.1446
3.1666
3.0073
2.9809
3.8697
2.9784
2.9557
3.1461
2.9437
3.3698
3.4611
2.9911
2.999
3.1914
3.46
2.9574
3.6922
3.0192
3.2647
3.4119
2.9733
2.9749
3.134
3.4302
3.323
3.0332
2.9534
3.3835
3.5447
2.9724
3.1741
3.0222
3.0058
3.9348
3.0354
3.0303
3.1784
2.9843
3.4341
3.5636
2.9929
3.0029
3.2156
3.5236
3.0566
3.1192
2.9766
3.7163
3.0115
2.9983
3.5255
3.0362
3.5358
3.263
3.0121
2.9383
3.4716
3.6293
3.0065
3.1654
2.9477
2.9604
4.0749
2.9397
3.0588
3.131
3.0835
3.1459
3.0511
3.0218
3.0133
3.5909
3.1343
3.6454
2.9603
2.9929
3.6753
3.0312
3.0228
3.4752
3.0101
3.5441
3.2046
2.957
2.9399
3.8191
3.3673
3.0133
3.1797
2.9604
3.0599
3.1824
2.9505
2.9665
3.1068
3.1108
3.4445
3.0272
2.993
2.9602
3.449
3.1586
3.5942
3.0186
3.014
3.6649
2.9731
2.9637
3.4329
3.0159
3.4848
3.1726
2.9673
2.9859
3.6158
3.551
3.0963
3.1797
2.9747
3.604
3.163
2.9268
3.0345
3.0657
3.1378
3.4408
3.0961
2.9557
3.0075
3.4106
3.1667
3.3713
3.007
2.9849
3.6746
3.1933
3.0074
3.4494
2.9547
3.5921
3.1174
3.0004
2.99
3.8626
3.3918
3.0875
3.147
2.9949
3.0001
3.3421
3.0151
2.9873
3.0123
3.3647
3.6064
2.935
2.9897
3.2019
3.549
3.1289
3.5144
2.9931
3.0449
3.683
3.0545
2.9932
3.6383
3.0362
3.6738
3.2228
3.0325
2.9724
3.6348
3.0961
3.1367
2.9428
2.9137
3.7151
3.0446
2.9953
3.1024
2.9701
3.2665
3.4719
2.9762
2.9532
3.1371
3.5196
2.9579
3.4417
3.0457
3.0042
3.5932
3.0073
3.0018
3.6663
3.041
3.6395
3.2
3.0089
3.0313
3.5759
3.1761
2.9814
3.0079
2.9539
3.8234
3.1296
2.9412
3.1459
2.9856
3.2696
3.6382
3.9165
3.9274
4.1205
3.1618
3.5039
3.0305
3.015
3.6489
3.1625
3.0322
3.496
2.9693
3.543
3.2229
2.9614
2.9777
3.7289
3.2882
2.9759
3.1674
3.0148
3.0976
3.1923
3.0407
2.9803
3.1681
3.3493
3.4318
3.0588
2.9846
3.1146
3.5977
3.151
3.467
3.0012
2.9916
3.6634
3.0205
2.9208
3.4649
2.9772
3.5369
3.2248
3.0578
3.0073
3.4563
3.4546
3.0825
3.1684
3.045
3.7358
3.2889
2.9966
3.0377
3.0064
3.6525
3.4296
3.0412
2.9714
3.2108
3.5823
2.9743
3.4094
3.0311
2.9933
3.6519
2.9881
2.9417
3.4093
3.025
3.6152
3.1573
3.1182
2.9553
4.1688
3.1354
3.0047
3.0583
2.9778
3.7086
3.146
3.0169
2.9997
3.0293
3.3786
3.5576
2.9907
2.9593
3.0236
3.5339
3.0743
3.4125
3.0558
2.9945
3.4179
3.0376
2.9913
3.5368
2.9702
3.462
3.1307
2.9678
3.1639
3.5331
3.5425
3.0071
3.2036
3.0094
3.0332
3.2681
3.0243
3.0834
3.0253
3.3527
3.3922
2.9825
3.0166
3.2468
3.4956
3.0706
3.3949
2.9697
2.979
3.6667
3.0059
3.0318
3.8014
3.09
3.4677
3.1869
2.9721
2.99
3.5022
3.1442
3.0153
3.0318
2.9217
3.7371
3.1833
2.9321
3.0824
2.9695
3.3559
3.4192
3.054
2.9677
3.1665
3.4521
3.1463
3.6156
3.0516
3.0681
3.9661
3.0668
2.978
3.1795
3.2021
3.1651
3.1125
2.9865
3.3607
3.5679
3.1597
3.014
2.985
2.9766
3.8143
2.9484
2.9518
3.1128
2.9558
3.1274
3.4151
3.0457
3.0201
3.1699
3.4296
3.2313
3.6441
2.9673
3.0426
3.6777
3.0265
2.9952
3.5645
3.0421
3.38
3.1914
2.9959
3.2956
3.4291
3.1635
3.0047
2.9772
3.0711
3.7438
3.1506
3.0204
3.1785
2.9571
3.2784
3.7031
2.9826
3.0221
3.1768
3.5682
2.9935
3.6065
3.0272
2.9611
3.7592
3.0287
3.0368
3.0245
3.3473
3.4042
2.9702
2.9775
3.6347
3.4834
3.2058
3.1554
2.998
3.0421
3.7301
3.0534
3.0171
3.1545
3.0256
3.3509
3.4889
2.9948
2.9776
3.0879
3.8125
3.0974
3.1197
3.0589
3.3677
3.0822
2.9877
3.3549
3.0941
3.471
3.329
3.0014
3.0088
3.4127
3.6331
3.0527
3.0761
2.961
3.0338
3.725
3.0349
2.952
3.1783
2.9682
3.303
3.7104
3.0079
2.8606
3.2227
3.2648
2.9694
3.1091
3.0268
3.5851
3.178
2.9882
3.4055
3.0172
3.5022
3.2798
2.9751
2.9868
3.4204
3.6073
2.9888
3.1778
3.0045
3.0294
4.0671
3.0473
2.9393
3.2424
3.0027
3.138
3.1073
3.0005
3.0202
3.6445
3.2423
3.5109
4.0265
4.2699
3.6557
2.987
3.239
3.1164
3.3932
3.2823
2.9997
3.0004
3.5672
3.5325
3.0076
3.1742
3.0364
2.9938
3.8491
3.0178
2.9971
3.22
2.9756
3.4813
3.6685
2.9852
3.0028
3.2554
3.2941
3.1838
3.0426
3.0318
3.7537
3.0999
3.0204
3.4425
2.9813
3.4255
3.3454
2.971
3.0651
3.555
3.5532
2.9799
3.1848
3.0016
3.0443
4.2059
2.9815
3.0137
3.1663
3.1105
3.1308
3.0174
2.9898
2.9643
3.6542
3.2094
3.4585
3.0651
2.9681
3.6166
3.1083
2.9759
3.3455
3.0364
3.416
3.1509
2.9538
2.9703
3.5516
3.6301
2.96
3.1537
3.0439
3.0435
3.9238
2.9161
2.9964
3.1529
3.0749
2.9995
3.8085
3.0215
2.9809
3.7268
3.1347
3.3436
2.9712
2.9057
3.6105
3.1861
2.9887
3.7037
3.0101
3.5365
3.1976
3.0242
3.2172
3.4453
3.4391
3.0006
3.0953
2.9714
2.9888
3.9117
2.9303
2.9396
3.1683
3.0389
3.048
3.5626
3.0012
3.0539
3.3036
3.2535
3.2419
3.0644
2.9451
3.6402
2.9893
3.0528
3.5648
3.1184
3.5772
3.1728
3.0039
3.004
3.5048
3.5774
2.9154
3.1129
2.9936
2.9819
4.1087
2.985
2.9864
3.2831
3.1004
3.1699
3.0709
2.9903
2.9729
3.5685
3.1771
3.3955
3.0472
2.9818
3.4724
3.1044
2.9914
3.4195
3.0421
3.5799
3.6292
2.9867
3.1961
3.0023
2.9473
3.7055
2.9773
2.9757
3.1303
3.0716
3.4152
3.9046
3.0034
3.0262
3.117
3.472
3.0209
3.5587
2.955
3.1795
3.2766
2.988
3.0471
3.0479
3.594
3.2696
2.9948
2.9896
3.4837
3.5761
3.0143
3.2157
2.9549
2.9806
3.8896
3.0322
3.0966
3.1196
2.9998
3.4501
3.1523
2.9709
3.0145
3.6732
3.2534
3.3951
2.9984
3.0189
3.6616
3.1241
2.9234
3.4261
3.0144
3.4306
3.3085
3.0378
2.9486
3.6124
3.8509
2.9858
3.1669
3.0239
3.2736
3.1893
2.9726
3.0852
3.0657
3.2377
3.3633
3.1127
3.0176
2.9806
3.4654
3.0989
3.3718
3.0377
2.9851
3.6215
3.0797
3.0141
3.4876
2.9596
3.4209
3.2248
2.9174
2.961
3.4482
3.5615
3.041
3.0972
2.9971
2.9389
3.8062
2.9872
3.0204
3.1883
3.1147
3.7316
3.1187
2.9396
3.0315
3.8016
3.2031
3.4296
3.0296
3.0355
3.6395
3.2113
2.9635
3.5234
3.0295
3.6609
3.1983
2.9965
2.9511
3.7463
3.3287
2.9675
3.2243
3.0133
3.4589
3.169
2.9793
2.9794
3.0049
3.365
3.3927
3.0427
3.0271
3.0129
3.664
3.1391
3.5104
3.0526
2.9315
3.7169
3.0297
2.9814
3.7927
4.278
4.2138
3.007
3.0184
3.4219
3.4441
2.999
3.2021
3.0124
2.9409
3.863
3.0102
2.9517
3.2679
2.9543
3.458
3.5207
2.9817
3.007
3.0252
3.5041
3.0432
3.0549
3.053
3.5633
3.1596
3.0402
3.4078
3.0151
3.5601
3.3653
3.0751
2.9746
3.4191
3.5906
2.9826
3.1267
2.9198
3.0289
3.9447
3.0361
3.07
3.1902
3.0514
3.2316
3.6624
2.99
2.9775
3.6215
3.2855
3.2609
3.0633
2.9367
3.6502
3.1536
2.9934
3.4895
3.0702
3.536
3.28
2.9789
2.979
3.571
3.6051
3.0229
3.5971
3.1962
3.0902
3.3478
2.9624
2.9519
3.3184
3.4904
3.2065
3.0252
2.965
3.4073
3.3734
3.169
3.0902
2.9928
2.986
3.8315
3.0984
3.0024
3.0595
2.9452
3.4428
3.5662
3.0557
3.1909
3.0528
3.5879
2.9213
3.6868
2.9625
3.0177
3.4332
2.9601
2.9823
3.0953
3.6229
3.1993
2.9855
2.9774
3.5253
3.6073
3.0373
3.0885
2.9913
2.9777
3.9433
3.0277
2.9504
3.8325
3.1038
3.0434
3.1132
3.0375
2.9758
3.5258
3.1652
3.4554
2.9872
3.0109
3.6884
3.1226
3.017
3.5873
2.9631
3.4537
3.0575
2.9599
3.0418
3.7089
3.454
3.0129
3.0157
2.9977
3.4588
3.2545
2.9665
3.0102
2.9429
3.2784
3.4277
3.0315
2.9839
3.0735
3.449
3.147
3.5665
3.0022
2.9238
3.3815
3.0864
2.9506
3.5697
3.0121
3.4719
3.0096
2.9752
2.9737
3.5329
3.5241
3.0184
3.0113
2.9446
3.0264
4.078
3.0433
2.9737
3.0618
3.3062
3.0946
3.0749
2.991
2.9527
3.3946
3.1525
3.5464
3.0098
2.9482
3.5583
3.0848
2.9601
3.4625
3.0035
3.6346
3.0646
3.0095
2.9795
3.4704
3.433
2.8418
3.1545
3.0053
2.9806
4.0696
3.011
2.9646
3.144
2.9939
3.2913
3.5203
2.99
3.0251
3.2794
3.4335
2.9595
3.1445
3.0113
3.3508
3.1258
3.0069
3.4413
3.0116
3.5456
3.1243
2.9366
3.0157
3.6057
3.6274
3.0079
3.0668
2.9353
3.0269
4.5281
4.2765
3.0718
2.9676
3.399
3.5252
2.9906
2.9247
3.0247
3.7105
3.1449
3.501
2.9792
3.026
3.6529
3.0276
2.9798
3.7854
2.9827
3.0594
3.9077
3.2407
2.9703
3.0383
2.9595
3.9887
3.0005
3.0006
3.0793
2.9631
3.5857
3.5787
3.0178
2.8868
3.0996
3.7099
2.9971
3.6404
3.0394
3.3334
3.5877
2.9678
3.211
3.0971
3.7371
3.2217
2.9717
2.9167
3.7464
3.9011
3.0869
3.0648
2.9963
2.9763
4.3286
3.0247
3.0389
3.0765
3.064
3.4872
3.8785
3.8002
3.9475
3.645
3.1828
3.1568
2.9707
3.6683
3.0748
2.9938
3.4666
3.0566
3.7607
3.0411
2.9857
3.0011
3.5376
4.0447
2.9956
3.1661
2.9566
3.1622
3.2808
2.9798
3.1113
2.965
3.7509
3.4828
2.9862
2.9127
3.0334
3.744
3.0379
3.4989
2.9817
3.0096
3.9148
2.9864
2.9604
3.5999
3.5927
3.1527
3.024
2.9168
3.2699
3.7003
3.199
3.0509
3.051
2.9797
4.4
2.9906
2.9633
3.0351
3.0455
3.5047
3.6254
3.0775
2.9897
3.0963
3.7797
3.0991
3.0485
2.9398
3.5193
3.0764
3.0709
3.6007
3.0864
3.8451
3.1738
2.9448
2.9653
3.4846
4.5891
3.0351
3.127
3.0577
3.6794
3.9263
2.9377
3.053
2.9128
3.9196
3.8084
3.0302
3.1265
3.0046
4.4324
3.2606
3.0835
3.0153
3.9125
3.3781
2.9584
3.4545
3.0148
4.0052
3.1262
2.9914
3.0226
3.7009
3.0433
3.0324
3.0616
2.9472
3.292
3.647
3.7617
2.9902
3.0263
3.7607
3.7392
2.9718
2.9717
2.9958
4.2107
3.213
3.1071
2.9883
3.6531
3.1124
2.9479
3.5714
3.028
3.8557
3.1599
3.0363
2.9752
3.9426
4.4392
3.2878
3.1351
2.9841
4.1495
3.2367
2.9674
3.3502
3.0215
3.9357
3.183
2.9977
2.9831
3.7464
3.124
3.1964
3.0358
3.0035
4.1973
3.1959
3.0027
3.2094
2.9822
4.2874
3.1573
3.0583
2.9806
3.7916
3.5604
3.4641
3.0366
2.9857
3.623
3.0582
2.9563
3.5028
2.9796
3.9164
3.1098
3.0475
3.0271
3.8508
3.2948
3.0526
3.0341
2.9904
3.7179
3.1448
2.9547
2.9762
3.0526
3.4427
3.3601
3.0506
3.023
3.1033
3.7109
3.1307
3.4736
2.9745
3.0073
3.7171
2.9716
2.9809
3.5884
2.9945
3.6027
3.2064
2.9896
3.2526
3.5265
3.1435
3.0691
2.9944
2.9328
3.6547
3.0413
2.9448
3.2856
3.0136
3.2841
3.4893
2.9941
3.0429
3.1911
3.6612
2.9419
3.3529
3.014
2.9683
3.6771
3.0256
3.0518
3.6208
3.0773
3.352
3.1347
2.9538
3.0447
3.5528
3.0769
3.1067
3.0204
3.0112
3.8069
3.0449
2.945
3.1903
3.0018
3.4752
3.6266
3.072
2.9616
3.1425
3.4904
3.0124
3.4471
2.9866
2.9927
3.9391
2.9775
3.0139
3.0368
3.267
3.2851
3.0101
3.0293
3.4511
3.6597
2.9985
3.2369
4.1643
3.0303
4.1005
2.9693
3.0115
3.5609
3.8014
3.3969
3.0674
3.0441
3.0522
4.1384
3.2238
3.4818
2.9811
2.913
4.353
3.0236
3.3357
3.073
3.3719
3.7207
2.9904
2.9382
3.7713
4.4928
3.8836
3.3033
3.0132
3.9897
3.0139
2.9891
3.3926
2.9755
3.9225
3.5793
3.0061
3.0844
3.5366
3.8997
3.553
3.0224
3.0124
4.3497
3.2174
3.033
3.2083
3.6297
3.8561
2.9513
2.9969
3.3707
4.1062
3.1664
3.3522
3.3399
3.3456
4.4152
2.973
3.162
3.0107
3.5958
3.5797
2.9942
2.9884
3.1202
3.7711
2.9658
3.5963
3.0394
3.0464
3.6078
2.9429
3.0957
3.127
3.6506
3.2911
3.0155
3.0012
3.4004
3.3413
3.7903
3.0304
3.0061
3.054
2.9971
3.745
3.393
3.0536
3.0267
3.2282
3.5164
2.9661
3.575
2.9723
3.0378
3.6101
2.9239
3.0346
3.0197
3.5197
3.2385
3.0008
3.0244
3.6312
3.7212
2.9829
3.1322
2.9758
3.4535
3.6164
3.0054
2.9977
3.1691
3.0242
4.4425
3.0795
2.9461
2.9324
3.9299
2.9811
3.2717
3.034
3.0115
3.8557
3.1779
2.8972
3.7241
3.0359
3.7186
3.1329
2.9878
2.9302
3.847
3.5003
2.9672
3.1722
3.5429
3.5011
3.1391
2.9898
3.0397
2.9881
3.6237
3.6385
3.0138
2.971
3.0983
3.5731
2.949
3.4497
3.016
2.9911
3.8384
3.0082
2.945
3.6108
3.0206
3.7759
3.2437
3.038
3.3195
3.7347
3.1297
3.0738
2.974
3.5559
3.7793
2.983
3.0025
3.1316
2.9568
3.9476
3.5022
2.9938
2.9432
3.2603
3.3306
3.0023
3.6346
2.981
3.4657
3.336
3.1161
3.4562
3.034
3.8678
3.3134
3.2009
3.045
3.5574
3.8232
3.1447
3.1436
3.1106
3.6311
3.2103
3.7635
3.1448
3.0923
3.8098
3.5732
3.0116
3.1412
3.2538
3.3617
3.0405
3.1082
3.2066
3.8704
3.1849
3.013
3.389
3.0382
3.6708
3.1413
2.9553
2.9638
3.5467
3.9473
2.9572
3.1652
3.5237
3.4247
3.2286
2.9575
2.9393
3.0204
3.4942
3.54
3.0219
3.0603
3.1105
3.6017
2.9693
3.3856
3.0267
2.9826
3.9128
3.042
2.9557
3.4594
3.0073
3.9316
3.2057
2.9617
2.9706
3.7844
3.105
3.1427
3.0164
3.4308
4.1115
2.9751
2.9822
3.1199
2.9854
3.7092
3.7221
2.9641
2.9415
3.2426
3.1725
3.1369
3.1113
2.9911
3.5087
3.1638
2.9515
3.3671
3.03
3.7163
3.313
2.999
3.015
3.3999
3.8277
3.0252
3.171
3.0047
3.5654
3.865
2.9469
2.9614
3.1651
3.1474
4.1425
3.0689
2.9912
2.9665
3.598
3.0178
3.3816
3.0842
2.9725
3.9113
3.0572
3.5846
3.5568
3.0418
3.7873
3.3671
3.0098
3.238
3.8381
3.0703
3.2465
3.0522
3.7844
4.4304
3.9983
3.1411
3.097
3.5124
3.5588
2.9764
2.9881
3.2299
3.736
3.0662
3.7029
3.1006
3.2085
3.7318
2.8974
3.3181
3.0529
3.7796
3.4337
2.9921
3.1776
3.446
3.8327
3.0096
3.3028
3.007
3.9557
3.4011
3.0217
3.209
2.9921
3.58
3.5942
3.0805
2.9988
3.0702
3.6907
3.0131
3.6639
2.9262
2.9955
3.6765
2.9611
3.0728
3.5378
3.2326
3.4726
3.1379
2.9242
3.1571
3.8148
2.9837
3.194
2.9985
3.4891
3.7763
2.9884
3.013
3.1598
3.0089
3.6934
3.454
2.9613
3.0063
3.5309
3.1783
3.2345
3.1075
3.0264
3.6614
3.1433
2.9827
3.5835
3.5102
3.6656
3.0995
3.0355
3.2487
3.5073
3.7904
2.9574
3.2794
3.148
3.9547
3.1484
3.0224
3.2271
2.971
3.7153
3.628
3.1654
3.0332
3.185
3.8516
3.1662
3.2178
2.9805
3.2657
3.2638
2.9701
3.4028
3.2696
3.8384
3.2801
3.0763
3.0026
3.5731
3.683
3.1229
3.1356
2.9808
3.9199
3.1939
3.1243
3.0336
3.1539
3.733
3.5485
2.9636
2.9457
3.3425
3.6081
3.1038
3.5279
3.1996
2.9647
3.9656
2.9847
3.0444
3.1582
3.7001
3.2388
3.0077
3.1592
3.4066
3.858
2.9383
3.1896
3.0433
3.6609
3.5572
2.9808
3.0874
3.1671
3.5425
3.7342
3.1741
2.9963
3.1257
3.8324
2.9449
3.4994
3.0343
3.0473
3.1567
3.9056
3.331
3.0507
2.9441
3.6332
3.774
3.05
3.2617
2.998
3.7898
3.4611
3.0772
2.9762
3.2275
3.169
3.6216
3.026
2.9619
3.1774
3.6772
3.1249
3.539
3.2219
2.9916
4.0978
2.9998
2.9629
3.6158
3.0654
3.5914
3.2372
2.9191
3.1368
3.7858
3.0943
3.1064
3.12
3.4721
3.7724
3.0568
3.0233
3.1466
3.0076
3.9354
3.502
3.1081
3.0205
3.566
3.0185
3.0809
3.0686
3.0206
3.8732
3.1771
3.0786
3.445
3.1999
3.7117
3.1825
3.009
2.9532
3.8596
3.6534
3.0218
3.1339
3.2129
3.8478
3.3433
3.0574
3.1107
3.0712
3.6895
3.8478
2.9679
3.0865
3.1934
3.6972
3.3235
3.0819
2.944
3.7351
3.1157
3.0067
3.395
3.0329
3.7361
3.2581
2.9663
2.9788
3.4856
3.8853
2.9734
3.1981
2.9324
4.0477
3.2267
3.0147
3.0672
3.227
3.3499
3.4903
3.0208
3.0031
3.0155
3.4562
2.9863
3.3593
3.0143
2.9679
3.7601
3.0936
2.9113
3.4365
2.979
3.5399
3.128
3.0069
3.0087
3.4179
3.56
3.019
3.1892
3.0226
3.4133
3.8979
3.034
2.9845
3.1317
3.0592
3.8518
4.0771
4.0107
4.2067
3.1127
3.2506
2.9691
2.9863
3.8725
3.1002
2.9949
3.4642
3.026
3.8814
3.1558
2.9816
3.1398
3.6371
3.7882
3.0175
3.3163
3.0127
3.9559
3.1611
3.0235
3.2292
3.0688
3.7201
3.4369
3.2268
2.9638
3.1598
3.7075
3.0114
3.6485
2.97
3.2387
3.612
2.9885
3.1738
3.0878
3.818
3.2508
3.1317
2.939
3.5411
3.8395
3.0193
3.1478
3.0007
3.6625
3.7257
3.0352
3.0436
3.3082
3.083
3.5677
3.1058
3.0344
3.2992
3.633
3.0538
3.4175
3.09
2.9759
3.8243
3
3.0341
3.8885
2.9812
3.857
3.1855
3.0011
3.4334
3.3511
3.2814
3.0399
3.0843
2.9896
4.3023
3.07
2.9742
3.3814
2.8471
3.9352
4.1141
3.0888
3.0258
3.7641
2.9499
3.4711
3.0588
2.9892
3.7067
3.1014
3.1009
3.7273
3.0751
3.8619
3.1037
3.1041
3.0253
3.5414
3.634
3.5627
3.0918
3.3916
4.2889
3.1502
2.9782
3.331
3.1247
3.7987
3.1936
3.0297
3.3245
3.7919
3.3724
3.4856
3.344
3.6921
3.8857
3.0192
3.4615
3.2892
3.6718
3.2756
2.9622
3.2112
3.5184
3.9466
2.9753
3.2939
3.5834
4.2537
3.1511
2.9695
3.3525
2.9598
4.0568
3.5437
3.1378
3.0101
3.2326
3.3592
3.131
3.1936
2.9194
3.9234
3.1689
3.1815
3.4078
3.1425
3.7442
3.2939
3.0231
3.0582
3.9875
3.1872
3.3239
3.0246
3.5715
3.9962
3.1849
3.0493
3.428
3.3613
3.5507
3.6585
2.9685
3.4387
3.5882
3.2745
3.5063
3.2261
3.1829
3.7525
3.0268
3.0843
3.0732
3.4083
3.2025
2.9559
3.0063
3.3887
3.9388
3.1086
3.2347
3.1478
3.2432
3.8505
3.0104
3.2691
3.1399
3.4454
3.7973
3.0311
3.2945
3.1287
3.7436
2.9742
3.4749
2.9835
2.9378
3.7224
2.9895
3.3441
3.5428
3.2726
3.5934
3.5051
2.9836
3.4489
3.8605
2.9947
3.1144
2.9754
3.1243
4.0954
3.1801
2.9769
3.1791
3.1863
3.9302
3.1105
2.9545
3.2832
3.4919
3.3134
3.4363
2.9917
2.9884
3.8222
3.3398
3.0351
3.6098
3.3134
4.2459
2.9817
3.2184
3.3124
3.8786
3.3105
3.1388
3.9013
3.4752
3.0103
4.3396
3.1132
3.1259
2.9884
3.6674
3.3959
3.6614
3.9123
4.2767
4.4505
3.992
4.1864
4.6517
4.2293
3.2471
3.0896
3.9549
3.4262
3.4294
2.9608
3.3392
4.2092
3.3026
3.0512
3.3498
4.1075
3.8248
2.9937
3.0706
3.0925
4.1096
3.369
4.0471
4.062
4.1482
3.0218
3.3813
3.0539
3.7213
3.5052
3.009
3.0649
3.3915
4.2907
2.9804
3.1273
2.995
3.4238
4.3009
2.9859
3.1675
3.0131
3.8679
3.6996
3.0237
2.9937
3.1352
4.337
3.144
3.0193
2.995
3.2496
3.1761
2.979
3.2502
3.0241
3.632
3.2707
3.1826
2.9596
3.5181
3.7728
2.9955
3.1869
3.0018
2.9744
4.45
3.7904
3.0929
3.068
3.4679
3.7164
3.0968
3.023
3.1608
3.6627
3.3695
3.1175
3.2783
3.5826
3.3031
2.9505
3.4211
3.0035
3.5963
3.3757
3.0539
3.2116
3.4731
3.667
2.9512
3.3475
3.6181
3.8281
3.1048
2.97
3.3627
2.9336
3.7627
3.526
3.2349
2.9964
3.1793
3.582
3.2022
3.2227
3.0014
3.8248
3.1072
3.235
3.6359
3.266
3.5948
3.2112
3.171
3.0124
3.6453
3.2992
3.1946
3.1251
2.9382
3.5367
3.2906
3.2645
2.9968
3.0888
3.4386
3.6098
2.9981
3.0436
3.3637
3.4498
3.1569
3.4757
3.1085
2.9858
3.5981
3.0264
2.9961
3.8228
3.0233
3.3039
3.0964
2.9779
3.0234
3.317
3.4663
3.1536
3.2414
2.9453
3.9211
3.0134
2.9129
3.0445
2.9982
3.3773
3.4126
3.0172
2.9914
3.2154
3.4072
2.9749
3.5202
2.9755
3.0715
3.9799
3.0146
2.961
3.6251
3.0696
3.2684
3.1676
2.9977
3.0728
3.5641
3.1274
3.1865
2.9877
2.9538
3.7031
3.1652
2.9471
3.0102
2.9709
3.5204
3.5518
2.9443
2.9746
3.1626
3.3311
3.14
3.3635
3.0855
2.9186
3.6555
3.0395
2.9817
3.413
2.9744
3.8448
3.1565
3.0099
2.9807
4.1489
3.1822
2.9767
3.0684
2.9658
3.859
3.1156
2.9505
3.1071
2.9455
3.5316
3.6024
3.0158
2.9498
3.1263
3.4945
3.0638
3.4451
3.0162
2.9548
3.6439
2.955
2.9572
3.4769
2.9391
3.6803
3.1763
3.0349
2.9477
3.8303
3.1641
2.9437
3.1545
2.9376
3.4865
3.2999
2.9976
2.9859
3.045
3.4479
3.607
3.0877
3.0112
3.0089
3.5556
3.1292
3.3997
3.0618
2.9394
3.5615
3.1594
2.9347
3.4657
3.0595
3.5124
3.0767
3.0211
3.0598
3.4792
3.5607
2.9832
3.0779
2.9478
3.4668
3.2768
2.998
3.0189
3.1969
3.2115
3.5986
3.9957
3.1377
3.106
3.6526
3.0186
3.5023
2.9521
2.9504
3.7397
2.9849
2.9732
3.4785
3.1707
3.4209
3.0985
2.9902
3.2616
3.6511
3.0447
3.0644
3.0022
3.0026
3.6761
3.1891
2.9031
3.1152
3.0173
3.3533
3.5501
3.0037
2.9775
3.1173
3.5401
2.9682
3.4184
3.025
2.948
3.5606
2.9726
2.9544
4.0277
4.2007
4.0682
3.0108
3.0028
3.4083
3.6645
3.0218
3.1219
2.9807
2.9769
4.2738
2.9808
2.9673
3.1828
2.9569
3.6363
3.0625
2.951
3.0137
3.3934
3.2086
3.2826
3.0443
2.9772
3.5198
3.1845
2.9781
3.5219
3.0133
3.4393
3.2564
2.9199
3.041
3.3298
3.7467
2.9697
3.1356
2.9764
2.9626
3.9773
2.9184
2.9317
3.1102
2.9819
3.9021
3.0836
3.0291
2.9344
3.465
3.1339
3.4501
3.0153
3.0303
3.6314
3.1074
2.9916
3.4859
3.1221
3.5929
3.5234
3.0673
3.0778
3.0142
2.952
3.6173
2.9658
2.9944
3.1431
2.9981
3.6765
3.5668
3.0461
3.016
3.1993
3.58
3.0407
3.1097
2.9724
3.6248
3.1744
2.9232
3.5901
3.0203
3.6734
3.2523
2.9986
2.9425
3.4973
3.7876
2.945
3.3513
2.9932
3.7763
3.2461
2.9956
2.9352
3.1856
3.0892
3.3309
3.0692
3.0493
3.0098
3.5926
3.1165
3.4715
3.9023
3.0418
4.0001
2.9592
2.9894
3.039
3.3527
3.158
3.0051
2.9164
3.5434
4.3784
4.1014
4.0967
4.0528
4.462
4.2686
4.156
5.1126
3.3273
2.9563
3.0793
2.965
3.3455
3.1575
3.5468
2.9835
2.9601
3.4915
2.9783
3.0288
3.7283
4.1322
3.4588
3.2021
2.9327
3.1834
3.497
3.2143
3.1248
3.0665
2.9577
3.707
3.1694
3.0148
3.0754
3.0256
3.4334
3.5667
3.0254
3.0013
3.1177
3.4984
3.0438
3.4257
3.0067
3.0076
3.7596
3.013
3.0129
3.5916
2.9887
3.2854
3.1315
3.0129
2.9977
3.4875
3.2147
3.0862
2.9447
2.9478
3.6187
3.1175
2.974
3.0578
2.9841
3.4218
3.4949
3.0012
3.0135
3.042
3.484
3.0784
3.5799
2.986
2.9509
3.6053
2.9853
3.0091
3.5792
3.0125
3.6
3.1371
3.0581
2.9822
3.8828
3.0798
2.9694
3.1565
3.0076
3.3546
3.1846
2.982
3.0202
3.1436
3.1732
3.5608
3.4251
2.9535
3.1093
3.5326
3.136
3.4636
2.994
2.946
3.8182
2.9406
2.9581
3.5324
3.0332
3.6858
3.1519
3.0178
3.062
3.507
3.1356
3.093
2.9672
3.0217
3.9174
3.0484
2.9696
3.0684
2.9953
3.3205
3.4156
3.0299
2.9269
3.153
3.5304
3.1166
3.5783
2.9663
2.9902
3.7398
2.9989
3.0136
3.5908
3.1148
3.3594
3.2264
3.0783
3.1148
4.4873
3.0141
3.1811
3.0077
2.9433
3.8851
2.9892
3.064
3.114
2.9827
3.4344
3.8389
3.0317
3.0754
4.4573
3.0711
3.4181
3.0211
2.9142
3.6873
3.2044
3.0118
3.4496
2.9703
3.5455
3.1772
3.0708
2.9334
4.0614
4.1056
3.9442
2.9746
3.017
3.7647
3.0654
2.9578
3.1557
2.9112
3.3416
3.4295
3.0204
2.9324
3.1608
3.8403
2.9893
3.494
2.9616
3.1844
3.5158
2.994
3.2017
3.0909
3.476
3.3033
2.9349
3.0131
3.5693
3.6063
3.0261
3.1203
2.9119
2.9588
5.5342
4.2021
3.6045
2.9425
3.1779
3.4075
3.0393
2.9927
3.0821
3.8129
2.9709
4.5407
4.0296
4.4496
3.9567
4.3557
4.5574
4.167
4.0207
3.9783
4.723
4.0356
3.9683
3.9854
4.6094
3.9228
4.0497
3.979
4.1567
4.4356
4.1363
4.36
4.2215
4.5038
3.8761
2.9666
3.6959
2.9914
2.9804
3.5717
3.4648
3.1975
3.036
3.012
3.4417
3.6876
2.9799
3.2439
2.9745
3.0632
4.2542
3.9951
4.1711
4.0861
4.3569
4.0124
3.4712
3.1776
3.4757
2.9948
3.8
2.925
3.0504
3.6315
2.9836
2.9539
3.4964
3.1393
3.2617
3.1612
2.9881
3.1757
3.3115
2.9892
3.027
3.0899
2.9845
3.8097
3.0711
3.0417
3.0128
3.0094
3.2506
3.3922
3.0643
3.006
3.1564
3.5438
3.1613
3.5674
3.0001
3.0632
3.7693
2.9471
2.9594
3.8
2.9937
3.551
3.2081
2.9639
3.2025
3.6312
3.1522
3.1404
3.0242
3.1752
3.6472
3.0825
2.9809
3.1631
2.9913
3.3738
3.581
2.9956
2.9377
3.1286
3.5467
3.0242
3.5744
3.1058
3.0085
3.0877
3.3037
3.1153
3.0403
3.0067
3.2203
3.4979
3.1824
3.1627
2.9625
3.117
3.9934
3.0297
3.007
3.1218
2.95
3.2676
3.471
3.0083
2.9759
3.115
3.3794
2.9777
3.3551
3.0113
2.9922
3.6327
2.9599
3.0104
3.5775
3.0267
3.4957
3.1659
2.9735
3.12
3.5136
3.1524
3.0446
2.9548
2.9698
3.5906
3.1127
2.9543
3.086
2.9404
3.1247
3.3813
3.1179
2.9571
3.1056
3.3142
3.0902
3.4244
3.0198
2.9711
3.649
3.1983
2.9921
3.6493
2.9862
3.6207
3.1645
2.9649
3.0109
3.643
3.271
2.9916
3.1746
3.0407
2.9925
3.2666
2.9466
2.9637
3.115
3.3702
3.3193
3.0568
2.947
2.99
3.5189
3.1751
3.3951
3.0286
2.939
3.665
3.1775
2.953
3.4569
3.0292
3.6236
3.1983
3.0109
3.015
3.87
3.3524
2.989
3.157
2.9781
3.0212
3.8514
3.1087
2.9958
3.1692
3.3017
3.4492
3.0482
2.9119
2.9989
3.5548
3.217
3.491
3.0752
2.9936
3.7988
2.9542
3.0168
3.4172
3.0804
3.4975
3.1658
3.0686
2.9864
3.4843
3.6481
3.0078
3.2414
2.9708
3.0678
4.3416
4.046
3.9069
2.9702
3.1974
3.6362
2.991
2.9726
3.4056
3.3102
3.097
3.0872
2.9541
3.6002
3.2183
2.9833
3.4374
3.0787
3.5023
3.3034
2.9515
2.9938
3.3946
3.4509
3.0071
3.1284
2.9306
2.9963
3.9184
3.026
2.9562
3.1701
3.0112
3.4527
3.5248
3.0036
2.9485
3.1879
3.3803
3.2815
3.3653
2.935
3.5391
3.1718
2.9538
3.4049
3.0581
3.6316
3.2125
2.995
2.9835
3.678
3.6704
2.9857
3.1504
2.983
2.9563
4.207
2.9473
2.973
3.222
2.9784
2.9988
3.599
3.0327
2.9489
3.5138
3.3399
3.2577
3.0041
2.9885
3.6735
3.0572
2.9479
3.4842
3.1329
3.526
3.299
2.9223
2.9499
3.402
3.8018
3.006
3.1366
2.9453
2.9321
4.174
3.0461
3.0404
3.1558
3.2592
3.1198
3.024
3.0139
2.9806
3.6474
3.1515
3.4454
3.0064
3.0358
3.618
3.0941
2.9831
3.6154
3.0081
3.523
3.1973
2.9189
3.0254
3.3786
3.6868
2.9639
3.1426
2.9615
3.0232
3.9516
3.0202
2.9792
3.1477
3.0463
3.0395
3.6539
3.032
3.0131
3.277
3.1001
3.2723
3.1063
2.9532
3.5155
3.1644
3.017
3.4563
2.9731
3.5751
3.1745
3.0155
2.964
3.3705
3.5603
2.9996
3.1792
3.0046
2.9431
3.8066
3.0257
3.0178
3.159
3.0512
3.2871
3.5253
3.03
2.9416
3.1936
3.5813
3.1046
3.0128
2.952
3.4198
3.2577
2.9553
3.2862
2.9748
3.5356
3.2643
2.9796
2.999
3.6749
3.5336
3.0229
3.2087
3.0052
2.9032
3.5844
3.0169
2.9648
3.1489
2.988
3.5418
3.531
3.0158
2.9847
3.1006
3.8292
3.0768
3.1317
2.9734
3.2725
3.2173
2.9714
3.3402
3.0425
3.5267
3.195
2.9495
3.0311
3.4203
3.6276
3.0383
3.1278
3.0172
2.9578
3.9303
3.03
2.9276
3.1549
3.0046
3.2976
3.5994
3.0253
2.9319
3.1924
3.7097
2.9765
3.1384
2.9923
3.2941
3.2536
2.9591
3.333
3.047
3.3255
3.2452
2.9603
3.0315
3.3241
3.4511
3.1586
3.1658
2.9253
2.9593
3.9426
3.001
2.9379
3.2018
2.9922
3.2504
3.3673
3.0255
3.0588
3.1231
3.5242
2.9643
3.7646
2.9995
2.9982
3.5717
2.9555
3.0135
3.0322
3.4577
3.2998
2.9318
3.0014
3.4289
3.5687
3.0958
3.0818
3.0113
3.0063
3.8997
3.0245
3.0122
3.1037
2.9153
3.3028
3.4464
3.0206
2.9699
3.1342
3.5064
3.026
3.4368
3.0594
2.9912
3.9214
2.9403
3.1578
3.1475
3.468
3.1123
3.0336
2.9877
3.367
3.6312
3.1126
3.1128
2.9837
3.047
3.6999
3.0239
2.931
3.0079
2.9564
3.4094
3.9369
3.9021
3.8535
3.6417
3.2225
3.3774
3.0443
2.9936
3.6635
3.032
2.9416
3.4698
3.0303
3.621
3.1231
3.0031
2.9487
3.4305
3.6934
3.0228
3.1199
3.0204
3.0416
3.2767
2.9864
2.9973
3.1832
3.3343
3.3631
3.0577
3.0424
3.059
3.3467
3.1011
3.3368
3.055
2.9968
3.6893
3.1823
2.9474
3.4568
3.0371
3.6449
3.1189
2.996
3.0483
3.4532
3.78
2.9592
3.1644
2.9797
2.9994
3.9018
3.042
2.9895
3.146
3.0288
3.0326
3.1275
2.9988
3.0064
3.6103
3.2188
3.4629
3.0481
2.9531
3.6051
3.1881
2.9158
3.7403
2.9966
3.4615
3.1665
2.9346
2.941
3.5333
3.4228
3.0251
3.2637
2.9768
2.9788
3.9681
2.8679
2.9325
3.1585
3.0845
3.0129
3.4707
3.062
2.9606
3.5995
3.2203
3.3321
3.0236
2.9518
3.6282
3.1526
3.0161
3.4557
3.0203
3.5492
3.2099
2.9899
3.0085
3.5268
3.6422
2.9953
3.168
2.9988
2.9878
3.9695
2.9563
2.9758
3.1311
3.1518
3.1981
3.0788
2.9625
2.9513
3.5005
3.2713
3.4451
3.0477
2.917
3.6544
3.1142
2.9872
3.3653
2.9881
3.5408
3.3046
3.0191
2.9005
3.538
3.452
2.9385
3.1036
2.9975
2.9296
3.9543
2.9921
2.9417
3.0723
3.0243
3.462
3.1578
3.041
3.0447
3.3799
3.2683
3.3353
3.0595
2.9711
3.643
3.0743
2.9318
3.3184
3.0538
3.4778
3.3359
2.9099
2.9369
3.5533
3.594
2.9595
3.152
2.9416
2.9557
3.9326
3.1157
2.9737
3.1576
2.9495
3.3863
3.6173
3.0062
3.0171
3.2162
3.3394
3.1123
3.0082
3.1143
3.4801
3.1216
3.0175
3.3915
3.0489
3.3979
3.2372
2.9773
3.002
3.3655
3.4875
3.1801
3.1973
2.911
2.9409
3.8961
3.0205
2.971
3.2041
3.0242
3.3952
3.6549
2.9691
2.9447
3.4918
3.3394
3.0339
3.0163
2.9551
3.5895
3.1481
2.928
3.374
3.0686
3.4395
3.1762
3.0002
2.9806
3.3382
3.6077
3.0964
3.1666
2.9646
2.9902
3.6092
3.0343
2.9963
3.1282
3.0137
3.2612
3.4909
3.0386
3.0132
3.2083
3.7808
2.9942
3.1026
3.0134
3.5729
3.2203
2.9917
3.368
3.1094
3.4312
3.0908
2.926
2.9693
3.5157
3.7783
3.0026
3.0959
2.9937
3.0116
4.015
2.9445
2.9721
3.1963
3.0068
3.1085
3.9458
2.9291
2.9706
3.3794
3.259
3.1968
3.0369
3.0065
3.7319
3.2247
3.0267
3.3187
2.9882
3.5689
3.1924
3.0286
2.9176
3.4437
3.5379
3.0598
3.1239
3.0127
2.9782
3.8419
3.0203
3.0202
3.1525
2.9796
3.1387
3.6171
2.9932
2.9621
3.2945
3.2456
3.0922
4.1342
3.8836
4.1034
2.9976
2.963
3.0789
3.4628
3.2257
2.9183
2.9801
3.5765
3.5416
3.1257
3.1236
2.9856
2.9812
3.7203
3.0074
3.0125
3.2156
2.9525
3.2743
3.3472
3.0433
3.0288
3.1058
3.5789
2.9037
3.539
3.0566
2.954
3.7242
3.0053
3.0206
3.0473
3.3903
3.3437
2.9697
3.0636
3.6371
3.506
3.1518
3.1654
2.9771
3.003
3.9834
2.9948
3.0569
3.0866
3.0414
3.3046
3.4879
3.0437
3.014
3.1603
3.4099
3.0423
3.0778
3.0153
3.4329
3.086
2.9889
3.5015
3.4372
3.0911
3.6759
2.9821
3.1249
2.9291
2.9791
3.9639
3.0227
3.0424
3.1512
2.9963
3.0904
3.4815
3.0017
2.9974
3.5999
3.2969
3.541
3.1013
2.9252
3.6224
3.1199
2.9424
3.4579
3.0897
3.5028
3.2896
2.9969
2.9423
3.4273
3.7119
3.0031
3.1085
2.9359
2.9926
3.9016
2.9943
2.9492
3.1081
2.908
3.4098
3.4913
3.0154
2.9755
3.185
3.4897
3.0377
3.0633
2.9527
3.6494
3.1662
2.9344
3.4386
3.0344
3.5699
3.2934
2.9334
3.0094
3.5099
3.5537
3.0296
3.1817
2.9537
2.9299
3.9606
3.0236
3.0064
3.1591
2.9464
3.0929
3.6596
3.0117
3.0415
3.2654
3.1737
3.2098
3.06
3.1216
3.6824
3.151
2.9939
3.4409
3.008
3.5966
3.2601
2.924
2.9472
3.4951
3.6949
2.9655
3.2001
2.9694
3.0021
4.225
2.9659
2.9967
3.1839
2.9988
3.0468
3.0666
3.0481
2.9405
3.8675
3.1827
3.4107
2.9949
2.9645
3.6859
3.1673
3.0757
3.5585
3.0697
3.785
3.2381
3.1012
2.9582
3.98
3.2159
3.1183
3.1589
2.987
3.6668
3.2474
2.996
3.0892
2.9594
3.1068
3.3742
3.0675
3.0007
3.0516
3.4809
3.1569
3.4113
2.9789
2.9848
3.6325
3.0866
2.9705
3.5847
3.004
3.6872
3.2111
2.9337
2.9817
3.5906
3.1692
2.98
3.1647
2.9617
2.9682
3.9825
2.9875
2.9417
3.1597
3.3065
3.2777
3.0905
3.0175
3.0394
3.4376
3.1421
3.4242
2.9842
2.943
3.5575
3.2433
2.948
3.425
3.0309
3.4452
3.2538
3.0844
2.9865
3.5612
3.8224
3.0464
3.1824
3.0042
3.2743
3.2959
3.1685
3.0211
3.1308
3.199
3.3584
3.8171
2.9309
3.3328
3.5358
3.1413
3.6989
3.0989
3.0718
3.5792
3.2214
3.2164
3.6706
3.4165
3.4723
2.9991
3.2185
3.4065
3.7565
3.0109
3.1307
3.1326
3.0101
4.1537
3.0318
3.1703
3.1892
3.1251
4.033
3.8201
3.0813
3.162
3.752
2.9633
3.6748
3.0178
3.5437
3.2505
2.9977
3.8098
3.8159
4.108
3.724
3.0702
3.3487
3.5099
3.0927
3.3855
2.9296
3.015
3.7696
3.082
3.0363
3.1214
3.3437
3.6451
3.6935
3.013
2.9244
3.2551
3.4798
3.4649
3.0861
2.9205
3.6062
3.1723
2.9971
3.5204
2.9929
3.4725
3.2525
2.9781
2.939
3.6336
3.5648
3.0214
3.1566
2.9944
2.9657
3.8653
3.0299
2.9294
3.1297
3.032
3.3003
3.6868
3.0023
2.9708
3.5375
3.2578
3.1535
3.1216
2.917
3.5563
3.1806
2.9929
3.5898
3.0277
4.5728
3.1605
2.9972
2.9468
3.6237
3.5699
3.1306
3.1882
2.9492
3.4535
3.2349
2.9967
3.0111
3.1926
3.3122
3.3612
2.9933
2.9993
3.0832
3.4538
3.1495
3.4866
3.0228
2.966
3.6261
3.1512
2.9966
3.439
3.0132
3.6937
3.1409
2.9544
2.9957
4.0237
3.9536
4.2455
4.0361
4.3005
3.9706
4.8261
4.8603
4.4618
4.077
3.865
4.2195
4.082
4.4026
4.0123
4.207
3.9651
3.9247
4.3797
3.9149
3.2107
3.0043
3.0017
3.5786
3.5494
3.0705
3.3378
3.052
3.0158
4.4308
3.1591
3.0013
3.2556
3.2765
3.6262
4.1392
3.0414
3.2805
3.5529
3.1323
3.7728
3.2693
3.3581
3.6912
2.9897
3.2619
3.2201
3.4397
3.4826
2.9381
3.2
3.6809
3.5586
3.5521
3.1619
3.2447
3.0576
3.3848
2.9943
3.2952
3.017
3.6187
3.5638
3.5452
3.4674
3.2411
2.963
3.9349
2.9559
3.1831
3.4185
3.124
3.5791
3.2025
3.2134
2.9782
5.0861
4.1037
3.1931
2.9643
4.0165
4.0563
4.0624
3.4159
3.4624
3.4863
3.3037
3.0061
3.2929
3.3641
3.2499
3.4664
3.0031
3.1999
3.7651
3.2382
3.0154
3.7643
3.1086
3.4604
3.1341
3.0547
3.4915
3.571
3.2955
3.0478
3.0755
2.9711
3.8285
3.0363
2.9982
3.3523
2.9745
3.4807
3.3633
3.0206
3.0479
3.0814
4.3744
3.1868
3.3355
2.9862
3.751
3.0838
2.9812
3.656
3.0545
3.8354
3.202
3.1922
2.9791
3.8191
3.3213
3.052
3.1995
2.9941
3.6661
3.2618
3.4676
3.1609
3.157
3.1994
3.316
3.3039
2.998
3.3565
3.581
3.4422
3.5137
3.1166
3.3259
3.5972
3.1946
3.2654
3.3145
3.6524
3.6802
2.9838
3.1615
3.5355
3.7287
3.0288
3.2184
3.3608
3.2281
3.3003
3.0459
3.3429
3.026
3.4414
3.576
2.9484
3.2493
3.1906
3.7246
2.9581
3.6153
2.9867
2.9615
3.9698
2.9563
3.0627
3.1005
3.3579
3.4012
2.9747
2.9729
3.3834
4.282
3.9476
3.5363
2.9789
3.6799
3.2986
3.1779
3.0603
3.1589
3.0749
3.2832
3.003
2.9258
3.1393
3.5128
3.1391
3.5239
3.0092
3.1435
3.7578
3.162
2.9543
3.6187
2.962
3.9368
3.2677
2.962
3.6174
3.3728
3.4268
3.075
3.1956
2.9561
3.766
3.1392
3.0338
3.3356
3.0249
3.5551
3.5743
3.0437
3.1313
3.1975
3.5851
3.0662
3.3586
3.0261
3.7146
3.0328
3.0362
3.6831
2.9127
3.5722
3.0827
3.3047
3.0431
3.592
3.6151
2.958
3.0663
2.9618
3.0165
3.2789
3.2073
3.0482
3.1404
3.4167
3.3725
3.2176
2.9751
3.1539
3.4077
3.3086
3.4778
3.0317
3.2862
3.9595
3.1885
2.9367
3.7179
3.2176
3.4022
3.0282
2.9325
3.4672
3.6024
3.3472
3.0366
3.0755
2.9765
3.7579
3.1143
3.0186
3.3252
2.979
3.4908
3.4749
3.0267
2.9526
3.059
3.9507
3.1978
3.3686
3.021
3.3235
3.1788
2.9372
3.4805
3.022
3.5888
3.1956
2.9668
2.9271
3.3766
3.3715
3.1619
3.3238
2.9551
3.1982
3.7532
3.0651
2.9548
3.0117
3.0179
3.1829
3.7476
2.9995
2.9648
3.5388
3.3665
3.531
3.081
3.1875
3.4674
3.1961
3.0113
3.3749
3.2507
3.5823
3.4388
2.9883
3.1588
3.4257
3.7345
2.9683
3.0313
3.3107
3.0003
4.0518
2.9669
3.0002
3.1035
3.3017
3.4085
3.077
3.1386
2.9872
3.6301
3.1481
3.4675
3.0099
3.001
3.5818
3.1729
3.0703
3.6757
2.9755
3.6663
3.12
3.1812
3.0026
4.1887
3.087
3.155
3.0262
2.9752
3.752
3.2001
3.2671
2.974
3.0748
3.252
3.5361
3.1761
3.0291
3.1812
3.5351
3.2567
3.4889
3.0469
3.1939
3.8007
3.2754
3.1626
3.3267
3.4751
3.3202
2.9728
2.958
3.5813
3.696
3.5005
3.0219
3.2765
2.941
4.0281
2.9829
3.0097
3.3662
3.0221
3.184
3.1062
3.2719
3.0239
3.6412
3.3798
3.5535
3.0145
2.9763
3.6411
2.9324
3.0813
3.3976
3.026
3.7677
3.0859
3.8328
3.1408
3.8593
3.0692
3.286
3.0427
3.0738
3.8745
3.0279
2.9765
3.0459
3.0729
3.3895
3.6774
2.9823
2.9323
3.3798
3.3967
3.3131
3.0585
2.9441
3.3302
3.246
2.9807
3.5043
3.0485
3.5342
3.2535
2.9467
2.9797
3.5261
2.9602
3.545
3.1998
3.0316
3.0406
2.9431
3.2719
3.4424
3.049
2.9949
3.0744
3.4674
3.1855
3.4537
2.9747
2.9871
3.5859
3.1122
3.037
3.3591
2.9793
3.4733
3.0526
2.9482
2.9887
3.8072
3.5796
2.9513
3.0915
2.9869
3.0797
4.6561
3.9347
3.8151
3.1917
3.3323
3.7173
3.0037
3.0936
3.095
3.4029
3.3794
3.1182
3.1489
3.6084
3.2871
2.9599
3.405
3.1634
3.3859
3.1939
2.9679
3.2655
3.8264
3.665
2.9882
3.0744
3.1356
3.05
3.2228
2.962
2.9708
2.9697
3.2903
3.5508
3.0784
2.99
3.1144
3.4536
3.1039
3.404
3.0237
2.9583
3.7134
3.1216
3.0163
3.686
2.9704
4.0562
3.0297
3.0106
2.9432
3.8389
3.3478
3.0199
3.1624
3.0058
3.5405
3.3684
3.005
3.0189
3.0354
3.5251
3.6013
3.0303
3.0167
3.2703
3.464
3.0564
3.6404
3.0733
3.4445
3.3934
3.2711
3.0879
3.2217
3.62
3.2366
2.9845
2.9875
3.3959
3.4422
3.0645
3.0515
2.9925
2.9856
3.9216
3.0679
2.9533
3.2047
2.9581
3.7134
3.7982
2.9494
2.9704
3.0488
3.5391
3.3203
3.2338
2.9288
3.4892
3.1968
2.9626
3.2857
3.0789
3.4989
3.1371
3.0148
3.032
3.4361
3.7717
3.1238
3.1238
3.0136
2.8844
3.9356
3.0812
3.0061
3.0443
2.9292
3.6523
3.6638
3.0157
2.9826
3.1574
3.5624
3.13
3.0754
2.9667
3.2077
3.337
3.0095
3.2495
3.0952
3.4216
3.1745
2.981
3.0446
3.4359
3.5472
3.1405
3.1121
2.9619
3.0344
3.5582
3.0104
3.0474
3.0771
3.0225
3.3925
3.3981
2.9966
2.9225
3.0506
3.5717
2.9872
3.5537
3.0436
3.0009
3.8513
2.9921
2.958
3.6069
3.1299
3.4081
3.1039
3.4041
3.3283
3.5613
3.088
3.2667
3.9461
3.9033
4.3499
3.892
3.9994
4.1645
4.1537
3.6589
4.0764
4.048
3.4765
3.8549
3.971
3.9037
4.2714
4.267
5.008
4.1408
4.0948
3.8571
4.1308
4.1403
3.8562
4.0214
4.3001
4.9497
4.3335
4.0307
4.4387
4.4809
4.2547
4.0728
4.322
4.1114
4.3638
4.1661
4.526
4.1252
4.8133
4.2413
4.2331
3.9962
4.4779
4.454
4.0842
4.2471
4.4767
4.5618
4.0695
4.0855
3.8891
4.1985
4.3964
4.292
4.3718
3.9754
4.1241
4.0681
4.114
4.4081
4.4296
4.2751
3.9859
4.1158
3.7924
4.4327
3.7226
4.1674
4.0506
4.0774
3.8169
3.0322
2.9844
3.0674
3.0309
3.8392
3.0892
2.9659
3.028
3.473
3.3056
3.4287
2.974
2.9657
3.649
3.2142
2.9835
3.4015
2.9993
3.565
3.2416
2.9606
2.9449
3.5013
3.6165
3.0333
3.0993
2.9184
2.9287
3.9276
2.9153
2.9396
3.0226
2.9265
3.3922
3.7771
3.9973
3.8741
4.1722
3.8534
4.2263
4.0261
4.2661
4.038
4.18
2.9953
3.2973
3.1885
2.9926
2.9739
3.4876
3.6624
2.9541
2.9415
2.9899
3.0007
3.6346
3.0561
2.9673
3.0546
2.9518
3.5047
3.4213
3.0141
2.9721
3.5297
3.8686
4.3642
4.3706
4.2998
4.5202
4.8343
4.554
4.5378
4.1704
4.6159
4.1076
4.1919
4.5124
4.4935
4.022
3.1232
2.9749
2.9967
3.0937
3.9685
3.4218
2.9518
3.7963
3.2985
3.5528
3.0055
2.9962
3.0015
4.5459
4.0696
3.2667
2.986
2.9738
3.9156
3.1181
3.5353
4.209
3.6673
3.212
2.9673
3.0168
3.2573
3.7763
4.3402
4.0965
4.2716
3.6153
3.0481
3.0972
4.0954
4.1232
3.8855
4.2248
4.7985
4.2993
3.9353
4.4721
4.0051
4.1106
4.1186
4.1208
4.0999
4.0833
4.0655
3.9779
4.1669
4.4277
4.3199
4.038
4.087
4.3471
3.928
3.8947
4.1838
4.2631
3.974
4.2796
4.5483
4.2081
4.0742
4.2918
4.0042
3.9667
4.2968
4.5758
4.2122
4.1085
3.9056
4.3901
4.0208
4.4237
4.2599
4.7836
4.0349
4.392
4.8774
4.2677
4.2229
4.0271
4.0265
4.1064
4.3305
4.7242
3.8299
4.171
4.1899
4.1051
4.3333
4.306
4.3964
4.3297
4.1823
4.2806
4.3543
4.2598
4.3034
4.3163
4.0999
4.1585
4.2307
3.9811
4.3321
4.6453
4.3849
4.3217
4.4506
4.4978
4.1609
4.3175
4.1697
4.1085
3.9464
4.3103
4.4014
4.5279
3.9343
4.1273
4.0634
3.9988
4.1062
4.2155
4.0673
4.1648
4.4317
4.8716
3.9339
3.9745
4.2516
4.0915
3.9771
3.9338
4.5895
3.92
4.0157
3.9324
4.3874
4.4502
4.1409
4.633
4.0189
3.9349
3.9307
4.2336
3.2351
3.1412
3.0579
3.6914
4.038
3.8983
4.039
3.6879
3.3096
3.1815
3.0039
3.2685
3.009
3.3827
3.7957
3.9698
4.1236
4.1789
4.2102
4.3237
4.229
5.5162
4.4885
4.4955
4.5575
4.6361
4.846
5.1135
4.1876
4.5178
3.276
3.8751
3.1062
3.0485
3.0495
3.0448
3.7062
3.0031
4.0072
4.4155
5.044
3.0839
3.0692
3.0678
3.6802
3.187
3.6149
3.6094
2.9413
3.543
3.8147
3.6768
2.9774
3.2035
4.5769
3.3616
3.007
2.9005
3.7225
3.9022
3.0153
3.1669
3.1452
3.5422
2.9572
2.9589
4.1012
4.8151
3.9963
3.4182
2.9801
3.7392
3.2303
2.9996
2.9541
2.9664
3.6132
3.0431
2.9504
2.9966
3.3761
3.7228
2.937
3.3201
4.6506
4.3258
4.5466
4.5929
5.1453
4.5919
4.7284
4.2936
4.7183
4.7434
4.9797
4.4807
4.589
4.4338
4.5254
4.5451
4.9391
4.4176
5.0369
5.4094
4.7706
4.4731
5.234
4.5483
4.5096
5.0223
5.0076
5.2004
4.849
5.4965
4.403
4.7255
4.4647
4.41
4.4006
5.3996
4.4672
4.5491
4.3544
4.4095
4.2432
4.6938
4.6326
4.7559
4.7871
4.617
4.2857
4.5556
4.7241
4.3448
4.4875
4.7697
5.3311
7.0867
8.9098
6.4247
5.3461
5.1766
5.1612
4.9407
5.323
8.4961
5.1756
4.8259
3.9801
4.163
4.0588
4.0039
4.5617
4.8573
4.3118
3.9305
5.4901
4.5247
5.4798
4.0531
4.3974
3.9777
4.0736
4.9736
5.2769
4.6478
4.4818
4.7104
4.6743
4.4172
4.9686
4.3675
4.8499
4.5225
6.0189
5.0128
5.0544
4.1243
4.285
4.4642
5.3633
5.3395
3.886
4.1101
6.7849
4.345
4.4193
4.0453
4.0234
4.1377
4.8041
4.5702
4.721
5.8542
4.1354
4.2475
4.0606
5.6203
4.6359
4.3273
4.3569
5.276
4.5169
4.4974
4.2521
4.7336
4.343
4.3114
5.8323
4.2178
4.0549
3.5855
3.9292
3.9588
4.3712
4.4743
4.6259
4.734
4.3046
3.9979
3.9775
4.118
4.3891
4.2378
3.8976
4.5121
4.4557
5.3811
3.7969
4.1187
4.0176
4.4547
4.0353
4.8246
4.2827
4.1402
4.3431
4.0132
4.1132
3.979
4.6081
3.9402
4.0675
4.549
5.1544
4.2323
4.0666
4.325
3.9878
4.8947
4.047
4.1628
3.8633
4.3708
4.0021
4.1384
4.0243
4.4101
5.446
4.3567
3.9786
4.2063
4.3068
4.0812
4.0492
4.032
4.0557
4.5001
3.8703
4.2078
3.9527
4.0511
4.186
3.8686
4.3196
4.174
4.752
4.5384
3.591
3.8923
4.0327
4.2299
3.139
3.0465
3.3479
4.1577
4.8894
3.9331
3.0573
2.9348
3.7024
4.0091
3.069
3.0246
3.0633
4.0449
5.0064
3.7506
4.2446
3.6274
3.8465
4.2472
4.2427
4.0137
3.8839
4.3975
4.3536
3.9172
4.2914
4.2575
5.0377
4.2161
4.0011
4.0314
4.1823
3.9306
4.0341
4.4212
4.0153
4.0372
3.9924
4.5814
4.1308
4.026
4.0039
5.1796
5.6542
4.3999
3.8042
3.8414
4.0796
3.8578
4.1833
3.9375
5.1203
3.9224
4.388
3.9532
4.057
4.738
4.3414
4.3658
4.057
4.5856
4.0662
3.8551
3.0706
4.307
4.0875
3.9896
4.0487
4.2007
4.846
4.025
3.1674
3.8536
3.1806
3.1937
3.9994
4.1378
4.1052
4.0192
5.6673
4.2927
4.6535
4.1829
4.352
4.0366
4.3881
4.5082
4.9083
4.6194
4.3921
5.76
5.0272
4.2245
4.633
4.9883
4.6943
4.3057
4.3279
4.7463
4.5659
4.5931
4.3762
4.6234
4.2135
4.7029
4.5932
4.4406
5.0045
4.1815
4.6606
5.068
5.7111
4.5065
5.3959
6.0761
5.9503
4.8818
3.7734
3.9758
4.3447
3.5639
3.0438
3.0405
3.4127
4.6077
4.1589
4.1835
3.9245
3.9825
4.2081
4.0531
4.0737
4.2644
4.7523
4.3875
4.0681
3.9374
3.0226
3.4648
3.0115
3.518
3.4038
3.0898
2.9969
5.0686
3.7425
3.1646
3.0277
3.0094
3.789
3.1509
2.9702
3.2124
2.9941
3.5948
4.5682
3.0219
2.9685
3.4318
3.2047
3.382
3.016
2.9705
3.5905
3.1191
2.9852
4.2934
3.266
3.6587
3.2074
3.0729
3.0847
3.2399
3.2522
3.1639
2.9874
2.9472
4.1666
3.8387
3.0234
3.2239
3.0179
3.482
3.0937
2.9579
3.0019
3.4816
3.3501
3.8852
4.6419
3.0645
3.9276
3.0136
3.4482
3.0904
3.3431
3.2292
3.0075
2.9769
3.9351
5.3562
3.0701
2.9619
3.0148
3.2092
3.6702
3.0179
3.1777
3.0232
3.5361
4.2899
3.3235
2.995
3.1947
3.5109
3.2397
3.0694
2.976
3.6023
3.072
2.9169
4.0195
3.6325
3.6008
3.3343
2.9251
2.961
3.2032
3.4727
2.9746
3.0744
3.0191
4.202
4.2168
2.9592
3.1731
2.972
3.5655
3.4831
3.023
2.9941
3.1596
3.8404
4.0109
3.6492
2.9666
3.7196
3.1464
2.9987
3.6083
2.9724
3.7615
3.5232
3.0441
3.3111
4.3207
3.1292
3.1431
2.9821
2.9808
3.8142
3.0419
2.9746
3.1532
3.0348
3.5443
4.0558
3.0049
3.0538
3.4497
3.3057
4.0674
3.2404
3.027
3.4607
3.1039
3.0331
3.8913
4.131
3.4539
2.9778
2.9883
3.3095
3.5211
3.2498
3.1544
2.9727
3.0372
4.1724
3.171
3.0407
3.2478
2.9849
3.64
3.9247
2.9856
3.1112
3.5022
3.7887
3.5842
4.4616
4.0043
4.3038
3.9645
5.0566
4.3213
4.0982
4.5617
4.1561
4.2025
3.9885
3.9682
2.9631
4.63
2.9398
3.1637
3.158
3.15
4.0397
3.1428
2.9797
3.0093
3.7116
3.3026
4.088
3.0038
3.2246
4.1207
3.7549
3.2661
3.2486
3.1844
3.3327
3.4227
3.0747
4.3318
3.6201
3.2518
3.1928
3.2514
3.3922
3.4414
2.9721
3.1087
3.4306
3.4085
4.5604
3.4415
3.2666
3.4576
3.3706
3.6012
4.0528
3.1184
4.0361
2.9358
3.4203
4.9622
3.9272
3.2579
3.1734
3.2493
3.6815
3.1823
3.2138
3.3125
2.9798
4.0748
3.0997
3.2405
3.2036
2.9715
3.6039
3.1176
2.9681
2.8968
3.7967
3.2282
4.2759
3.1067
3.1937
3.6383
3.1264
2.9935
3.6269
3.2396
3.5434
3.5059
2.9855
3.7933
3.7184
3.1453
3.2052
2.9881
3.1835
3.868
3.2467
3.0395
3.3554
3.0033
3.7101
3.0594
3.0328
3.3645
3.0632
3.35
4.064
3.2065
2.9761
3.8937
3.1022
3.0054
3.7963
3.0131
3.9685
3.0738
3.2243
3.8316
3.6871
3.1431
3.1843
2.9744
2.9448
4.1188
3.0305
3.0864
3.1776
3.043
3.5373
3.7279
3.0063
3.2087
3.835
3.0703
3.5797
2.9899
3.1433
3.5535
3.0157
3.0411
4.4593
3.0867
3.5163
2.9931
2.9277
3.2175
3.4616
3.1887
3.1298
3.0343
3.1149
4.138
3.2011
2.986
3.2511
2.9853
3.5619
3.9639
3.0295
3.0354
3.1843
3.6753
3.8045
3.5464
3.0355
3.4837
3.1237
2.9273
3.9893
4.3366
4.5524
3.9472
3.0392
4.5568
3.2273
3.1032
3.1136
2.9771
3.6553
3.2531
3.0401
3.1063
3.0063
3.6448
4.2312
3.2413
3.0356
3.352
3.5414
3.4568
3.0509
3.021
3.8236
3.1645
3.2112
4.1567
3.3052
3.6474
3.3278
2.9913
3.0793
3.134
3.2608
3.2623
3.0344
3.4951
4.3987
3.9408
2.9534
3.4809
3.3848
3.6096
3.0165
3.1047
3.0921
3.4404
3.6876
4.1569
4.565
3.6152
3.1663
2.9808
3.4829
3.108
3.7017
3.6842
3.1817
3.2092
3.5442
3.2634
3.1009
3.3488
2.9631
4.4124
3.0839
3.2359
3.2317
3.0224
3.7646
3.1651
2.9989
3.0382
3.6343
3.2091
3.8166
3.0271
3.2057
3.6995
3.0807
3.3569
3.5648
3.2176
3.7449
3.5666
2.9319
4.1324
3.5391
3.2292
3.1411
3.0615
3.1494
3.7538
3.2408
2.9667
3.3565
2.958
4.2504
3.1502
3.0278
3.2696
3.3399
3.6064
3.4007
3.2341
3.0297
3.5427
3.0246
2.9147
4.2462
3.0444
3.9741
3.138
3.4561
3.4352
3.6596
3.1543
3.3905
3.1657
2.9577
4.1731
3.0234
3.2237
3.1538
3.0578
3.9726
3.2002
3.0229
3.1159
3.7464
3.1719
4.3702
3.0101
3.2302
3.6992
3.0803
3.0579
3.2072
3.3273
3.3165
3.2628
3.0443
4.3208
3.7425
3.1791
3.2403
3.2287
3.207
3.3355
3.0293
3.2078
3.1394
3.4974
4.3019
3.0332
3.2126
3.2188
3.7294
3.3613
3.1842
2.9738
3.6073
3.3529
2.9437
3.9961
2.944
3.806
3.2734
3.307
2.9896
3.2975
3.2242
3.0058
3.2622
3.0518
4.5788
3.1802
3.2349
3.1944
3.1006
3.8291
3.1136
3.1383
3.031
3.811
3.1867
4.1603
3.0337
3.207
3.5851
3.1091
3.0328
3.5347
3.1777
3.493
3.406
3.0683
3.4692
3.4784
3.2939
3.2219
3.0287
3.3974
4.2713
3.2613
3.0259
3.4038
2.9902
3.8424
3.0558
2.969
3.2301
3.4226
3.2219
3.8824
3.2166
2.9474
3.9715
3.1656
3.0171
3.5989
3.002
3.6328
3.1531
3.306
3.2348
4.4063
3.1425
3.232
2.9834
3.012
3.7972
3.0311
3.1818
3.071
2.9622
4.1695
5.2877
3.7136
3.7174
3.2444
3.5601
3.0838
2.9858
3.8608
3.7777
3.3468
3.4631
3.6989
3.6311
3.05
3.214
3.9035
3.8471
3.4306
3.2972
3.3265
4.0196
3.4953
3.278
4.1435
4.677
4.1166
3.079
4.7907
3.5547
3.2136
3.0115
3.451
3.0279
4.9465
2.9997
3.0017
2.9694
2.9957
3.8557
3.0999
3.3404
3.179
4.0378
3.3894
4.3018
3.3418
3.4217
3.6339
3.4431
3.6457
3.563
3.594
3.486
3.5459
3.9982
3.6744
3.7571
3.8699
3.3737
3.9477
3.4336
3.1642
3.4854
3.654
4.0072
3.5386
3.4071
3.267
3.6972
3.2388
3.8624
3.2649
3.762
4.0099
3.1161
5.115
3.6249
3.7972
3.3066
3.1807
3.7347
3.7805
3.358
3.2983
3.3297
4.0267
5.3991
4.0198
3.0279
3.5803
3.978
2.9327
3.1903
3.0784
3.6699
3.1045
3.8535
3.0569
3.4799
3.1817
3.0109
3.5972
3.0181
3.7969
3.17
3.3151
3.0366
4.2379
3.2172
3.1541
3.0246
2.9958
3.7133
3.2546
3.1833
3.0137
3.1444
3.465
4.3437
2.978
2.9774
3.2376
3.4149
3.0185
3.2771
3.1588
3.42
3.3942
2.9949
4.2176
3.0275
3.5359
3.2515
2.9904
3.1884
3.5851
3.8331
3.0156
3.0274
3.3774
3.9389
3.6128
3.0403
3.2546
2.9777
3.7839
3.7857
3.0867
3.0333
3.0142
3.6904
3.8349
3.4362
2.991
3.5392
3.2241
3.0955
3.6131
2.9833
3.7026
3.1234
3.135
2.9886
3.7282
3.5213
2.9676
3.0956
2.9986
3.2249
3.3293
3.0851
3.0296
3.1309
3.6568
3.8622
2.9587
2.9906
3.2547
3.8247
3.456
4.9115
3.143
3.7525
3.0318
3.2398
3.1422
3.349
3.2132
2.9696
3.0169
3.7915
3.6088
3.2492
2.9918
3.0191
3.0103
3.948
3.0915
3.0222
3.1124
3.0161
3.599
3.2453
2.9955
2.9625
3.0912
3.4022
3.4138
3.0657
3.0393
3.4924
3.1564
2.9999
4.1798
3.0383
3.6747
2.9737
2.9976
2.957
4.2968
3.4468
3.1937
2.9866
2.9627
4.0164
3.2272
2.9733
3.067
2.9528
3.5662
3.7433
2.9968
3.0069
2.9938
3.5358
3.1625
4.4919
3.6343
3.611
3.1909
2.928
3.5321
3.0628
3.5882
3.2009
3.046
3.2632
4.4257
3.6558
3.0734
3.0164
2.9568
3.5029
4.6701
3.2551
3.0738
2.9951
3.6143
5.7205
3.1972
3.0465
3.6302
2.9843
3.2755
3.5297
3.5352
3.4917
3.785
4.3145
2.9871
3.6167
3.0107
3.0854
3.6181
3.3222
3.2804
2.9921
2.9529
3.8273
4.8729
2.994
2.9939
3.0628
3.0023
4.2364
3.238
3.0257
3.0673
3.3639
3.3191
3.7262
3.0366
2.9746
3.7324
3.2071
4.6526
3.7097
4.1169
4.325
3.9735
4.4502
4.8489
4.0747
4.0931
4.3187
4.1336
3.9784
4.0877
4.0829
4.0555
4.3857
3.9547
4.1246
4.3622
3.9908
4.1078
4.2332
4.0123
4.2636
4.2409
4.3787
4.0166
4.0979
4.2911
3.9443
4.0491
4.0025
4.7244
4.0687
4.1466
3.9802
4.4933
4.4053
4.6537
4.7044
4.3993
4.2263
4.1571
4.4179
4.1769
5.4317
4.4062
3.9971
4.0368
4.4663
4.2739
4.0764
4.0708
4.0209
5.2155
3.9742
4.1219
4.1806
4.6401
3.8916
3.9183
4.376
4.0583
5.1596
4.4452
4.4046
3.9621
4.1579
4.1565
4.1327
4.0453
4.4663
4.8135
4.0119
3.9417
3.9863
4.5425
4.1598
4.0389
3.9538
4.388
5.0436
4.4825
4.217
4.0726
4.1816
3.9868
4.2344
3.9609
4.9549
4.0584
4.1013
3.9969
4.01
4.2423
4.281
4.0872
3.9786
4.813
3.9896
4.054
3.9873
4.1351
4.2043
4.1669
3.9809
4.0894
4.0486
3.8562
4.0225
4.0629
3.9621
5.1186
4.1504
4.0056
4.0025
3.9498
4.3374
3.8877
4.0334
3.9854
5.2815
3.7624
4.0278
3.95
4.0164
4.3152
4.0049
3.9841
3.998
4.6795
4.0367
4.2075
4.0724
3.9049
4.1159
3.9355
3.9869
3.764
4.2546
4.2409
3.9991
4.003
3.9087
4.2954
3.9672
4.1119
3.8398
4.2207
4.225
4.1198
3.9229
4.0697
4.3049
4.1478
4.1774
4.0458
4.0087
4.6305
4.1072
4.0691
3.962
4.3288
4.2045
4.0811
3.9793
4.1962
4.0827
4.1127
3.9735
4.2258
4.1818
3.881
3.9374
4.2465
4.0183
3.8912
3.89
4.2806
3.95
4.1126
3.8174
3.6425
3.3598
3.0554
3.1398
3.6872
3.224
3.065
3.0021
3.0562
3.9161
3.1991
2.9944
3.2118
2.959
3.6575
4.3119
3.0718
2.9864
3.0697
3.4965
3.3591
3.0867
3.0342
3.3971
3.2892
3.0152
4.0903
3.0114
3.5706
3.1344
3.1618
3.0261
3.6192
3.5775
3.0284
3.179
2.9974
3.0447
4.4788
3.2084
2.9802
2.9403
3.1012
3.5865
3.1804
2.9697
3.1171
3.449
3.2246
3.6008
3
3.1021
3.463
3.2941
2.9819
4.4489
4.2237
3.4193
2.9858
3.0074
3.5228
3.3342
3.1883
3.0218
3.0979
3.0582
4.9607
4.551
3.0668
2.948
3.4839
3.7274
3.044
3.1159
2.9804
3.6528
3.0531
4.3906
3.0143
3.0837
3.4305
2.9992
3.5803
2.9939
3.3417
3.2102
3.0097
3.0367
3.9244
3.3085
3.1652
3.2292
3.0322
3.0704
3.7452
3.0244
3.0597
3.0832
3.0442
3.5216
4.516
3.0007
3.0185
3.42
3.236
3.5577
3.0864
3.494
3.768
3.6346
3.0332
4.4353
3.2971
3.4743
3.0201
2.9673
4.1025
4.0784
2.9401
3.016
3.2447
2.9446
4.7884
3.0015
3.28
3.1614
3.2508
4.1007
3.0576
3.1796
3.0749
3.6209
3.1819
4.2836
3.0626
3.4325
3.2469
2.9298
3.6095
3.07
3.8258
3.4874
3.0816
2.9888
4.6354
3.2169
3.0859
3.8297
3.0044
4.1609
3.174
3.2888
3.1056
3.1748
3.4938
3.8682
2.9569
3.4407
3.5988
3.2995
3.5318
3.0118
3.2565
3.6499
3.2375
2.9922
3.4541
3.4313
3.411
2.9357
3.059
3.5992
3.5691
3.3746
3.0778
3.0808
3.0046
4.6071
2.9553
3.0389
3.0426
3.0795
4.0957
3.073
3.1395
3.0256
3.7088
3.1494
3.7126
3.0248
2.9987
3.72
3.0109
2.9893
4.7129
3.4721
3.2142
2.9892
3.0113
3.4959
3.5209
3.1321
3.0513
3.0153
2.9936
4.4083
3.0057
3.0058
3.0079
3.005
3.5394
3.7234
2.9442
3.0185
3.0498
3.6073
3.6737
3.0893
3.0054
3.5775
3.3609
2.9876
3.6801
3.0491
3.6354
3.2449
2.9719
3.0005
4.5186
3.4059
3.0675
3.0237
2.9698
3.6229
3.3585
3.0364
2.9983
2.9779
3.362
4.2146
4.1167
3.0476
3.0978
3.583
3.1922
4.0017
4.2079
4.473
4.0577
5.4077
4.3771
3.2129
3.0126
3.0176
4.1662
4.5639
4.0502
4.6661
3.4047
3.2428
2.9854
2.972
3.0051
3.0652
3.8725
3.4649
3.0097
3.03
3.6267
3.059
3.6744
3.049
2.9703
3.5639
2.9893
3.0064
3.7128
2.9551
3.6893
3.0613
3.0271
3.8213
3.8414
3.2384
3.0031
3.2493
3.0111
4.079
2.999
2.9701
3.2805
2.9835
3.9233
3.1168
3.2013
3.0628
3.5453
3.241
3.4946
3.2231
2.9567
3.6992
3.1658
3.0198
4.1321
3.0636
3.6257
3.0262
3.22
3.288
3.4799
3.296
3.1432
2.9943
3.015
4.229
3.204
3.8349
3.012
3.4188
4.4251
3.18
2.9958
3.2732
3.3719
3.1155
3.6082
2.98
3.2269
3.3547
3.2592
3.0049
4.4017
2.9255
3.8966
3.1173
3.0024
3.3457
3.5365
3.311
3.0992
3.0136
3.0458
4.7559
3.1447
3.023
3.1578
3.0092
3.8835
3.1293
3.1661
3.068
3.1218
3.2233
4.0084
3.2461
2.9789
3.8323
2.9809
3.1555
3.4866
3.0279
3.645
3.0841
3.3569
3.093
3.5693
3.3035
3.2652
3.07
2.9485
4.0892
3.1687
3.0162
2.9971
3.1605
3.5015
4.2648
3.0169
2.9717
3.0071
3.6559
3.3805
2.9822
3.0188
3.2991
3.1685
3.0204
3.7646
3.0401
3.3355
3.2752
3.0057
3.0486
3.55
3.5792
3.1327
3.048
2.9653
2.9764
5.0197
3.3434
3.1237
2.9694
3.082
4.009
3.0454
3.2246
3.0383
3.5957
3.1674
4.1722
3.0446
2.983
3.6251
2.9961
3.2177
3.1353
3.163
3.188
2.9956
3.3398
3.9145
4.3772
3.4665
3.1375
2.9459
3.1014
3.1159
3.1523
3.0716
3.1229
3.8235
4.8749
4.1481
3.3181
3.6359
2.9697
3.5501
3.1452
3.1017
3.7061
3.133
3.7544
3.0407
3.524
3.065
2.9831
3
3.4952
3.6469
3.0054
2.9856
2.9781
2.9755
4.0519
3.0183
3.0109
3.1427
2.9732
3.9306
3.0922
2.9935
3.0206
3.3567
3.2477
3.7727
2.9852
3.034
3.673
3.189
3.0202
4.2558
2.932
3.6532
3.0412
3.2368
3.2524
3.3283
3.1459
3.1689
2.9767
2.893
4.2627
3.1878
3.2833
3.0812
3.5498
4.1415
3.2423
2.9576
3.0623
3.0884
3.2867
3.9057
3.0004
3.1715
3.4337
3.2297
2.9572
3.6761
3.0151
3.5096
3.4507
3.0573
3.1807
3.9549
3.3512
3.0349
3.01
3.0258
3.3374
3.3001
3.0292
3.0126
2.9782
3.404
4.0785
2.9502
2.9781
3.0459
3.4771
3.1515
3.6377
3.0647
3.0079
3.5921
2.9757
3.3658
5.2505
4.294
3.9228
4.0246
4.4189
3.8658
2.9496
3.0167
2.9445
3.0101
3.4297
2.9915
3.0485
3.0238
3.4057
3.5203
3.0315
3.0596
3.0529
3.465
3.1344
3.8628
2.9964
2.958
3.6638
3.1037
2.9686
3.6029
3.0003
3.6237
3.0932
2.9625
2.9644
4.7078
3.1835
3.0055
2.9855
2.9679
3.6122
3.3709
3.0414
3.0047
3.0079
3.4797
4.4259
3.0016
2.922
3.027
3.5687
2.9996
3.7836
3.0263
3.0695
3.7303
3.0114
3.963
3.0858
3.5867
3.2399
2.9518
3.0269
3.6796
3.4975
3.1498
3.0592
2.9995
2.9793
3.9692
3.0255
2.9562
3.059
3.0086
3.6683
3.1925
3.0399
2.9735
3.4203
3.261
3.6282
2.9989
3.0075
3.5656
3.2111
3.01
4.2182
3.4977
3.6304
2.9674
3.0196
3.3785
3.6091
3.1357
3.0717
3.0853
3.0361
4.5605
4.1527
3.0185
3.0704
3.0074
3.909
3.0269
3.2417
3.0177
3.2916
3.2034
4.1744
3.0062
3.0374
3.5181
3.2087
3.2044
3.4375
2.9723
3.6202
3.0732
2.937
3.1439
4.4608
3.1703
3.2128
3.0167
3.0244
4.0747
3.0512
3.02
3.0589
2.9999
3.9208
3.2135
2.919
3.1498
3.2943
3.1582
3.6604
2.976
3.1421
3.5954
3.3371
2.9539
4.2888
2.976
3.4886
3.3036
2.9993
3.3129
3.3636
3.2492
3.0554
3.0037
3.2554
3.8963
3.1574
3.0442
3.152
3.0033
3.2959
4.6969
3.5457
3.101
3.1625
3.6327
3.9519
3.7396
2.9486
3.7527
3.0489
3.1732
3.567
3.0794
3.6109
2.9881
2.9687
3.6314
4.1083
3.0909
3.1743
2.9331
2.9496
4.0017
3.0375
3.0258
2.9766
2.9937
3.4121
4.173
2.9393
2.9486
3.3764
3.6979
3.2852
3.0676
3.0266
3.1447
3.1375
2.9674
3.3326
3.1184
3.4853
3.278
2.991
2.9964
4.1961
3.6965
3.1265
3.0266
2.9427
3.022
4.1673
2.9871
3.0014
2.9655
2.9726
3.676
3.0865
2.987
3.0032
3.1161
3.3862
3.3481
2.995
3.0178
3.0907
3.1785
2.9472
3.7876
3.4346
3.6291
3.1917
2.9585
2.9932
3.4657
3.5592
3.0646
3.2173
3.0829
3.4004
3.5708
3.0094
3.0313
2.948
3.4757
3.7222
3.2086
3.0585
3.0985
3.8162
3.1191
4.4545
3.4803
3.4344
3.2547
3.1595
4.6164
4.5584
4.1357
3.9794
4.7344
4.5355
4.0245
4.0216
4.0776
4.3868
3.6729
2.9753
3.0288
3.1202
4.6519
4.3805
3.0547
2.9824
3.7834
3.2862
3.1411
3.0242
3.3922
3.1968
3.0144
3.9771
3.5564
3.9762
3.0561
2.9623
2.9545
3.585
3.5867
3.0561
2.9996
3.0081
4.0944
3.5999
2.9677
3.0188
2.9689
3.6016
3.7894
3.0093
3.0111
3.1043
3.5296
3.0025
4.8625
3.0163
3.3272
3.1201
2.9795
3.7573
3.007
3.5153
3.193
2.9794
2.9987
3.9275
3.5044
3.0118
3.022
2.8865
3.0154
3.8153
3.0284
3.0075
3.0117
3.0209
3.4251
4.7749
3.0177
2.9936
3.3626
3.2349
3.4141
3.0317
2.9844
3.6076
3.1536
2.9397
3.6845
3.089
3.7106
3.019
3.2125
3.0097
4.8765
3.1256
3.0966
3.0046
3.0258
3.9139
3.0052
3.0288
3.0985
3.1847
4.003
3.2484
2.9596
3.0635
3.0442
3.3473
3.5152
3.0664
3.0064
3.5817
3.1353
2.9863
4.1723
3.0295
3.5918
3.0688
3.0054
3.0049
3.6574
3.803
3.0385
3.0486
3.1795
3.7015
4.3254
4.1704
4.0165
4.2877
4.258
3.9403
4.0481
4.3191
4.6846
4.0491
3.7876
3.7159
3.0084
3.3668
3.1028
3.296
3.2752
2.9921
3.2604
4.2589
4.1096
3.0456
3.1041
3.0468
3.1838
3.5398
3.0147
3.0236
3.0115
3.4598
4.642
4.3544
3.02
3.1916
3.3997
3.4354
3.1044
3.2568
3.7051
3.1956
2.98
3.8108
3.071
3.5018
3.1118
2.9437
2.9854
3.5439
3.5638
2.9631
3.0415
3.0135
3.0287
4.8878
3.0262
3.0577
2.9378
3.4276
4.0788
3.6702
3.038
3.0626
3.7721
3.0673
3.7166
3.0383
3.4763
3.0417
3.0769
3.5159
3.0583
3.4835
3.2115
2.898
2.9205
3.8489
3.5842
3.0107
3.0534
2.9681
2.9877
4.1822
2.9642
2.9717
3.1095
3.9694
4.9419
3.8693
4.0782
4.4133
3.885
3.9236
4.062
4.0922
3.9391
4.2919
3.0212
3.5642
3.1948
2.9875
2.9361
4.5629
3.4838
3.0127
3.0272
2.9767
3.664
3.3056
2.9771
2.9924
2.9896
3.1457
4.3177
3.4015
3.0129
3.0455
3.6664
2.956
3.7588
3.073
3.0497
3.7871
3.0058
4.0332
3.1605
3.3678
3.2483
3.0428
3.0293
3.5066
3.5641
3.1512
3.0677
2.9493
3.0048
4.6537
2.9569
2.9704
3.0625
3.0155
3.6273
3.0897
2.9677
3.0327
3.0906
3.4596
4.079
3.0005
2.9753
3.4764
3.1452
3.0347
3.5812
3.0444
3.5832
3.0609
3.0611
2.9605
4.4581
4.2327
3.0177
3.0101
2.9659
3.8405
3.1666
2.9976
3.0344
2.9782
3.5446
4.8299
3.2655
2.9856
3.0201
3.3094
3.4263
3.0724
3.0101
3.2263
3.1357
3
3.8038
4.7475
3.5893
3.1277
2.997
3.3155
3.4729
3.2452
2.9895
2.9173
2.973
3.9163
3.4
3.0301
3.0458
3.0438
3.5586
3.6543
2.9915
2.9933
3.0329
3.5603
3.1817
3.9558
3.0419
3.0056
3.6379
3.0178
3.2431
3.1522
3.1573
3.3523
2.9827
3.0196
3.9066
3.754
3.1946
3.0522
3.0748
3.0365
4.1365
4.0711
4.1025
3.9924
4.2392
4.1996
4.0132
4.0568
4.6528
3.9438
4.2981
4.3248
4.2008
4.0966
4.0461
4.674
4.4816
3.9191
4.6388
4.0348
4.6066
4.504
4.6522
4.1441
4.4622
4.5648
5.1077
4.3175
4.3685
4.2363
4.8835
4.296
4.3508
4.2766
4.9531
4.0379
4.0769
4.0292
4.0142
4.2505
4.0585
3.2483
3.0748
2.9824
4.5337
3.8882
2.944
3.0253
2.963
3.4251
3.7202
3.0432
3.0107
3.0947
3.5325
3.1822
3.2967
3.0167
3.4783
3.1031
3.034
3.5871
3.0558
3.5858
3.169
2.9564
2.9356
3.9536
3.6387
2.9417
3.1097
2.9997
2.962
4.1975
2.9631
3.0067
3.0957
3.0906
4.3412
2.8906
2.9905
3.0139
3.4278
3.0603
3.497
3.0811
3.2612
3.5792
3.1667
3.0969
4.5005
3.0512
3.4172
3.0552
2.9902
3.4796
4.291
3.175
3.03
3.0113
2.9727
4.3789
3.1002
3.01
3.0301
3.0492
3.9186
3.9818
2.9844
3.0669
3.4149
3.2241
4.0703
3.0341
2.9214
3.6142
2.9623
3.0496
4.7166
3.5
3.1119
3.0101
3.021
4.5286
3.4117
3.1525
2.996
3.0527
3.3769
3.1249
3.0112
3.7767
3.1277
4.3099
3.4854
2.9731
3.0439
3.0635
3.6505
3.5063
4.6645
3.0451
3.6411
3.0428
2.9168
3.7029
3.0093
3.3855
3.0395
3.0703
3.4655
3.4371
3.3414
3.0561
2.9675
2.973
3.7044
3.1174
2.9151
3.0143
2.9842
3.5637
4.3215
3.084
2.9169
3.0037
3.521
3.0232
3.8691
3.0374
2.9801
3.6641
3.0163
3.9193
2.9224
3.4293
3.1943
2.9397
3.0593
3.9981
4.3176
3.0636
3.0654
2.9798
3.2471
3.333
2.9579
2.9737
2.9527
3.0551
3.755
3.0553
3.0083
3.1023
3.5096
3.192
3.6642
3.0594
3.0409
3.6433
3.1333
3.003
3.5228
3.0697
3.48
3.0704
2.966
2.9208
3.7577
3.7222
2.9892
3.0395
2.9629
3.1414
3.4688
4.3222
3.4019
2.9767
3.4911
4.7384
4.3169
3.4687
3.5903
2.9683
3.1344
2.9963
3.3161
3.2911
3.0101
3.7624
2.9942
3.3624
3.0913
3.0308
3.0212
3.5014
3.4823
3.1499
3.6569
3.0517
3.2601
4.4599
2.9604
3.0713
3.0005
3.2172
3.728
3.5577
2.9921
3.0491
3.5827
3.1455
3.6067
3.0882
3.0385
3.7093
2.9492
3.0005
3.9806
4.5254
3.4611
3.0384
2.9313
3.5106
3.4788
3.1459
3.0219
3.0084
3.0264
3.9985
3.1109
2.9734
2.9923
2.9891
3.7133
3.2384
3.0673
3.0182
3.0901
3.1795
3.5312
3.0715
2.9701
3.1715
3.2541
2.9902
3.5097
3.6443
3.5912
3.1604
2.9933
2.9974
3.6142
3.7264
3.0393
3.0566
3.0558
2.9997
4.3168
3.0033
3.0498
2.9828
3.0056
3.3603
3.4418
4.1258
3.0319
3.5845
3.1571
3.6476
3.0012
2.9883
3.5382
3.1782
3.0169
3.1126
3.3721
3.3165
3.0723
2.9894
3.3603
3.394
3.0419
2.9932
2.9936
3.0506
3.7204
3.1909
2.9986
3.1033
3.0533
3.3877
4.1057
3.072
2.9564
3.0813
3.5682
2.9572
3.8982
2.9814
3.0043
4.0172
4.1474
3.7753
2.9782
3.6917
3.0772
3.0069
3.3143
3.3496
3.0975
3.026
2.9739
3.0542
3.4941
3.2919
3.0475
3.0635
3.0369
3.7402
3.6752
3.0378
3.0093
3.0164
3.3754
3.1983
3.5532
2.9788
3.2212
3.588
3.4387
4.604
4.0425
3.5877
3.2175
3.0148
3.0091
3.4502
3.7215
3.1647
3.0563
3.011
3.24
3.4067
2.9534
3.0519
2.9675
3.0363
3.8903
3.2999
3.0146
3.0234
3.2458
3.1872
3.6937
3.8327
2.949
3.6492
2.9312
2.9441
3.69
2.9725
3.8278
3.0881
2.9731
3.2307
3.513
3.2841
2.9963
2.9383
3.0311
3.6168
3.2413
2.9579
3.0045
2.9521
3.325
3.6948
2.9998
2.9908
3.0039
3.5178
3.1414
3.598
2.9872
2.9415
3.5439
3.1089
3.0202
3.7551
3.0069
3.7747
3.0685
3.0143
2.9432
3.7539
3.2592
3.005
3.0287
2.9748
3.4142
4.2476
3.8962
3.8681
4.1531
4.3471
3.9917
4.7162
4.2042
3.9804
4.4872
4.7915
4.6401
4.3973
4.5628
4.987
4.6523
5.2627
6.3665
5.3761
6.2507
7.372
5.7864
4.2609
4.94
4.3172
4.4201
4.288
4.2133
3.9515
4.0431
4.2264
3.9444
4.1572
4.1124
4.184
4.123
3.912
4.7546
4.5556
4.5744
4.2596
4.4123
3.9392
5.26
5.5022
5.908
5.8569
5.1832
4.9239
4.5925
4.7193
4.7663
4.9385
5.3865
4.7998
4.8122
5.7094
4.8476
5.0124
4.8634
4.9331
4.7134
4.7872
5.4173
4.7404
4.8496
4.5807
5.2503
4.4422
4.5923
4.4393
4.2912
4.2621
4.6374
4.0791
3.0185
3.2452
3.0766
3.2527
2.9914
2.9462
3.0436
3.4799
4.1566
4.1576
3.1001
3.0064
3.5474
3.1874
3.0308
2.9565
3.0883
3.4632
3.5425
3.6912
3.046
3.5314
3.0343
2.9403
3.6158
3.024
3.5987
3.1628
2.9939
2.9468
3.6525
3.726
3.0064
3.0283
2.9967
3.1621
4.9453
5.6812
4.4516
5.2736
4.1353
4.1441
4.6485
4.4554
4.3737
4.3959
4.5426
4.4629
4.5733
5.2043
4.3365
4.3827
4.7667
4.6876
4.5346
5.5803
8.7785
8.0922
4.8005
4.2231
4.4162
4.526
4.5518
4.5007
4.4444
4.1899
4.5154
4.3319
4.827
4.3034
4.5415
5.3496
3.9524
5.0899
5.2745
4.6444
4.9233
4.912
5.2221
4.6174
4.5711
4.9503
5.1654
4.7236
5.1477
4.8203
5.1531
4.8909
4.6322
4.8328
5.4224
4.5754
4.9066
4.7
4.8626
4.6416
4.7188
4.9062
4.9828
4.0422
4.4355
4.1658
4.1169
3.9304
4.2033
4.1036
4.5956
4.4221
4.4812
4.1824
4.5576
4.3356
3.9237
4.0608
3.8638
4.8057
3.1688
3.0184
3.0933
3.037
3.9572
3.9822
3.9165
3.1504
3.6006
3.0139
3.1082
3.027
3.0965
3.5042
2.9392
3.2877
3.1226
3.3564
3.3362
3.067
2.9952
3.5753
3.5513
3.1646
3.0105
3.0127
3.0083
3.9257
3.0899
2.951
3.0771
2.9648
3.689
3.6349
3.0179
2.9989
3.0577
3.7226
3.3425
4.2178
3.8183
4.2388
3.9938
4.3081
4.9516
4.0274
4.0252
4.4017
4.7139
4.4595
4.7465
5.9599
4.5803
4.2316
4.3823
5.0983
4.4207
4.4261
4.6842
5.8831
4.856
5.4875
4.6625
5.1227
5.0177
4.3898
4.5205
5.0508
4.6552
4.2769
4.3363
4.6389
3.1385
2.9867
3.0811
3.004
3.2903
3.5464
3.0786
3.0186
3.0877
3.8563
4.119
4.0365
2.9687
3.5634
3.0627
3.2932
4.1646
3.4238
3.7766
3.2923
3.367
3.5978
4.0432
3.0055
3.5771
3.0428
3.6997
3.5107
3.0778
3.3386
3.385
4.0792
4.4145
3.5088
4.1108
3.7125
3.459
3.0231
3.251
3.7621
3.556
3.2917
3.8112
3.205
4.002
3.2574
3.3137
3.9133
4.2441
4.2623
4.0174
4.2897
4.5992
5.1074
4.281
4.3659
4.7865
4.8847
5.2304
5.5017
4.6456
4.7747
4.779
4.948
4.4757
4.8199
5.5117
5.6182
5.9667
5.2378
5.1176
4.972
4.9354
4.7664
5.4178
4.1866
4.2276
4.4108
4.2062
4.4568
5.0015
3.796
3.2279
3.9477
3.27
3.8408
3.3284
3.3231
3.2583
3.8662
4.3108
3.3716
2.9673
3.0006
4.0563
3.0222
3.035
3.0722
3.031
3.8057
3.0579
3.0336
3.0113
3.0384
3.3243
3.3846
3.0828
3.0805
3.4599
3.2552
3.036
3.5511
3.0313
3.4244
3.0799
3.025
2.9796
3.6487
3.8102
3.125
3.1687
2.9997
2.977
4.0274
2.9819
2.952
3.0663
2.9465
4.0099
3.7574
3.0391
3.0469
3.5385
3.1701
3.5584
3.0163
3.3008
3.6282
3.0645
3.0212
3.1811
3.1178
3.2472
3.0284
2.981
3.2241
3.3892
3.3519
2.9771
2.9859
3.0291
3.6802
3.2072
2.9734
3.055
2.998
3.3338
4.0545
3.0065
3.0325
3.079
3.4806
3.1539
3.6224
3.0098
2.9457
3.584
3.0534
3.016
3.0842
3.0625
3.4046
2.9939
2.9925
3.3769
4.3157
3.1393
3.0832
2.9906
3.0343
4.0743
2.9474
2.9366
3.093
2.918
3.3748
3.6212
3.0054
2.881
3.0172
3.5728
2.9677
3.5299
2.9963
2.9907
3.6568
2.9508
3.2769
3.0856
3.1814
3.3095
2.9704
3.0025
3.6698
3.6204
2.9453
3.0632
2.9891
2.9678
3.8209
3.1432
3.0131
3.0896
3.0165
3.4471
3.5444
3.0045
3.007
3.0682
3.5213
2.9901
3.1277
2.955
3.1556
3.4059
3.0279
3.4143
3.1075
3.3867
3.2838
3.0398
2.9768
3.5518
3.6074
3.1552
3.0364
2.9975
3.0121
4.0842
2.939
2.9759
3.0356
3.0008
3.5765
3.2691
3.0216
3.0622
3.3238
3.4222
3.5349
3.2624
2.9821
3.2997
3.2463
3.2247
3.5016
2.9304
3.2974
3.3313
2.9751
2.9951
3.9658
3.6294
3.8721
3.0085
3.597
3.5908
3.5805
3.2906
3.4526
3.5578
4.4231
3.1061
3.0452
3.5779
3.5359
3.518
3.5311
3.2072
3.005
3.9003
3.0291
3.3236
3.0702
3.4817
3.0844
3.032
3.2755
3.4113
3.6715
3.1497
3.2138
3.0014
3.017
3.9857
3.2128
3.5245
2.9973
3.4669
3.9805
3.125
3.0021
3.0513
3.4982
3.2447
3.6455
2.9847
3.114
3.5257
3.2637
2.9882
3.6376
3.1405
3.6234
3.2252
3.0295
3.098
3.669
3.2651
3.016
2.9905
3.1599
3.7309
3.3426
3.0317
3.0931
3.0191
3.3575
3.8736
3.0201
3.0951
3.0965
3.7482
2.9494
3.7733
3.0134
2.9737
3.6481
3.0217
3.3812
3.1145
3.175
3.191
2.9393
3.1326
3.4557
3.3963
3.2219
3.2191
3.0069
2.9946
3.9977
3.119
3.1844
3.0986
3.1048
3.4944
3.6896
3.0524
3.0145
3.1649
3.7565
3.2884
3.0117
3.0914
3.142
3.2977
3.0176
3.4589
3.0494
3.3746
3.3504
3.009
2.9759
3.6292
3.6386
3.1984
3.0607
3.0919
2.9404
3.8622
3.1618
3.0117
3.3109
3.0121
3.963
3.1108
3.1007
3.012
3.0422
3.5776
3.58
3.1118
3.0843
3.6311
3.1749
2.9752
3.541
3.0464
3.5768
3.1091
2.9842
3.0228
3.7379
3.6472
2.9432
3.0017
3.024
3.0431
3.9438
2.9594
3.0405
3.0852
3.4603
3.9514
3.3051
3.0585
3.1052
3.4543
3.1286
3.6276
3.0145
3.2039
3.5581
3.31
2.9014
4.0075
3.0825
3.6658
3.2284
3.0171
3.5411
3.4518
3.3027
3.0345
3.0492
3.0925
3.9388
3.263
3.0427
3.2458
2.9878
4.1979
3.3818
3.121
2.9985
3.4724
3.361
3.4486
3.1837
2.9701
3.7321
3.1891
2.9657
3.67
3.0132
3.5044
3.0874
3.2003
2.9744
3.7355
3.5174
3.0307
3.2045
2.9873
3.9589
4.0594
3.1924
3.0914
2.9746
3.6095
3.3508
2.9334
2.9661
3.3193
3.3518
3.5385
3.0285
3.1483
3.326
3.2404
3.1458
3.6138
3.1482
3.628
3.2273
2.9665
3.109
3.8119
3.6708
3.2706
3.0493
3.1022
3.1913
3.3228
3.0038
3.0852
3.0046
3.3214
3.5723
3.0548
3.0528
3.0468
3.4411
3.1233
3.473
3.0117
2.9757
3.4991
3.0732
3.0497
3.4796
3.0551
4.6792
5.2947
4.7376
4.8269
4.4246
4.0587
3.9642
4.1277
3.0232
3.2752
3.3092
3.3411
3.4043
2.9738
3.0019
3.6325
3.4458
3.0898
3.1184
3.0381
3.2137
4.0124
3.0123
2.9124
3.1518
2.9583
4.0024
3.2374
3.0587
3.0566
3.0965
3.3211
3.5485
3.0875
2.9501
3.5598
3.1376
2.9445
3.4397
3.0273
3.6462
3.336
3.0473
2.9281
3.6011
3.4627
3.0317
3.1993
3.0005
2.9664
3.99
3.0042
3.0184
3.2388
2.9168
3.7623
3.0614
3.0149
3.038
3.533
3.1299
3.324
3.0671
3
3.2801
3.2931
3.0035
3.5409
2.9996
3.4662
3.4024
3.0606
3.0179
3.4968
3.5443
3.0383
3.2215
3.0243
3.033
4.1956
2.9963
3.0321
3.1572
3.0398
3.8533
3.0601
2.9959
2.9542
3.5809
3.2121
3.6047
2.9966
2.9623
3.5832
2.982
3.0219
3.4954
2.9946
3.4694
3.3727
2.9475
2.9832
3.7587
3.6079
2.9777
3.1431
2.9248
3.036
3.9881
3.0103
3.0167
3.2284
2.9601
4.0287
3.031
2.9875
3.0367
3.0727
3.3355
3.6371
3.4319
2.996
3.5602
3.1409
3.0111
3.5847
3.0832
3.5282
3.2545
3.1896
3.0202
3.9438
3.3424
3.1589
3.0388
2.9691
3.9397
3.1946
3.1506
3.1427
3.1326
3.5559
3.7821
3.0614
3.0357
3.2272
3.5563
3.0967
3.135
3.1649
3.0964
3.4718
2.9881
3.5405
3.1155
3.3533
3.3506
2.9417
3.1136
3.401
3.6925
3.0344
3.1423
3.1573
3.0538
3.9243
2.9881
3.1283
3.1625
2.9964
3.9637
3.0455
3.1301
3.069
3.2814
3.2605
3.5455
3.1005
3.0108
3.7322
3.1152
3.1238
3.4133
3.0514
3.5356
3.2783
3.1827
3.028
3.3548
3.3342
3.1989
2.9915
3.0233
3.909
3.1643
3.0163
3.1098
3.0187
3.5334
3.5601
3.0462
3.0168
3.1922
3.5778
3.0498
3.8513
3.0486
3.0243
3.6064
2.9921
3.3021
3.0668
3.1182
3.6879
3.3013
2.9696
3.4139
3.3248
3.1668
3.1333
3.0142
3.0202
3.7732
3.1624
2.9956
3.1448
3.0273
3.5213
3.6519
3.013
2.985
3.2139
3.5742
3.1394
3.1587
3.0001
3.0063
3.6647
3.0685
3.5973
3.87
3.4458
3.3031
3.0197
2.9617
3.556
3.6683
3.0114
3.1764
3.0263
2.9969
4.0179
2.9925
2.9683
3.147
2.9668
3.9255
3.0296
2.9527
3.0429
3.1968
3.1506
3.3832
3.0641
2.9482
3.2844
3.1538
3.0144
3.6432
3.0517
3.2555
3.4406
2.9416
3.0087
3.3635
3.4976
3.0893
3.1875
2.9635
3.0241
3.7775
3.0344
3.0072
3.185
2.9394
3.5597
3.1246
3.0901
3.0343
3.1847
3.5011
3.3346
3.0287
2.9649
3.062
3.3728
2.9949
3.3547
3.0632
3.4711
3.3512
3.0103
2.979
3.4473
3.605
3.141
3.1261
2.9528
3.0187
3.7272
3.0794
3.0274
3.188
2.995
3.4976
3.5301
3.0342
3.0618
3.1526
3.5152
3.1216
3.1708
3.0406
3.4597
3.129
3.1044
3.4898
2.9755
3.3486
3.2878
3.0122
2.996
3.5951
3.5867
3.0787
3.1629
3.0163
2.9414
4.1767
4.3303
3.2053
3.0406
3.4801
3.7902
3.3074
2.9676
3.5964
4.5979
3.7047
3.4903
2.9828
3.5475
3.1542
3.0821
3.5347
3.0309
3.4119
3.3035
3.0376
2.9402
3.4963
3.6347
3.0176
3.2705
3.031
2.9826
3.2757
3.0329
3.1682
2.9789
3.3033
3.4571
3.0591
3.0169
3.2425
3.63
3.1334
3.6087
3.1501
3.0161
3.6869
3.0722
3.1944
3.1781
3.0598
3.3101
3.0639
3.0208
3.3759
3.6037
3.2989
3.1608
3.1158
3.0491
3.7593
3.0542
3.0116
3.1472
2.9697
3.6045
3.7189
3.0582
3.0051
3.2217
3.7445
3.2554
3.0447
2.9422
3.6675
3.2628
3.0398
3.4574
3.0894
3.6851
3.3681
2.9728
3.0002
3.4717
3.5805
3.0362
3.255
3.0054
2.9741
3.983
2.9527
2.978
3.1482
3.0498
3.9974
3.0887
3.0241
3.0435
3.5805
3.1114
3.5133
3.0403
2.9528
3.6021
3.1349
3.0021
3.4662
3.1509
3.4832
3.323
2.9952
2.9391
3.4831
3.5372
3.0589
3.1707
3.1275
2.9894
3.3688
2.991
2.9698
3.1399
3.0413
3.9102
3.0959
3.0536
3.0999
3.3493
3.2385
3.4876
2.9973
3.0152
3.5391
3.1878
3.1478
3.6076
3.1373
3.6735
3.2019
3.0242
2.9943
3.7583
3.3138
3.0677
3.1505
3.0066
3.9346
3.1355
3.005
3.1479
3.2192
3.541
3.6442
3.0392
2.9738
3.1975
3.6061
3.2315
3.6767
2.9664
3.009
3.8772
2.9859
3.1167
3.1103
3.3946
3.7936
2.9776
3.0481
3.47
3.5417
3.1296
3.2119
3.0436
2.912
5.1325
4.0208
4.0411
3.0201
3.5604
3.0785
2.9866
3.0306
3.1911
3.3754
3.473
3.163
2.9879
3.5647
3.2703
3.0127
3.7397
3.8487
3.6457
3.2848
3.0724
2.9921
3.4716
3.1962
3.1137
2.982
3.0178
3.892
3.164
2.9655
3.0625
2.9524
3.4048
3.5348
2.9958
2.9361
3.1758
3.3662
3.1556
3.5817
3.0319
3.0456
3.6629
3.0295
3.0763
3.4788
3.0413
3.5808
3.2831
3.0047
3.2048
3.4978
3.2378
3.1767
2.9859
3.0194
3.6524
3.2094
2.9505
3.1691
2.9953
3.5094
3.7587
3.0608
3.0056
3.2018
3.465
2.9869
3.5582
2.9888
2.9935
3.92
2.96
3.0931
3.1516
3.266
3.352
2.9559
3.0599
3.3832
3.8266
3.1164
3.2426
2.996
3.0333
3.906
3.2257
2.9814
3.2199
3.0067
3.6914
3.044
3.0112
2.9674
3.2017
3.5909
3.2585
3.0308
2.9695
3.4956
3.2838
3.0285
3.4656
3.0612
3.3058
3.3359
2.9939
2.9342
3.9452
3.5476
3.0295
3.1605
3.247
2.9727
3.5558
3.0488
3.0386
3.0335
3.3628
3.7046
2.9659
3.0222
3.1136
3.6194
3.1528
3.5688
3.035
3.0206
3.6328
3.0609
2.9794
3.5492
2.9712
3.6666
3.2168
3.0265
3.1241
3.2543
3.3651
3.042
3.0487
2.9924
3.7855
3.2211
2.9534
3.0707
3.0234
3.232
3.6772
3.0754
3.0317
3.1678
3.4348
3.1532
3.4536
3.0549
2.9818
3.7101
3.0623
2.9525
3.5184
3.0025
3.5438
3.2655
3.0413
3.0133
3.3885
3.2775
3.1253
3.005
3.0443
3.672
3.1807
2.9852
3.049
3.0213
3.4427
3.6493
2.989
2.9541
3.1432
3.3688
3.0902
3.5823
3.041
3.012
3.6218
3.1523
2.9556
3.6073
3.0122
3.8607
3.2123
3.0323
3.1876
3.1594
3.3612
3.2676
3.0229
3.0945
3.5054
3.2721
3.0234
3.153
2.9838
3.3471
3.6388
3.0476
3.0188
3.0827
3.4776
3.1739
3.6782
2.9479
2.9749
3.6261
3.0655
2.997
3.119
3.3968
3.3393
3.0052
2.9762
3.4359
3.6073
3.1533
3.2105
3.0069
3.0644
3.8676
3.2122
3.0029
3.1824
3.0158
3.5408
3.5431
3.0452
3.045
3.1432
3.8417
3.3005
3.0724
2.9791
3.0779
3.4036
3.0103
3.5663
3.0152
3.241
3.3259
3.0254
2.9725
3.4903
3.3821
3.1753
3.156
2.9976
2.9728
3.5997
3.2028
3.0141
3.2607
3.0809
3.4015
3.4647
3.0055
2.9837
3.2199
3.5332
2.9771
3.6051
2.9691
3.0636
3.732
3.0651
3.2903
3.0086
2.9974
3.5904
3.3636
2.9705
3.4692
3.6176
3.0683
3.1477
3.0971
2.9595
3.7773
3.2181
3.0278
3.2084
3.0171
3.5999
3.6741
3.0211
3.0019
3.1705
3.9188
3.4095
3.0198
3.0453
3.2843
3.1303
2.951
3.4414
3.9623
3.5288
3.3906
3.0245
2.9871
3.739
3.7502
3.0476
3.1931
3.0727
3.4009
3.3217
3.0066
2.9425
3.0808
3.1473
3.6722
3.0667
2.9411
3.187
3.4744
3.1121
3.3505
3.084
3.0673
3.6693
3.1345
2.9605
3.507
3.0478
3.4885
3.1585
2.9879
2.9907
3.748
3.7513
3.0716
3.1207
2.9746
3.2792
3.3895
2.9728
3.2296
3.0042
3.4654
3.6956
3.0557
3.009
3.1746
3.5703
3.0961
3.5061
3.0246
2.9567
3.6896
3.0687
2.9388
3.5202
3.0093
3.9156
3.116
3.0589
3.234
3.5834
3.1144
3.1471
3.0247
2.9469
3.7179
3.162
2.9944
3.082
2.9465
3.345
3.6452
3.0671
2.9973
3.1328
3.546
3.1516
3.5932
3.0009
2.9472
3.7017
3.0559
2.9357
3.5603
3.0196
3.6556
3.1706
2.9249
3.362
3.1719
3.2021
3.0113
3.0324
3.007
3.7235
3.1729
3.0111
3.0094
2.9954
3.0978
3.8318
3.1026
3.0083
3.1685
3.3321
3.1136
3.5933
3.0769
2.9986
3.7107
3.0776
2.9919
3.6349
2.9381
3.5089
3.1871
3.0135
2.9948
3.6551
3.3419
3.0036
3.2802
2.9981
3.9234
3.2837
3.0773
3.0644
3.0136
3.5811
3.5791
3.0512
3.036
3.1642
3.6231
3.1742
3.6193
3.0223
2.9408
3.7946
3.0038
3.005
3.1349
3.0852
3.4112
3.0225
2.9651
3.3936
3.4346
3.2874
3.2005
3.0245
3.06
3.8697
3.1401
3.0453
3.2234
3.0267
3.5107
3.6572
3.0905
2.9786
3.2004
3.802
3.1073
3.0791
3.0593
3.149
3.2833
3.0217
3.4606
3.1138
3.5264
3.3536
3.0033
3.0029
3.4579
3.4691
3.1175
3.1252
2.9321
3.0108
3.6733
3.0794
3.072
3.2508
3.0113
3.519
3.7236
2.989
2.9806
3.2286
3.6368
3.2968
3.085
2.9511
3.0445
3.4065
3.0256
3.439
3.0163
3.3792
3.3409
2.9607
2.9565
3.3665
3.3003
3.2011
3.2089
3.0064
3.056
3.7043
3.1288
2.9625
3.1933
3.0535
3.5306
3.4824
3.0355
2.9957
3.1391
3.5563
3.0123
3.6679
2.9494
2.9461
3.6574
3.0374
2.9798
3.1164
3.2455
3.4677
3.0496
3.011
3.3165
3.3036
3.2615
3.0746
3.0109
3.0519
3.785
3.1742
3.1225
3.2447
3.111
3.5482
3.7572
2.9627
3.0021
3.2109
3.8393
3.1136
3.1036
3.0053
3.454
3.2045
2.9841
3.3772
2.9744
3.5413
3.73
3.0014
2.9925
3.3515
3.6824
2.9778
3.1152
3.0225
3.0251
4.0133
3.0395
3.0241
3.203
2.9507
4.2584
2.989
3.0356
3.0022
3.3612
3.3047
3.4712
2.9986
2.9366
3.4464
3.236
2.9982
3.4257
2.9765
3.5723
3.2627
3.0686
2.9479
3.8034
3.7813
2.9708
3.1258
2.9834
3.0068
3.3052
3.0013
2.9934
3.2813
3.0512
3.7015
3.0575
2.9801
3.0455
3.4003
3.2707
3.7446
2.9917
3.0395
3.4236
3.1557
2.9527
3.6281
3.0785
3.5354
3.1816
3.0536
2.9868
3.1506
3.4789
3.0743
3.0589
3.0306
3.7567
3.131
3.0033
3.151
3.0145
3.3328
3.5783
3.014
3.0538
3.1986
3.5225
3.13
3.507
3.0612
3.0106
3.728
2.9741
2.9425
3.7802
3.0541
3.6324
3.2794
2.9932
3.1495
3.5841
3.2456
3.208
3.0633
3.0246
3.9528
3.1304
2.9684
3.1595
3.0032
3.5922
3.5655
3.0151
3.0243
3.261
3.4918
3.037
3.0542
2.995
2.9884
3.5558
2.9817
3.3171
3.1237
3.3171
3.3444
2.9948
2.991
3.496
3.6293
3.1205
3.1127
3.0453
2.9993
3.6935
3.1736
3.0136
3.2486
2.9615
3.6391
3.1018
2.9904
2.9387
3.4553
3.3745
3.3515
3.0488
3.0261
3.5079
3.2359
2.9438
3.4452
3.0691
3.2645
3.2012
3.0308
2.9597
3.5035
3.3718
3.1643
3.1669
3.018
3.029
4.0158
3.0012
3.0128
3.145
2.9678
3.2577
3.4914
3.0193
2.9934
3.2417
3.7243
3.2523
3.0735
3.0354
3.0621
3.4651
3.0627
3.3579
3.0634
3.4523
3.2377
3.0554
3.0673
3.6952
3.5989
3.1026
3.2826
2.9712
3.0121
3.8391
3.0013
3.0204
3.2525
3.0135
3.7421
3.1435
3.0078
2.95
3.3352
3.4597
3.5683
3.1097
2.998
3.4223
3.3037
2.9929
3.6015
3.242
3.4838
3.3552
2.9903
2.9714
3.5643
3.7057
2.9946
3.1564
2.9585
3.0001
4.0275
2.9677
3.094
3.2873
3.0027
3.6853
3.0892
3.0378
3.0115
3.2135
3.2792
3.3882
3.0254
2.9608
3.4628
3.1123
2.973
3.3913
3.0971
3.6715
3.388
2.9839
2.999
3.575
3.5968
2.9832
3.1495
2.9103
2.9825
3.8997
3.0112
2.9643
3.1935
3.0008
4.024
3.0694
3.0659
2.9869
3.5029
3.3047
3.4478
3.0749
2.9912
3.6053
3.1308
3.0152
3.4686
3.0668
3.4525
3.3465
3.0186
3.023
3.6875
3.7901
3.0045
3.336
3.0079
3.4764
3.3317
2.9678
3.0188
3.0046
3.2945
3.6373
3.0727
3.0625
3.1086
3.49
2.9933
3.7114
3.0393
3.0364
3.6768
3.0782
2.9934
4.1569
4.3065
4.451
2.9471
3.0535
3.4911
3.6855
2.9584
3.2023
3.1891
3.1512
3.2319
3.0071
3.0995
2.9732
3.0695
4.0907
2.9873
3.196
3.142
3.53
3.1276
3.4125
3.003
2.9996
3.7155
3.1503
2.998
3.7244
3.0473
3.7203
3.1631
2.9708
3.2274
3.6275
3.1807
3.1558
2.9991
3.0423
4.0196
3.6645
2.9827
3.2157
2.996
3.4531
3.5073
3.0113
3.0074
3.2059
3.8269
3.5333
3.0611
3.0622
3.0773
3.292
3.0429
3.4992
3.0747
3.5299
3.309
2.9842
2.9815
3.5437
3.5275
3.2252
3.1893
3.0123
3.0185
3.9312
3.0289
2.9845
3.1905
3.0293
3.5409
3.1564
3.012
2.9716
3.382
3.1691
3.3834
2.9895
3.0029
3.4273
3.2356
2.9912
3.4678
3.0188
3.4739
3.2563
2.9427
2.967
3.3933
3.5621
3.1106
3.2142
2.9573
2.9905
4.1922
3.0267
2.9636
3.2432
3.0175
4.1218
3.0907
3.0897
2.9607
3.3434
3.2207
3.3764
3.0646
3.0101
3.3941
3.085
2.9398
3.5227
2.9672
3.489
3.3315
2.9805
3.0282
3.5305
3.6349
3.1438
3.2046
3.096
3.058
3.8378
2.9986
2.9615
3.1796
3.0404
3.6688
3.0506
2.9746
2.9931
3.1852
3.5973
3.4475
3.0472
2.9691
3.3113
3.2652
3.0308
3.4903
3.0079
3.244
3.4145
3.0021
2.975
3.3944
3.4399
3.1437
3.1838
3.0221
2.995
3.7264
3.1584
3.016
3.2225
3.0533
3.5693
3.2622
3.0112
3.0646
3.3136
3.3127
3.4607
3.0493
2.9392
3.4967
3.3152
2.9901
3.3902
3.0478
3.4443
3.3421
3.0523
2.9634
3.4537
3.6653
3.051
3.0987
2.9544
2.9707
3.921
2.9949
3.0354
3.1898
2.9658
4.1266
3.0266
2.9734
3.0176
3.3116
3.3063
3.4399
3.1003
2.9176
3.2258
3.1038
3.1047
3.3714
3.0514
3.4949
3.4517
3.0419
3.0181
3.5326
3.4019
3.1689
3.1739
2.9501
2.9762
3.7314
2.9871
2.9974
3.2176
3.0104
3.5854
3.1105
3.0197
2.9785
3.3278
3.1966
3.2419
3.0346
2.9706
3.181
3.1335
3.0224
3.4408
3.0542
3.4172
3.1866
2.998
3.019
3.338
3.3857
3.1008
3.0554
3.0334
2.9679
3.9046
3.1274
3.0032
3.1661
3.0263
3.492
3.5837
2.9714
3.0771
3.1927
3.5688
2.9932
3.268
2.9561
3.3259
3.373
2.984
3.3873
3.0602
3.2881
3.3073
3.0238
2.9588
3.3343
3.5273
3.1002
3.1669
3.0213
2.9733
3.8597
3.12
3.0564
3.1472
3.0566
3.6221
3.7148
3.0456
2.9652
3.2504
3.6653
3.1265
3.146
2.9755
3.5624
3.1519
2.9521
3.3872
3.1372
3.5948
3.804
2.9738
2.9496
3.4844
3.538
3.0048
3.0797
3.0511
2.9611
3.8852
2.9622
2.984
3.1749
3.0571
4.1224
4.3133
3.0104
3.2147
3.4585
3.1582
3.6843
3.0157
3.0957
3.6451
3.0032
3.089
2.9587
3.1027
3.8067
3.6862
2.9663
3.5696
3.6302
3.0226
3.1234
2.9905
3.0737
4.4478
3.4057
2.9853
3.1677
2.9827
3.6608
2.9821
3.0345
2.9306
3.205
3.1228
3.426
3.0219
2.948
3.4864
3.2062
2.9971
3.4802
2.9556
3.5467
3.3126
2.8722
3.0042
3.4696
3.5032
3.1225
3.1642
2.9499
2.9657
3.6331
3.1496
2.9644
3.1827
2.9531
3.5217
3.7417
3.0167
2.9641
3.1638
3.6129
3.2256
3.0966
3.0005
3.1041
3.3729
3.0267
3.5541
3.0948
3.4101
3.4838
3.0742
2.9528
3.4843
3.5224
3.0746
3.1804
3.0044
2.9637
3.9013
3.0323
3.0288
3.2293
3.006
3.5734
3.4806
3.0122
2.9814
3.2323
3.55
3.3565
3.0782
3.0378
3.2315
3.12
3.01
3.465
3.1362
3.5585
3.3493
3.0446
3.0274
3.5897
3.5589
3.1295
3.174
3.0072
3.0054
3.778
3.0227
3.0096
3.2291
3.0151
3.9992
3.0224
3.0362
3.0337
3.3263
3.2518
3.2201
3.0061
3.0294
3.1857
3.2779
3.0248
3.4262
3.0667
3.2769
3.3815
2.9271
2.9647
3.5736
3.4469
3.0815
3.1899
3.0481
2.9899
3.8823
3.0395
3.0483
3.1639
2.9921
3.5468
3.4727
2.9856
3.044
3.153
3.8168
3.2662
3.0938
2.9355
3.0032
3.2689
3.0166
3.2775
3.006
3.1426
3.274
2.9383
3.0545
3.3614
3.4643
3.3133
3.1541
2.9504
2.9489
3.7294
3.1601
3.0236
3.0839
2.9508
3.613
3.6332
3.034
2.9924
3.2012
3.4786
3.0088
3.0919
3.0093
3.0337
3.5754
2.9994
3.2924
3.9907
3.7572
3.3136
2.9897
3.0651
3.6878
3.8346
3.0219
3.2917
3.0037
3.3113
3.1736
3.021
3.0085
3.0069
3.2196
3.7975
3.0221
2.9625
3.1557
3.4785
3.1417
3.4578
3.0199
3.0041
3.7041
3.1136
2.9952
3.4283
2.9848
3.6181
3.176
2.9696
3.0025
3.5794
3.7284
2.9665
3.2809
3.0022
3.3237
3.2909
2.9567
2.9909
3.0496
3.0592
3.5307
3.065
2.9628
2.9896
3.2541
3.2715
3.4079
3.0205
3.0399
3.5364
3.0722
2.9442
3.4986
3.028
3.4133
3.3661
3.0071
2.9898
3.6258
3.63
2.9647
3.2238
3.0026
3.1175
4.0416
2.9854
2.9784
3.2149
3.0347
3.9482
3.0416
2.9965
3.0213
3.4365
3.2434
3.4635
3.0672
3.0338
3.6301
3.0478
2.9878
3.4925
3.0003
3.3714
3.8826
3.015
2.9862
3.5115
3.6251
3.0357
3.196
3.0102
3.1547
3.175
3.0065
2.9702
3.143
3.0535
3.6998
3.0142
3.029
2.899
3.3726
3.2196
3.4604
3.0522
3.0146
3.4856
3.1936
2.9589
3.5034
3.0027
3.594
3.4179
2.9732
3.0185
3.5168
3.6004
2.9876
3.1391
3.003
3.0113
4.055
2.9603
2.9661
3.2532
2.9969
3.6964
4.3375
3.6681
3.7008
3.6558
3.4746
3.0626
2.9362
3.5713
3.1279
2.9856
3.4832
3.0744
3.5055
3.2917
3.049
3.0178
3.468
3.6203
3.18
3.2063
2.9875
3.0306
4.2132
3.5293
3.6309
3.7642
4.0757
4.0377
3.4466
3.0662
3.4355
3.2742
3.3147
2.9707
3.0071
3.4334
3.2302
2.9552
3.47
2.9859
3.5442
3.2472
2.9409
2.9939
3.4897
3.4918
3.0622
3.2587
3.2404
2.9775
4.0606
3.0636
3.019
3.1951
2.9868
3.7446
3.0547
2.9048
3.0129
3.2784
3.3976
3.438
2.985
2.954
3.4473
3.0639
3.0444
3.4374
3.0507
3.3727
3.3445
2.947
2.9592
3.5529
3.6341
3.1643
3.1869
2.9808
3.0766
4.2049
3.061
2.999
3.1751
2.9619
3.782
3.0594
2.9888
3.0118
3.476
3.2188
3.4567
3.0621
3.0142
3.2614
3.2392
3.0182
3.5432
3.7284
4.0197
3.3941
2.9728
2.9447
3.1299
3.2853
3.0722
3.0046
2.971
3.6741
3.3575
2.9887
3.2009
3.0196
3.333
3.5775
2.9794
3.0322
3.1594
3.4628
3.1451
3.8788
3.6641
3.4241
4.0735
3.6676
4.1372
3.658
3.8024
3.1489
2.9794
3.143
3.317
3.2811
3.1922
3.0065
3.0159
3.931
3.0594
3.0292
3.1986
3.0091
3.5706
4.1899
3.6854
3.728
3.4344
3.1142
3.5491
3.039
3.0164
3.6773
3.1422
2.9398
3.5147
3.0532
Count:      16768 iterations
Duration:   60002.71 ms
Latency:    3.15 ms
Throughput: 317.45 FPS
